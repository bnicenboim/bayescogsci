# (PART) Cognitive modeling with Stan {-}
# Introduction to cognitive modeling {#ch-cogmod}

Until this point in the book, we have been discussing models that specify a \index{Generative process} generative process for the observed data. This generative process could be as simple as $Y \sim Normal(\mu,\sigma)$ or it could be an elaborate hierarchical model that incorporates multiple variance components. Usually, in these kinds of models, what is of interest is a parameter that represents a so-called "effect" of interest. Examples that we encountered in the present book are: the effect of word frequency on reading time; effect of relative clause type on reading time; and the effect of attentional load on pupil size.

## What characterizes a computational cognitive model?

One characteristic common to the models seen so far is that no underlying \index{Latent cognitive process} latent cognitive process is specified that elaborates on the generative process that produces the observed dependent variable. For example, in a logistic regression, the correct or incorrect response (say, to a yes/no comprehension question) could be the result of a cascade of alternative steps taken unconsciously (or consciously) by the subject as they generate a response. To make this concrete, a subject could give a yes/no response to a comprehension question after seeing a target sentence by probabilistically processing the sentence deeply  or superficially; once the deep/shallow path is taken, the subject might end up giving either a correct or incorrect answer (the latter by misinterpreting the meaning of the sentence). What is observed in the data is a correct or incorrect response, but the reason that that particular response was given could be underlyingly due to deep or superficial processing.

In this book, we use the phrase "computational cognitive modeling" to refer to generative models that are implemented computationally (as a computer program), and that specify latent (unobserved and, usually, unobservable) processes that result in a behavioral or other kind of response. Cognitive modeling as presented in this section goes beyond estimates of "effects" in the sense discussed above; the principal goal is to explain and understand how a particular cognitive process unfolds, often at an individual trial level and incorporating assumptions about individual-level variation in the way the assumed latent processes are deployed.

Unpacking the latent cognitive process that produces a response has a long history in cognitive science. For example, in sentence processing research, early models like the classic \index{Garden-path model} garden-path model [@frazier79] seek to spell out the steps that occur when the human sentence processing system (the \index{Parser} parser) attempts to build \index{Syntactic structure} syntactic structure incrementally when faced with a temporarily \index{Ambiguous sentence} ambiguous sentence. To make this concrete, consider the sentence: "While Mary bathed the baby happily played in the living room." Compared to the unambiguous baseline sentence
"While Mary bathed, the baby happily played in the living room," the garden-path model assumes that in the ambiguous sentence the parser initially connects the noun phrase "the baby" as the grammatical object of the verb "bathed." It is only when the verb "played" is encountered that the parser reassigns "the baby" as the grammatical subject of the verb "played," leading to the correct parse whereby Mary being the one who is bathing, and not that Mary is bathing the baby. This process of reassigning "the baby"'s grammatical role is computationally costly and is called \index{Reanalysis} reanalysis in sentence processing. The slowdown observed (e.g., in reading studies) at the verb "played" is often called the \index{Garden-path effect} garden-path effect.

This kind of paper-pencil model implicitly posits an overly simplistic and deterministic parsing process: Although this is never spelled out in the garden-path model, there is no assumption that the parser could only probabilistically misparse the sentence when it encounters "the baby"; misparses are implicitly assumed to happen every single time such a temporarily ambiguous sentence is encountered. Such a model does not explicitly allow alternative parsing constraints to come into play; by contrast, a computational model allows the empirical consequences of multiple parsing constraints to be considered quantitatively  [e.g., @jurafsky96;@paapevasishthmpt2022].

## Some advantages of taking the latent-variable modeling approach

Although this kind of simple paper-pencil model is an excellent start towards modeling the latent process of sentence comprehension, just stopping with such a description has several disadvantages.
First, no \index{Quantitative prediction} quantitative predictions can be derived; a corollary is that a slowdown at the verb "played" (due to reanalysis) of 10 ms or 500 ms would both be equally consistent with the predictions of the model---the model cannot say anything about how much time the reanalysis process would take. This is a problem for \index{Model evaluation} model evaluation, not least because overly large effect sizes observed in data could just be \index{Type M error} Type M errors and therefore very misleading [@gelmancarlin; @VasishthMertzenJaegerGelman2018].
Second, such paper-pencil models encourage an excessive (in fact, exclusive) focus on the \index{Average effect size} average effect size (here, the garden-path effect); the \index{Variability among individuals} variability among individuals (which would affect the standard error of the estimated effect from data) plays no role in determining whether the model's prediction is consistent with the data.
A third problem with such verbally stated models is that it is often not clear what the exact assumptions are. This makes it difficult to establish whether the model's predictions are consistent with observed patterns in the data. As a concrete example of these hidden degrees of freedom, an influential theory in sentence processing is the Dependency Locality Theory or DLT [@gibson00]. This theory explicitly assumes that interposing new discourse referents intervening between, say, a subject and a verb, will make it more difficult to complete the subject-verb dependency. The status of the intervening discourse referent is crucial for dependency completion cost to increase. A further descriptive elaboration of the model is presented in @warren2002influence; there, the authors argued that the cost of an intervening discourse referent should be graded according to its discourse accessibility. There was no quantitative implementation of what that implies empirically; for example, do old vs. new discourse referents eliminate dependency completion cost entirely, or is the cost attentuated by some amount (if so, how much?)? Interestingly, in later work, the discourse status of the intervener was ignored; in @gibsonwu, the intervening discourse referents are all old (previously introduced in an immediately preceding context), but they are assumed to have the same impact on dependency completion as new discourse referents, as described in @gibson00. Had the model been computationally implemented, the empirical impact of relaxing the model assumption would have had a quantitative impact on the predictions. This example also illustrates how easy it is to be misled by paper-pencil statements of theories.

Thus, the absence of quantitative predictions, the inability to quantitatively investigate individual-level variation, and hidden degrees of freedom in the model, are three major drawbacks of paper-pencil models. As @rp have discussed at length, a good fit of a model to data is not merely about the sign of the predicted effect being correct; the model must be able to commit a priori to the uncertainty of the predicted effect, and the estimated effect from the data and its uncertainty need to be compared to the predictions of the model. A good fit ideally requires a  tightly constrained quantitative prediction derived from the model that is then validated  by comparing the prediction with unseen data; this point has also been eloquently made by the psychologist @meehl97. Meehl suggests that the model makes risky numerical predictions (by which he means tighly constrained quantitative predictions), which should then be compared with the observed effect size and its confidence interval---this is essentially the same criterion for a good fit that @rp also favor.

For example, if a \index{Computational implementation} computational implementation of the garden-path model were to exist, one could have derived (through prior specifications on the parameters of the model) \index{Prior predictive distribution} prior predictive distributions of the garden-path effect, and compared these predictions to the estimates of the effect from a \index{Statistical model} statistical model fit to new, unseen data [for an example from psycholinguistics, see @VasishthEngelmann2022]. Using \index{Parameteric variation} parameteric variation, one could even investigate the implications of the model for individual-level differences [e.g., @yadavindiff2021]; such implications of models are impossible to derive unless the model is implemented computationally. In the absence of an implemented model, one is reduced to classifying subjects into groups (e.g., by working memory capacity measures) and investigating average group-level effects [e.g., @cw99]. This makes the question a binary one: are there individual differences or are there none? The right question to ask about individual differences is a quantitative one [@haaf2019some].

## Types of computational cognitive model

There are many different classes of computational cognitive model. For example, @utc pioneered a cognitive architectures approach, where a model of a particular cognitive process (like sentence processing) occurs within a broader computational framework that defines very general constraints on human information processing. Examples of cognitive architectures are SOAR [@laird2019soar], the CAPS family of models [@justetal99], and ACT-R [@abbl02]. Other approaches include connectionist models [e.g., @mcclelland1989explorations] and dynamical systems-based models [e.g., @port1995mind; @tabor1999dynamical; @beer2000dynamical; @Rabe2019; @RabePaapeJML2023; @engbertetal06].

In this book, we focus on Bayesian cognitive models [@LeeWagenmakers2014]; these are distinct from models that assume that human cognitive processes involve Bayesian inference [e.g., @feldman2017true]. The type of model we discuss here has the characteristic that the underlying generative process spells out the latent, probabilistically occurring sub-processes. The latent processes are spelled out by specifying a Bayesian model that allows different events to happen probabilistically in each trial.
An example is \index{Multinomial processing tree} multinomial processing tree models, which specify a sequence of possible latent sub-processes. Another example is a \index{Hierarchical finite mixture process} hierarchical finite mixture process which specifies that, in some proportion of trials, the observed response comes from one distribution, and in another proportion from a different distribution.  A third example is the assumption that the observed response (e.g., response time) is the result of an unobserved (latent) \index{Race process} race process in the cognitive system. Probabilistic programming languages like Stan allow us to implement such latent process models, allowing for hierarchical structure (individual-level variability). Additionally, we can make prior assumptions about plausible parameter values, this especially important because the parameters have a meaning in terms of latent processes.


This part of the book introduces these three types of cognitive models using Stan. In many cases, a great deal of cognitive detail is sacrificed for tractability, but this is a characteristic shared by all computational models---by definition, a model is a simplification of the underlying process being modeled [@mcclellandPlaceModelingCognitive2009].

## Summary

The main take-away from this section is that it is possible to specify an underlying generative process for the data that reflects theoretical assumptions in a particular research area. The gain is that: (i) the assumptions of the underlying theory, and their consequences, become transparent and explicit [@epstein2008model]; (ii) one can derive quantitative predictions (along with the uncertainty of those predictions) which, as @rp point out, are vital for model evaluation; (iii) it becomes possible (at least in principle) to eliminate competing theoretical proposals through quantitative model comparison using benchmark data [@nicenboimModelsRetrievalSentence2018; @lisson_2020; @LissonEtAlInterference2021; @YadavetalJML2022]; and (iv) the implications of models, for average behavior [e.g., @YadavetalJML2022] as well as for individual-level differences [e.g., @yadavindiff2021] can be investigated.

## Further reading

General textbooks on computational modeling for cognitive science are  @busemeyer2010cognitive, and @farrell2018computational. The textbook by @LeeWagenmakers2014 focuses on relatively simple computational cognitive models implemented in a Bayesian framework (using the BUGS language).
A good free textbook on computational modeling for cognitive science is @blokpoelvanrooij. The entire special issue [@mathpsych2011] on hierarchical Bayesian modeling in the Journal of Mathematical Psychology is highly recommended [in particular, see the article by @Lee2011]. @WilsonEtAl2019 discuss good practices in the computational modeling of behavioral data using examples from reinforcement learning. @haines2020learning discuss how generative models produce higher test-retest reliability and more theoretically informative parameter estimates than do traditional methods. For an overview of the different modeling approaches in cognitive science and the relationships between them, see @mcclellandPlaceModelingCognitive2009.
@luce1986response is a classic book that focuses on modeling response times.
