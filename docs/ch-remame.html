<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Meta-analysis and measurement error models | Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="Introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Meta-analysis and measurement error models | Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://bruno.nicenboim.me/bayescogsci/images/temporarycover.jpg" />
  <meta property="og:description" content="Introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/bnicenboim/bayescogsci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Meta-analysis and measurement error models | Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="Introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://bruno.nicenboim.me/bayescogsci/images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel J. Schad, and Shravan Vasishth" />


<meta name="date" content="2025-02-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-custom.html"/>
<link rel="next" href="ch-comparison.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block/empty-anchor.js"></script>
<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />
<script>
// FOLD code from 
// https://github.com/bblodfon/rtemps/blob/master/docs/bookdown-lite/hide_code.html
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // if code block has been labeled with class `fold-show`, show the code on init!
    var classList = $(this).attr('class').split(/\s+/);
    for (var i = 0; i < classList.length; i++) {
    if (classList[i] === 'fold-show') {
        show = true;
      }
    }

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide' : 'Code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // hack: return show to false, otherwise all next codeBlocks will be shown!
    show = false;

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>


<script data-goatcounter="https://bayescogsci.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science (DRAFT)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-read-this-book-and-what-is-its-target-audience"><i class="fa fa-check"></i>Why read this book, and what is its target audience?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#developing-the-right-mindset-for-this-book"><i class="fa fa-check"></i>Developing the right mindset for this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-read-this-book"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#some-conventions-used-in-this-book"><i class="fa fa-check"></i>Some conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#online-materials"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-needed"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#introprob"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#condprob"><i class="fa fa-check"></i><b>1.2</b>  Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#the-law-of-total-probability"><i class="fa fa-check"></i><b>1.3</b> The  law of total probability</a></li>
<li class="chapter" data-level="1.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-binomialcloze"><i class="fa fa-check"></i><b>1.4</b>  Discrete random variables: An example using the  binomial distribution</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="ch-intro.html"><a href="ch-intro.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.4.1</b> The mean and variance of the binomial distribution</a></li>
<li class="chapter" data-level="1.4.2" data-path="ch-intro.html"><a href="ch-intro.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.4.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-intro.html"><a href="ch-intro.html#continuous-random-variables-an-example-using-the-normal-distribution"><i class="fa fa-check"></i><b>1.5</b>  Continuous random variables: An example using the  normal distribution</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="ch-intro.html"><a href="ch-intro.html#an-important-distinction-probability-vs.-density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.5.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-intro.html"><a href="ch-intro.html#truncating-a-normal-distribution"><i class="fa fa-check"></i><b>1.5.2</b> Truncating a normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-intro.html"><a href="ch-intro.html#bivariate-and-multivariate-distributions"><i class="fa fa-check"></i><b>1.6</b> Bivariate and multivariate distributions</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="ch-intro.html"><a href="ch-intro.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.1</b> Example 1:  Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-intro.html"><a href="ch-intro.html#sec-contbivar"><i class="fa fa-check"></i><b>1.6.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-intro.html"><a href="ch-intro.html#sec-generatebivariatedata"><i class="fa fa-check"></i><b>1.6.3</b> Generate simulated bivariate (or multivariate) data</a></li>
<li class="chapter" data-level="1.6.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-decomposevcovmatrix"><i class="fa fa-check"></i><b>1.6.4</b> Decomposing a variance-covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-intro.html"><a href="ch-intro.html#sec-marginal"><i class="fa fa-check"></i><b>1.7</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.8" data-path="ch-intro.html"><a href="ch-intro.html#summary-of-some-useful-r-functions"><i class="fa fa-check"></i><b>1.8</b> Summary of some useful R functions</a></li>
<li class="chapter" data-level="1.9" data-path="ch-intro.html"><a href="ch-intro.html#summary"><i class="fa fa-check"></i><b>1.9</b> Summary</a></li>
<li class="chapter" data-level="1.10" data-path="ch-intro.html"><a href="ch-intro.html#further-reading"><i class="fa fa-check"></i><b>1.10</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-introBDA.html"><a href="ch-introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#bayes-rule"><i class="fa fa-check"></i><b>2.1</b>  Bayes’ rule</a></li>
<li class="chapter" data-level="2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-analytical"><i class="fa fa-check"></i><b>2.2</b> Deriving the  posterior using Bayes’ rule: An analytical example</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.2.1</b> Choosing a  likelihood</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-choosepriortheta"><i class="fa fa-check"></i><b>2.2.2</b> Choosing a  prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.2.3</b> Using  Bayes’ rule to compute the  posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.2.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#visualizing-the-prior-likelihood-and-posterior"><i class="fa fa-check"></i><b>2.2.5</b> Visualizing the prior, likelihood, and posterior</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch-introBDA.html"><a href="ch-introBDA.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.2.6</b> The  posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.2.7" data-path="ch-introBDA.html"><a href="ch-introBDA.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.2.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
<li class="chapter" data-level="2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#further-reading-1"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>II Regression models with brms</b></span></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sampling"><i class="fa fa-check"></i><b>3.1</b> Deriving the  posterior through  sampling</a></li>
<li class="chapter" data-level="3.2" data-path="ch-compbda.html"><a href="ch-compbda.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.2</b>  Bayesian Regression Models using Stan:  brms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-simplenormal"><i class="fa fa-check"></i><b>3.2.1</b> A simple linear model: A single subject pressing a button repeatedly (a finger tapping task)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-priorpred"><i class="fa fa-check"></i><b>3.3</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.4" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sensitivity"><i class="fa fa-check"></i><b>3.4</b> The influence of priors:  sensitivity analysis</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch-compbda.html"><a href="ch-compbda.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.4.1</b>  Flat, uninformative priors</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-compbda.html"><a href="ch-compbda.html#regularizing-priors"><i class="fa fa-check"></i><b>3.4.2</b>  Regularizing priors</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-compbda.html"><a href="ch-compbda.html#principled-priors"><i class="fa fa-check"></i><b>3.4.3</b>  Principled priors</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-compbda.html"><a href="ch-compbda.html#informative-priors"><i class="fa fa-check"></i><b>3.4.4</b>  Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-revisit"><i class="fa fa-check"></i><b>3.5</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.6" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ppd"><i class="fa fa-check"></i><b>3.6</b>  Posterior predictive distribution</a></li>
<li class="chapter" data-level="3.7" data-path="ch-compbda.html"><a href="ch-compbda.html#the-influence-of-the-likelihood"><i class="fa fa-check"></i><b>3.7</b> The influence of the likelihood</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lnfirst"><i class="fa fa-check"></i><b>3.7.1</b> The  log-normal likelihood</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lognormal"><i class="fa fa-check"></i><b>3.7.2</b> Using a log-normal likelihood to fit data from a single subject pressing a button repeatedly</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="ch-compbda.html"><a href="ch-compbda.html#list-of-the-most-important-commands"><i class="fa fa-check"></i><b>3.8</b> List of the most important commands</a></li>
<li class="chapter" data-level="3.9" data-path="ch-compbda.html"><a href="ch-compbda.html#summary-2"><i class="fa fa-check"></i><b>3.9</b> Summary</a></li>
<li class="chapter" data-level="3.10" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ch3furtherreading"><i class="fa fa-check"></i><b>3.10</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupil"><i class="fa fa-check"></i><b>4.1</b> A first  linear regression: Does attentional load affect pupil size?</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b>  Likelihood and  priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The  <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-trial"><i class="fa fa-check"></i><b>4.2</b>  Log-normal model: Does trial affect response times?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The  <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.2.4" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.2.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-reg.html"><a href="ch-reg.html#sec-logistic"><i class="fa fa-check"></i><b>4.3</b>  Logistic regression: Does  set size affect  free recall?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ch-reg.html"><a href="ch-reg.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-priorslogisticregression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-comlogis"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy-1"><i class="fa fa-check"></i><b>4.3.5</b>  Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-reg.html"><a href="ch-reg.html#summary-3"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="ch-reg.html"><a href="ch-reg.html#sec-ch4furtherreading"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#exchangeability-and-hierarchical-models"><i class="fa fa-check"></i><b>5.1</b> Exchangeability and hierarchical models</a></li>
<li class="chapter" data-level="5.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-N400hierarchical"><i class="fa fa-check"></i><b>5.2</b> A hierarchical model with a normal likelihood: The N400 effect</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-Mcp"><i class="fa fa-check"></i><b>5.2.1</b>  Complete pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.2.2</b>  No pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.2.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-uncorrelated"><i class="fa fa-check"></i><b>5.2.3</b>  Varying intercepts and  varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.2.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-mcvivs"><i class="fa fa-check"></i><b>5.2.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.2.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-sih"><i class="fa fa-check"></i><b>5.2.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.2.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-distrmodel"><i class="fa fa-check"></i><b>5.2.6</b> Beyond the maximal model–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-stroop"><i class="fa fa-check"></i><b>5.3</b> A  hierarchical log-normal model: The  Stroop effect</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.3.1</b> A correlated varying intercept varying slopes  log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort"><i class="fa fa-check"></i><b>5.4</b> Why fitting a Bayesian hierarchical model is worth the effort</a></li>
<li class="chapter" data-level="5.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#summary-4"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
<li class="chapter" data-level="5.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#further-reading-2"><i class="fa fa-check"></i><b>5.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>6</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch-contr.html"><a href="ch-contr.html#basic-concepts-illustrated-using-a-two-level-factor"><i class="fa fa-check"></i><b>6.1</b> Basic concepts illustrated using a two-level factor</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ch-contr.html"><a href="ch-contr.html#treatmentcontrasts"><i class="fa fa-check"></i><b>6.1.1</b> Default contrast coding:  Treatment contrasts</a></li>
<li class="chapter" data-level="6.1.2" data-path="ch-contr.html"><a href="ch-contr.html#inverseMatrix"><i class="fa fa-check"></i><b>6.1.2</b> Defining comparisons</a></li>
<li class="chapter" data-level="6.1.3" data-path="ch-contr.html"><a href="ch-contr.html#effectcoding"><i class="fa fa-check"></i><b>6.1.3</b>  Sum contrasts</a></li>
<li class="chapter" data-level="6.1.4" data-path="ch-contr.html"><a href="ch-contr.html#sec-cellMeans"><i class="fa fa-check"></i><b>6.1.4</b>  Cell means parameterization and  posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix-illustrated-with-a-three-level-factor"><i class="fa fa-check"></i><b>6.2</b> The hypothesis matrix illustrated with a three-level factor</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ch-contr.html"><a href="ch-contr.html#sumcontrasts"><i class="fa fa-check"></i><b>6.2.1</b>  Sum contrasts</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>6.2.2</b> The  hypothesis matrix</a></li>
<li class="chapter" data-level="6.2.3" data-path="ch-contr.html"><a href="ch-contr.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>6.2.3</b> Generating contrasts: The  <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-contr.html"><a href="ch-contr.html#sec-4levelFactor"><i class="fa fa-check"></i><b>6.3</b> Other types of contrasts: illustration with a factor of four levels</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ch-contr.html"><a href="ch-contr.html#repeatedcontrasts"><i class="fa fa-check"></i><b>6.3.1</b>  Repeated contrasts</a></li>
<li class="chapter" data-level="6.3.2" data-path="ch-contr.html"><a href="ch-contr.html#helmertcontrasts"><i class="fa fa-check"></i><b>6.3.2</b>  Helmert contrasts</a></li>
<li class="chapter" data-level="6.3.3" data-path="ch-contr.html"><a href="ch-contr.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>6.3.3</b> Contrasts in linear regression analysis: The design or  model matrix</a></li>
<li class="chapter" data-level="6.3.4" data-path="ch-contr.html"><a href="ch-contr.html#polynomialContrasts"><i class="fa fa-check"></i><b>6.3.4</b>  Polynomial contrasts</a></li>
<li class="chapter" data-level="6.3.5" data-path="ch-contr.html"><a href="ch-contr.html#an-alternative-to-contrasts-monotonic-effects"><i class="fa fa-check"></i><b>6.3.5</b> An alternative to contrasts:  Monotonic effects</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ch-contr.html"><a href="ch-contr.html#nonOrthogonal"><i class="fa fa-check"></i><b>6.4</b> What makes a good set of contrasts?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ch-contr.html"><a href="ch-contr.html#centered-contrasts"><i class="fa fa-check"></i><b>6.4.1</b>  Centered contrasts</a></li>
<li class="chapter" data-level="6.4.2" data-path="ch-contr.html"><a href="ch-contr.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>6.4.2</b>  Orthogonal contrasts</a></li>
<li class="chapter" data-level="6.4.3" data-path="ch-contr.html"><a href="ch-contr.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> The role of the  intercept in  non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ch-contr.html"><a href="ch-contr.html#computing-condition-means-from-estimated-contrasts"><i class="fa fa-check"></i><b>6.5</b> Computing condition means from estimated contrasts</a></li>
<li class="chapter" data-level="6.6" data-path="ch-contr.html"><a href="ch-contr.html#summary-5"><i class="fa fa-check"></i><b>6.6</b> Summary</a></li>
<li class="chapter" data-level="6.7" data-path="ch-contr.html"><a href="ch-contr.html#further-reading-3"><i class="fa fa-check"></i><b>6.7</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html"><i class="fa fa-check"></i><b>7</b> Contrast coding with two predictor variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-MR-ANOVA"><i class="fa fa-check"></i><b>7.1</b> Contrast coding in a factorial <span class="math inline">\(2 \times 2\)</span> design</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#nestedEffects"><i class="fa fa-check"></i><b>7.1.1</b>  Nested effects</a></li>
<li class="chapter" data-level="7.1.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>7.1.2</b>  Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-contrast-covariate"><i class="fa fa-check"></i><b>7.2</b> One factor and one  covariate</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>7.2.1</b> Estimating a  group difference and controlling for a covariate</a></li>
<li class="chapter" data-level="7.2.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>7.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-interactions-NLM"><i class="fa fa-check"></i><b>7.3</b> Interactions in generalized linear models (with non-linear link functions) and non-linear models</a></li>
<li class="chapter" data-level="7.4" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#summary-6"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#further-reading-4"><i class="fa fa-check"></i><b>7.5</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>III Advanced models with Stan</b></span></li>
<li class="chapter" data-level="8" data-path="ch-introstan.html"><a href="ch-introstan.html"><i class="fa fa-check"></i><b>8</b> Introduction to the probabilistic programming language Stan</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch-introstan.html"><a href="ch-introstan.html#stan-syntax"><i class="fa fa-check"></i><b>8.1</b> Stan syntax</a></li>
<li class="chapter" data-level="8.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-firststan"><i class="fa fa-check"></i><b>8.2</b> A first simple example with Stan:  Normal likelihood</a></li>
<li class="chapter" data-level="8.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-clozestan"><i class="fa fa-check"></i><b>8.3</b> Another simple example:  Cloze probability with Stan with the  binomial likelihood</a></li>
<li class="chapter" data-level="8.4" data-path="ch-introstan.html"><a href="ch-introstan.html#regression-models-in-stan"><i class="fa fa-check"></i><b>8.4</b>  Regression models in Stan</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-pupilstan"><i class="fa fa-check"></i><b>8.4.1</b> A first  linear regression in Stan: Does attentional load affect  pupil size?</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-interstan"><i class="fa fa-check"></i><b>8.4.2</b>  Interactions in Stan: Does attentional load interact with trial number affecting  pupil size?</a></li>
<li class="chapter" data-level="8.4.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-logisticstan"><i class="fa fa-check"></i><b>8.4.3</b>  Logistic regression in Stan: Does set size and trial affect free recall?</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-introstan.html"><a href="ch-introstan.html#summary-7"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="ch-introstan.html"><a href="ch-introstan.html#further-reading-5"><i class="fa fa-check"></i><b>8.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-complexstan.html"><a href="ch-complexstan.html"><i class="fa fa-check"></i><b>9</b> Hierarchical models and reparameterization </a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-hierstan"><i class="fa fa-check"></i><b>9.1</b> Hierarchical models with Stan</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#varying-intercept-model-with-stan"><i class="fa fa-check"></i><b>9.1.1</b> Varying intercept model with Stan</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-uncorrstan"><i class="fa fa-check"></i><b>9.1.2</b> Uncorrelated  varying intercept and slopes model with Stan</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-corrstan"><i class="fa fa-check"></i><b>9.1.3</b>  Correlated varying intercept varying slopes model</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-crosscorrstan"><i class="fa fa-check"></i><b>9.1.4</b> By-subject and by-items correlated varying intercept varying slopes model</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#summary-8"><i class="fa fa-check"></i><b>9.2</b> Summary</a></li>
<li class="chapter" data-level="9.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#further-reading-6"><i class="fa fa-check"></i><b>9.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-custom.html"><a href="ch-custom.html"><i class="fa fa-check"></i><b>10</b> Custom distributions in Stan</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch-custom.html"><a href="ch-custom.html#sec-change"><i class="fa fa-check"></i><b>10.1</b> A change of variables with the reciprocal normal distribution</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="ch-custom.html"><a href="ch-custom.html#scaling-a-probability-density-with-the-jacobian-adjustment"><i class="fa fa-check"></i><b>10.1.1</b> Scaling a probability density with the Jacobian adjustment</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ch-custom.html"><a href="ch-custom.html#sec-validSBC"><i class="fa fa-check"></i><b>10.2</b>  Validation of a computed posterior distribution</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ch-custom.html"><a href="ch-custom.html#the-simulation-based-calibration-procedure"><i class="fa fa-check"></i><b>10.2.1</b> The  simulation-based calibration procedure</a></li>
<li class="chapter" data-level="10.2.2" data-path="ch-custom.html"><a href="ch-custom.html#an-example-where-simulation-based-calibration-reveals-a-problem"><i class="fa fa-check"></i><b>10.2.2</b> An example where simulation-based calibration reveals a problem</a></li>
<li class="chapter" data-level="10.2.3" data-path="ch-custom.html"><a href="ch-custom.html#issues-with-and-limitations-of-simulation-based-calibration"><i class="fa fa-check"></i><b>10.2.3</b> Issues with and limitations of simulation-based calibration</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ch-custom.html"><a href="ch-custom.html#another-custom-distribution-the-exponential-distribution-implemented-manually"><i class="fa fa-check"></i><b>10.3</b> Another  custom distribution: The exponential distribution  implemented manually</a></li>
<li class="chapter" data-level="10.4" data-path="ch-custom.html"><a href="ch-custom.html#summary-9"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
<li class="chapter" data-level="10.5" data-path="ch-custom.html"><a href="ch-custom.html#further-reading-7"><i class="fa fa-check"></i><b>10.5</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence synthesis and measurements with error</b></span></li>
<li class="chapter" data-level="11" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>11</b>  Meta-analysis and  measurement error models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch-remame.html"><a href="ch-remame.html#meta-analysis"><i class="fa fa-check"></i><b>11.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ch-remame.html"><a href="ch-remame.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension"><i class="fa fa-check"></i><b>11.1.1</b> A meta-analysis of similarity-based interference in sentence comprehension</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-remame.html"><a href="ch-remame.html#measurement-error-models"><i class="fa fa-check"></i><b>11.2</b>  Measurement-error models</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ch-remame.html"><a href="ch-remame.html#accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency"><i class="fa fa-check"></i><b>11.2.1</b> Accounting for measurement error in individual differences in working memory capacity and reading fluency</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-remame.html"><a href="ch-remame.html#summary-10"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="ch-remame.html"><a href="ch-remame.html#further-reading-8"><i class="fa fa-check"></i><b>11.4</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>V Model comparison</b></span></li>
<li class="chapter" data-level="12" data-path="ch-comparison.html"><a href="ch-comparison.html"><i class="fa fa-check"></i><b>12</b> Introduction to model comparison</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch-comparison.html"><a href="ch-comparison.html#prior-predictive-vs.-posterior-predictive-model-comparison"><i class="fa fa-check"></i><b>12.1</b> Prior predictive vs. posterior predictive model comparison</a></li>
<li class="chapter" data-level="12.2" data-path="ch-comparison.html"><a href="ch-comparison.html#some-important-points-to-consider-when-comparing-models"><i class="fa fa-check"></i><b>12.2</b> Some important points to consider when comparing models</a></li>
<li class="chapter" data-level="12.3" data-path="ch-comparison.html"><a href="ch-comparison.html#further-reading-9"><i class="fa fa-check"></i><b>12.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>13</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ch-bf.html"><a href="ch-bf.html#hypothesis-testing-using-the-bayes-factor"><i class="fa fa-check"></i><b>13.1</b> Hypothesis testing using the Bayes factor</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ch-bf.html"><a href="ch-bf.html#marginal-likelihood"><i class="fa fa-check"></i><b>13.1.1</b> Marginal likelihood</a></li>
<li class="chapter" data-level="13.1.2" data-path="ch-bf.html"><a href="ch-bf.html#the-bayes-factor"><i class="fa fa-check"></i><b>13.1.2</b> The Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-N400BF"><i class="fa fa-check"></i><b>13.2</b> Examining the N400 effect with the Bayes factor</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ch-bf.html"><a href="ch-bf.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>13.2.1</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="13.2.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFnonnested"><i class="fa fa-check"></i><b>13.2.2</b>  Non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ch-bf.html"><a href="ch-bf.html#the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest"><i class="fa fa-check"></i><b>13.3</b> The influence of the priors on Bayes factors: beyond the effect of interest</a></li>
<li class="chapter" data-level="13.4" data-path="ch-bf.html"><a href="ch-bf.html#sec-stanBF"><i class="fa fa-check"></i><b>13.4</b>  The Bayes factor in Stan</a></li>
<li class="chapter" data-level="13.5" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-and-in-practice"><i class="fa fa-check"></i><b>13.5</b> Bayes factors in theory and in practice</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-stability-and-accuracy"><i class="fa fa-check"></i><b>13.5.1</b> Bayes factors in theory: Stability and  accuracy</a></li>
<li class="chapter" data-level="13.5.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFvar"><i class="fa fa-check"></i><b>13.5.2</b> Bayes factors in practice: Variability with the data</a></li>
<li class="chapter" data-level="13.5.3" data-path="ch-bf.html"><a href="ch-bf.html#sec-caution"><i class="fa fa-check"></i><b>13.5.3</b> A cautionary note about Bayes factors</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="ch-bf.html"><a href="ch-bf.html#sample-size-determination-using-bayes-factors"><i class="fa fa-check"></i><b>13.6</b> Sample size determination using Bayes factors</a></li>
<li class="chapter" data-level="13.7" data-path="ch-bf.html"><a href="ch-bf.html#summary-11"><i class="fa fa-check"></i><b>13.7</b> Summary</a></li>
<li class="chapter" data-level="13.8" data-path="ch-bf.html"><a href="ch-bf.html#further-reading-10"><i class="fa fa-check"></i><b>13.8</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ch-cv.html"><a href="ch-cv.html"><i class="fa fa-check"></i><b>14</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch-cv.html"><a href="ch-cv.html#the-expected-log-predictive-density-of-a-model"><i class="fa fa-check"></i><b>14.1</b> The expected log predictive density of a model</a></li>
<li class="chapter" data-level="14.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-and-leave-one-out-cross-validation"><i class="fa fa-check"></i><b>14.2</b> K-fold and leave-one-out cross-validation</a></li>
<li class="chapter" data-level="14.3" data-path="ch-cv.html"><a href="ch-cv.html#testing-the-n400-effect-using-cross-validation"><i class="fa fa-check"></i><b>14.3</b> Testing the N400 effect using cross-validation</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-psis-loo"><i class="fa fa-check"></i><b>14.3.1</b> Cross-validation with PSIS-LOO</a></li>
<li class="chapter" data-level="14.3.2" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-k-fold"><i class="fa fa-check"></i><b>14.3.2</b> Cross-validation with K-fold</a></li>
<li class="chapter" data-level="14.3.3" data-path="ch-cv.html"><a href="ch-cv.html#leave-one-group-out-cross-validation"><i class="fa fa-check"></i><b>14.3.3</b> Leave-one-group-out cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ch-cv.html"><a href="ch-cv.html#sec-logcv"><i class="fa fa-check"></i><b>14.4</b>  Comparing different likelihoods with cross-validation</a></li>
<li class="chapter" data-level="14.5" data-path="ch-cv.html"><a href="ch-cv.html#sec-issuesCV"><i class="fa fa-check"></i><b>14.5</b> Issues with cross-validation</a></li>
<li class="chapter" data-level="14.6" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-in-stan"><i class="fa fa-check"></i><b>14.6</b> Cross-validation in Stan</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="ch-cv.html"><a href="ch-cv.html#psis-loo-cv-in-stan"><i class="fa fa-check"></i><b>14.6.1</b>  PSIS-LOO-CV in Stan</a></li>
<li class="chapter" data-level="14.6.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-cv-in-stan"><i class="fa fa-check"></i><b>14.6.2</b>  K-fold-CV in Stan</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="ch-cv.html"><a href="ch-cv.html#summary-12"><i class="fa fa-check"></i><b>14.7</b> Summary</a></li>
<li class="chapter" data-level="14.8" data-path="ch-cv.html"><a href="ch-cv.html#further-reading-11"><i class="fa fa-check"></i><b>14.8</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>VI Cognitive modeling with Stan</b></span></li>
<li class="chapter" data-level="15" data-path="ch-cogmod.html"><a href="ch-cogmod.html"><i class="fa fa-check"></i><b>15</b> Introduction to cognitive modeling</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch-cogmod.html"><a href="ch-cogmod.html#what-characterizes-a-computational-cognitive-model"><i class="fa fa-check"></i><b>15.1</b> What characterizes a computational cognitive model?</a></li>
<li class="chapter" data-level="15.2" data-path="ch-cogmod.html"><a href="ch-cogmod.html#some-advantages-of-taking-the-latent-variable-modeling-approach"><i class="fa fa-check"></i><b>15.2</b> Some advantages of taking the latent-variable modeling approach</a></li>
<li class="chapter" data-level="15.3" data-path="ch-cogmod.html"><a href="ch-cogmod.html#types-of-computational-cognitive-model"><i class="fa fa-check"></i><b>15.3</b> Types of computational cognitive model</a></li>
<li class="chapter" data-level="15.4" data-path="ch-cogmod.html"><a href="ch-cogmod.html#summary-13"><i class="fa fa-check"></i><b>15.4</b> Summary</a></li>
<li class="chapter" data-level="15.5" data-path="ch-cogmod.html"><a href="ch-cogmod.html#further-reading-12"><i class="fa fa-check"></i><b>15.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-MPT.html"><a href="ch-MPT.html"><i class="fa fa-check"></i><b>16</b> Multinomial processing trees</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-multiple-categorical-responses"><i class="fa fa-check"></i><b>16.1</b> Modeling  multiple categorical responses</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mult"><i class="fa fa-check"></i><b>16.1.1</b> A model for multiple responses using the multinomial likelihood</a></li>
<li class="chapter" data-level="16.1.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-cat"><i class="fa fa-check"></i><b>16.1.2</b> A model for multiple responses using the categorical distribution</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-picture-naming-abilities-in-aphasia-with-mpt-models"><i class="fa fa-check"></i><b>16.2</b> Modeling picture naming abilities in aphasia with MPT models</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ch-MPT.html"><a href="ch-MPT.html#calculation-of-the-probabilities-in-the-mpt-branches"><i class="fa fa-check"></i><b>16.2.1</b> Calculation of the probabilities in the MPT branches</a></li>
<li class="chapter" data-level="16.2.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mpt-data"><i class="fa fa-check"></i><b>16.2.2</b> A simple MPT model</a></li>
<li class="chapter" data-level="16.2.3" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-reg"><i class="fa fa-check"></i><b>16.2.3</b> An MPT model assuming by-item variability</a></li>
<li class="chapter" data-level="16.2.4" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-h"><i class="fa fa-check"></i><b>16.2.4</b> A  hierarchical MPT</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ch-MPT.html"><a href="ch-MPT.html#summary-14"><i class="fa fa-check"></i><b>16.3</b> Summary</a></li>
<li class="chapter" data-level="16.4" data-path="ch-MPT.html"><a href="ch-MPT.html#further-reading-13"><i class="fa fa-check"></i><b>16.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-mixture.html"><a href="ch-mixture.html"><i class="fa fa-check"></i><b>17</b> Mixture models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ch-mixture.html"><a href="ch-mixture.html#a-mixture-model-of-the-speed-accuracy-trade-off-the-fast-guess-model-account"><i class="fa fa-check"></i><b>17.1</b> A mixture model of the speed-accuracy trade-off: The fast-guess model account</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="ch-mixture.html"><a href="ch-mixture.html#the-global-motion-detection-task"><i class="fa fa-check"></i><b>17.1.1</b> The global motion detection task</a></li>
<li class="chapter" data-level="17.1.2" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-simplefastguess"><i class="fa fa-check"></i><b>17.1.2</b> A very simple implementation of the fast-guess model</a></li>
<li class="chapter" data-level="17.1.3" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-multmix"><i class="fa fa-check"></i><b>17.1.3</b> A  multivariate implementation of the fast-guess model</a></li>
<li class="chapter" data-level="17.1.4" data-path="ch-mixture.html"><a href="ch-mixture.html#an-implementation-of-the-fast-guess-model-that-takes-instructions-into-account"><i class="fa fa-check"></i><b>17.1.4</b> An implementation of the fast-guess model that takes instructions into account</a></li>
<li class="chapter" data-level="17.1.5" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-fastguessh"><i class="fa fa-check"></i><b>17.1.5</b> A  hierarchical implementation of the fast-guess model</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="ch-mixture.html"><a href="ch-mixture.html#summary-15"><i class="fa fa-check"></i><b>17.2</b> Summary</a></li>
<li class="chapter" data-level="17.3" data-path="ch-mixture.html"><a href="ch-mixture.html#further-reading-14"><i class="fa fa-check"></i><b>17.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html"><i class="fa fa-check"></i><b>18</b> A simple accumulator model to account for choice response time</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#modeling-a-lexical-decision-task"><i class="fa fa-check"></i><b>18.1</b> Modeling a lexical decision task</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-acccoding"><i class="fa fa-check"></i><b>18.1.1</b> Modeling the lexical decision task with the log-normal race model</a></li>
<li class="chapter" data-level="18.1.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-genaccum"><i class="fa fa-check"></i><b>18.1.2</b> A generative model for a race between accumulators</a></li>
<li class="chapter" data-level="18.1.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#fitting-the-log-normal-race-model"><i class="fa fa-check"></i><b>18.1.3</b> Fitting the log-normal race model</a></li>
<li class="chapter" data-level="18.1.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-lognormalh"><i class="fa fa-check"></i><b>18.1.4</b> A hierarchical implementation of the log-normal race model</a></li>
<li class="chapter" data-level="18.1.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-contaminant"><i class="fa fa-check"></i><b>18.1.5</b> Dealing with  contaminant responses</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#posterior-predictive-check-with-the-quantile-probability-plots"><i class="fa fa-check"></i><b>18.2</b> Posterior predictive check with the quantile probability plots</a></li>
<li class="chapter" data-level="18.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#summary-16"><i class="fa fa-check"></i><b>18.3</b> Summary</a></li>
<li class="chapter" data-level="18.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#further-reading-15"><i class="fa fa-check"></i><b>18.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-closing.html"><a href="ch-closing.html"><i class="fa fa-check"></i><b>19</b> In closing</a></li>
<li class="appendix"><span><b>Online materials</b></span></li>
<li class="chapter" data-level="A" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html"><i class="fa fa-check"></i><b>A</b> Regression models with <code>brms</code> - Extended</a>
<ul>
<li class="chapter" data-level="A.1" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-efficientpriorpd"><i class="fa fa-check"></i><b>A.1</b> An efficient function for generating prior predictive distributions in R</a></li>
<li class="chapter" data-level="A.2" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-truncation"><i class="fa fa-check"></i><b>A.2</b> Truncated distributions</a></li>
<li class="chapter" data-level="A.3" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-intercept"><i class="fa fa-check"></i><b>A.3</b> Intercepts in <code>brms</code></a></li>
<li class="chapter" data-level="A.4" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-lognormal"><i class="fa fa-check"></i><b>A.4</b> Understanding the log-normal likelihood</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#log-normal-distributions-everywhere"><i class="fa fa-check"></i><b>A.4.1</b> Log-normal distributions everywhere</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-priorR"><i class="fa fa-check"></i><b>A.5</b> Prior predictive checks in R</a></li>
<li class="chapter" data-level="A.6" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-exch"><i class="fa fa-check"></i><b>A.6</b> Finitely exchangeable random variables</a></li>
<li class="chapter" data-level="A.7" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-matrixHierachicalModel"><i class="fa fa-check"></i><b>A.7</b> The Matrix Formulation of Hierarchical Models (the Laird-Ware form)</a></li>
<li class="chapter" data-level="A.8" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-cTreatGM"><i class="fa fa-check"></i><b>A.8</b> Treatment contrast with intercept as the grand mean</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html"><i class="fa fa-check"></i><b>B</b> Advanced models with Stan - Extended</a>
<ul>
<li class="chapter" data-level="B.1" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-target"><i class="fa fa-check"></i><b>B.1</b> What does <code>target</code> do in Stan models?</a></li>
<li class="chapter" data-level="B.2" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-tilde"><i class="fa fa-check"></i><b>B.2</b> Explicitly incrementing the log probability function (<code>target</code>) vs. using the sampling or distribution <code>~</code> notation</a></li>
<li class="chapter" data-level="B.3" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-cmdstanr"><i class="fa fa-check"></i><b>B.3</b> An alternative R interface to Stan: <code>cmdstanr</code></a></li>
<li class="chapter" data-level="B.4" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-stancontainers"><i class="fa fa-check"></i><b>B.4</b> Matrix, vector, or array in Stan?</a></li>
<li class="chapter" data-level="B.5" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-noncenterparam"><i class="fa fa-check"></i><b>B.5</b> A simple non-centered parameterization</a></li>
<li class="chapter" data-level="B.6" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-cholesky"><i class="fa fa-check"></i><b>B.6</b> Cholesky factorization for reparameterizing hierarchical models with correlations between adjustments to different parameters</a></li>
<li class="chapter" data-level="B.7" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-sbc"><i class="fa fa-check"></i><b>B.7</b> Different rank visualizations and the <code>SBC</code> package.</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="evidence-synthesis-and-measurements-with-error---extended.html"><a href="evidence-synthesis-and-measurements-with-error---extended.html"><i class="fa fa-check"></i><b>C</b> Evidence synthesis and measurements with error - Extended</a>
<ul>
<li class="chapter" data-level="C.1" data-path="evidence-synthesis-and-measurements-with-error---extended.html"><a href="evidence-synthesis-and-measurements-with-error---extended.html#app-sigmatrue"><i class="fa fa-check"></i><b>C.1</b> What happens if we set <code>sigma = TRUE</code> in <code>resp_se()</code> function in <code>brms</code>?</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html"><i class="fa fa-check"></i><b>D</b> Model comparison - Extended</a>
<ul>
<li class="chapter" data-level="D.1" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-null"><i class="fa fa-check"></i><b>D.1</b> Credible intervals should not be used to reject a null hypothesis</a></li>
<li class="chapter" data-level="D.2" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-likR"><i class="fa fa-check"></i><b>D.2</b> The likelihood ratio vs the Bayes factor</a></li>
<li class="chapter" data-level="D.3" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-integral"><i class="fa fa-check"></i><b>D.3</b> Approximation of the (expected) log predictive density of a model without integration</a></li>
<li class="chapter" data-level="D.4" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-CV-alg"><i class="fa fa-check"></i><b>D.4</b> The cross-validation algorithm for the expected log predictive density of a model</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="ch-priors.html"><a href="ch-priors.html"><i class="fa fa-check"></i><b>E</b> The Art and Science of Prior Elicitation</a>
<ul>
<li class="chapter" data-level="E.1" data-path="ch-priors.html"><a href="ch-priors.html#sec-simpleexamplepriors"><i class="fa fa-check"></i><b>E.1</b> Eliciting priors from oneself for a self-paced reading study: An example</a>
<ul>
<li class="chapter" data-level="E.1.1" data-path="ch-priors.html"><a href="ch-priors.html#an-example-english-relative-clauses"><i class="fa fa-check"></i><b>E.1.1</b> An example: English  relative clauses</a></li>
<li class="chapter" data-level="E.1.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-intercept"><i class="fa fa-check"></i><b>E.1.2</b> Eliciting a prior for the intercept</a></li>
<li class="chapter" data-level="E.1.3" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-slope"><i class="fa fa-check"></i><b>E.1.3</b> Eliciting a prior for the slope</a></li>
<li class="chapter" data-level="E.1.4" data-path="ch-priors.html"><a href="ch-priors.html#sec-varcomppriors"><i class="fa fa-check"></i><b>E.1.4</b> Eliciting priors for the  variance components</a></li>
</ul></li>
<li class="chapter" data-level="E.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-priors-from-experts"><i class="fa fa-check"></i><b>E.2</b>  Eliciting priors from experts</a></li>
<li class="chapter" data-level="E.3" data-path="ch-priors.html"><a href="ch-priors.html#deriving-priors-from-meta-analyses"><i class="fa fa-check"></i><b>E.3</b> Deriving priors from  meta-analyses</a></li>
<li class="chapter" data-level="E.4" data-path="ch-priors.html"><a href="ch-priors.html#using-previous-experiments-posteriors-as-priors-for-a-new-study"><i class="fa fa-check"></i><b>E.4</b> Using previous experiments’  posteriors as priors for a new study</a></li>
<li class="chapter" data-level="E.5" data-path="ch-priors.html"><a href="ch-priors.html#summary-17"><i class="fa fa-check"></i><b>E.5</b> Summary</a></li>
<li class="chapter" data-level="E.6" data-path="ch-priors.html"><a href="ch-priors.html#further-reading-16"><i class="fa fa-check"></i><b>E.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="ch-workflow.html"><a href="ch-workflow.html"><i class="fa fa-check"></i><b>F</b> Workflow</a>
<ul>
<li class="chapter" data-level="F.1" data-path="ch-workflow.html"><a href="ch-workflow.html#building-a-model"><i class="fa fa-check"></i><b>F.1</b>  Building a model</a></li>
<li class="chapter" data-level="F.2" data-path="ch-workflow.html"><a href="ch-workflow.html#principled-questions-to-ask-on-a-model"><i class="fa fa-check"></i><b>F.2</b> Principled questions to ask on a model</a>
<ul>
<li class="chapter" data-level="F.2.1" data-path="ch-workflow.html"><a href="ch-workflow.html#checking-whether-assumptions-are-consistent-with-domain-expertise-prior-predictive-checks"><i class="fa fa-check"></i><b>F.2.1</b>  Checking whether assumptions are consistent with  domain expertise: Prior predictive checks</a></li>
<li class="chapter" data-level="F.2.2" data-path="ch-workflow.html"><a href="ch-workflow.html#testing-for-correct-posterior-approximations-checks-of-computational-faithfulness"><i class="fa fa-check"></i><b>F.2.2</b>  Testing for correct posterior approximations: Checks of computational faithfulness</a></li>
<li class="chapter" data-level="F.2.3" data-path="ch-workflow.html"><a href="ch-workflow.html#sensitivity-of-the-model"><i class="fa fa-check"></i><b>F.2.3</b>  Sensitivity of the model</a></li>
<li class="chapter" data-level="F.2.4" data-path="ch-workflow.html"><a href="ch-workflow.html#does-the-model-adequately-capture-the-dataposterior-predictive-checks"><i class="fa fa-check"></i><b>F.2.4</b>  Does the model adequately capture the data?–Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="F.3" data-path="ch-workflow.html"><a href="ch-workflow.html#further-reading-17"><i class="fa fa-check"></i><b>F.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>G</b> Exercises</a>
<ul>
<li class="chapter" data-level="G.1" data-path="exercises.html"><a href="exercises.html#sec-Foundationsexercises"><i class="fa fa-check"></i><b>G.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="G.1.1" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisespnormPart1"><i class="fa fa-check"></i><b>G.1.1</b> Practice using the <code>pnorm()</code> function–Part 1</a></li>
<li class="chapter" data-level="G.1.2" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisespnormPart2"><i class="fa fa-check"></i><b>G.1.2</b> Practice using the <code>pnorm()</code> function–Part 2</a></li>
<li class="chapter" data-level="G.1.3" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisespnormPart3"><i class="fa fa-check"></i><b>G.1.3</b> Practice using the <code>pnorm()</code> function–Part 3</a></li>
<li class="chapter" data-level="G.1.4" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisesqnormPart1"><i class="fa fa-check"></i><b>G.1.4</b> Practice using the <code>qnorm()</code> function–Part 1</a></li>
<li class="chapter" data-level="G.1.5" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisesqnormPart2"><i class="fa fa-check"></i><b>G.1.5</b> Practice using the <code>qnorm()</code> function–Part 2</a></li>
<li class="chapter" data-level="G.1.6" data-path="exercises.html"><a href="exercises.html#exr:Foundationsexercisessamples1"><i class="fa fa-check"></i><b>G.1.6</b> Practice getting summaries from samples–Part 1</a></li>
<li class="chapter" data-level="G.1.7" data-path="exercises.html"><a href="exercises.html#exr:Foundationsexercisessamples2"><i class="fa fa-check"></i><b>G.1.7</b> Practice getting summaries from samples–Part 2.</a></li>
<li class="chapter" data-level="G.1.8" data-path="exercises.html"><a href="exercises.html#exr:Foundationsexercisesvcov1"><i class="fa fa-check"></i><b>G.1.8</b> Practice with a variance-covariance matrix for a bivariate distribution.</a></li>
</ul></li>
<li class="chapter" data-level="G.2" data-path="exercises.html"><a href="exercises.html#sec-BDAexercises"><i class="fa fa-check"></i><b>G.2</b> Introduction to Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="G.2.1" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesDerivingBayes"><i class="fa fa-check"></i><b>G.2.1</b> Deriving Bayes’ rule</a></li>
<li class="chapter" data-level="G.2.2" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj1"><i class="fa fa-check"></i><b>G.2.2</b> Conjugate forms 1</a></li>
<li class="chapter" data-level="G.2.3" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj2"><i class="fa fa-check"></i><b>G.2.3</b> Conjugate forms 2</a></li>
<li class="chapter" data-level="G.2.4" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj3"><i class="fa fa-check"></i><b>G.2.4</b> Conjugate forms 3</a></li>
<li class="chapter" data-level="G.2.5" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj4"><i class="fa fa-check"></i><b>G.2.5</b> Conjugate forms 4</a></li>
<li class="chapter" data-level="G.2.6" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesWeightedMean"><i class="fa fa-check"></i><b>G.2.6</b> The posterior mean is a weighted mean of the prior mean and the MLE (Poisson-Gamma conjugate case)</a></li>
</ul></li>
<li class="chapter" data-level="G.3" data-path="exercises.html"><a href="exercises.html#ex:compbda"><i class="fa fa-check"></i><b>G.3</b> Computational Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="G.3.1" data-path="exercises.html"><a href="exercises.html#exr:simulatedlinearmod"><i class="fa fa-check"></i><b>G.3.1</b> Check for parameter recovery in a linear model using simulated data.</a></li>
<li class="chapter" data-level="G.3.2" data-path="exercises.html"><a href="exercises.html#exr:linearmod"><i class="fa fa-check"></i><b>G.3.2</b> A simple linear model.</a></li>
<li class="chapter" data-level="G.3.3" data-path="exercises.html"><a href="exercises.html#exr:compbda-biasedpost"><i class="fa fa-check"></i><b>G.3.3</b> Revisiting the button-pressing example with different priors.</a></li>
<li class="chapter" data-level="G.3.4" data-path="exercises.html"><a href="exercises.html#exr:ppd"><i class="fa fa-check"></i><b>G.3.4</b> Posterior predictive checks with a log-normal model.</a></li>
<li class="chapter" data-level="G.3.5" data-path="exercises.html"><a href="exercises.html#exr:skew"><i class="fa fa-check"></i><b>G.3.5</b> A skew normal distribution.</a></li>
</ul></li>
<li class="chapter" data-level="G.4" data-path="exercises.html"><a href="exercises.html#sec-LMexercises"><i class="fa fa-check"></i><b>G.4</b> Bayesian regression models</a>
<ul>
<li class="chapter" data-level="G.4.1" data-path="exercises.html"><a href="exercises.html#exr:powerposing"><i class="fa fa-check"></i><b>G.4.1</b> A simple linear regression: Power posing and testosterone.</a></li>
<li class="chapter" data-level="G.4.2" data-path="exercises.html"><a href="exercises.html#exr:pupils"><i class="fa fa-check"></i><b>G.4.2</b> Another linear regression model: Revisiting attentional load effect on pupil size.</a></li>
<li class="chapter" data-level="G.4.3" data-path="exercises.html"><a href="exercises.html#exr:lognormalm"><i class="fa fa-check"></i><b>G.4.3</b> Log-normal model: Revisiting the effect of trial on finger tapping times.</a></li>
<li class="chapter" data-level="G.4.4" data-path="exercises.html"><a href="exercises.html#exr:reg-logistic"><i class="fa fa-check"></i><b>G.4.4</b> Logistic regression: Revisiting the effect of set size on free recall.</a></li>
<li class="chapter" data-level="G.4.5" data-path="exercises.html"><a href="exercises.html#exr:red"><i class="fa fa-check"></i><b>G.4.5</b> Red is the sexiest color.</a></li>
</ul></li>
<li class="chapter" data-level="G.5" data-path="exercises.html"><a href="exercises.html#sec-HLMexercises"><i class="fa fa-check"></i><b>G.5</b> Bayesian hierarchical models</a>
<ul>
<li class="chapter" data-level="G.5.1" data-path="exercises.html"><a href="exercises.html#exr:hierarchical-normal"><i class="fa fa-check"></i><b>G.5.1</b> A hierarchical model (normal likelihood) of cognitive load on pupil size.</a></li>
<li class="chapter" data-level="G.5.2" data-path="exercises.html"><a href="exercises.html#exr:hierarchical-logn"><i class="fa fa-check"></i><b>G.5.2</b> Are subject relatives easier to process than object relatives (log-normal likelihood)?</a></li>
<li class="chapter" data-level="G.5.3" data-path="exercises.html"><a href="exercises.html#exr:HLMExerciseMandarinRC"><i class="fa fa-check"></i><b>G.5.3</b> Relative clause processing in Mandarin Chinese</a></li>
<li class="chapter" data-level="G.5.4" data-path="exercises.html"><a href="exercises.html#exr:HLMExerciseEnglishAgrmt"><i class="fa fa-check"></i><b>G.5.4</b>  Agreement attraction in comprehension</a></li>
<li class="chapter" data-level="G.5.5" data-path="exercises.html"><a href="exercises.html#exr:ab"><i class="fa fa-check"></i><b>G.5.5</b>  Attentional blink (Bernoulli likelihood)</a></li>
<li class="chapter" data-level="G.5.6" data-path="exercises.html"><a href="exercises.html#exr:strooplogis-brms"><i class="fa fa-check"></i><b>G.5.6</b> Is there a Stroop effect in accuracy?</a></li>
<li class="chapter" data-level="G.5.7" data-path="exercises.html"><a href="exercises.html#exr:stroop-dist"><i class="fa fa-check"></i><b>G.5.7</b>  Distributional regression for the Stroop effect.</a></li>
<li class="chapter" data-level="G.5.8" data-path="exercises.html"><a href="exercises.html#exr:HLMExerciseGramCE"><i class="fa fa-check"></i><b>G.5.8</b> The  grammaticality illusion</a></li>
</ul></li>
<li class="chapter" data-level="G.6" data-path="exercises.html"><a href="exercises.html#sec-Contrastsexercises"><i class="fa fa-check"></i><b>G.6</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="G.6.1" data-path="exercises.html"><a href="exercises.html#exr:ContrastsPersian"><i class="fa fa-check"></i><b>G.6.1</b> Contrast coding for a four-condition design</a></li>
<li class="chapter" data-level="G.6.2" data-path="exercises.html"><a href="exercises.html#exr:ContrastsNPIHelmert"><i class="fa fa-check"></i><b>G.6.2</b>  Helmert coding for a six-condition design.</a></li>
<li class="chapter" data-level="G.6.3" data-path="exercises.html"><a href="exercises.html#exr:ContrastsNcomparisons"><i class="fa fa-check"></i><b>G.6.3</b> Number of possible comparisons in a single model.</a></li>
</ul></li>
<li class="chapter" data-level="G.7" data-path="exercises.html"><a href="exercises.html#sec-Contrasts2x2exercises"><i class="fa fa-check"></i><b>G.7</b> Contrast coding with two predictor variables</a>
<ul>
<li class="chapter" data-level="G.7.1" data-path="exercises.html"><a href="exercises.html#exr:ContrastsPersianANOVA"><i class="fa fa-check"></i><b>G.7.1</b> ANOVA coding for a four-condition design.</a></li>
<li class="chapter" data-level="G.7.2" data-path="exercises.html"><a href="exercises.html#exr:Contrasts2x2x2Dillon2013"><i class="fa fa-check"></i><b>G.7.2</b> ANOVA and nested comparisons in a <span class="math inline">\(2\times 2\times 2\)</span> design</a></li>
</ul></li>
<li class="chapter" data-level="G.8" data-path="exercises.html"><a href="exercises.html#introduction-to-the-probabilistic-programming-language-stan"><i class="fa fa-check"></i><b>G.8</b> Introduction to the probabilistic programming language Stan</a>
<ul>
<li class="chapter" data-level="G.8.1" data-path="exercises.html"><a href="exercises.html#exr:first"><i class="fa fa-check"></i><b>G.8.1</b> A very simple model.</a></li>
<li class="chapter" data-level="G.8.2" data-path="exercises.html"><a href="exercises.html#exr:badstan"><i class="fa fa-check"></i><b>G.8.2</b> Incorrect Stan model.</a></li>
<li class="chapter" data-level="G.8.3" data-path="exercises.html"><a href="exercises.html#exr:skewstan"><i class="fa fa-check"></i><b>G.8.3</b> Using Stan documentation.</a></li>
<li class="chapter" data-level="G.8.4" data-path="exercises.html"><a href="exercises.html#exr:linkfunction"><i class="fa fa-check"></i><b>G.8.4</b> The probit link function as an alternative to the logit function.</a></li>
<li class="chapter" data-level="G.8.5" data-path="exercises.html"><a href="exercises.html#exr:logisticstan"><i class="fa fa-check"></i><b>G.8.5</b> Examining the position of the queued word on recall.</a></li>
<li class="chapter" data-level="G.8.6" data-path="exercises.html"><a href="exercises.html#exr:fallacy"><i class="fa fa-check"></i><b>G.8.6</b> The conjunction fallacy.</a></li>
</ul></li>
<li class="chapter" data-level="G.9" data-path="exercises.html"><a href="exercises.html#hierarchical-models-and-reparameterization"><i class="fa fa-check"></i><b>G.9</b> Hierarchical models and reparameterization</a>
<ul>
<li class="chapter" data-level="G.9.1" data-path="exercises.html"><a href="exercises.html#exr:stroop"><i class="fa fa-check"></i><b>G.9.1</b> A log-normal model in Stan.</a></li>
<li class="chapter" data-level="G.9.2" data-path="exercises.html"><a href="exercises.html#exr:hierarchical-logn-stan"><i class="fa fa-check"></i><b>G.9.2</b> A by-subjects and by-items hierarchical model with a log-normal likelihood.</a></li>
<li class="chapter" data-level="G.9.3" data-path="exercises.html"><a href="exercises.html#exr:strooplogis"><i class="fa fa-check"></i><b>G.9.3</b> A hierarchical logistic regression with Stan.</a></li>
<li class="chapter" data-level="G.9.4" data-path="exercises.html"><a href="exercises.html#exr:distr-stan"><i class="fa fa-check"></i><b>G.9.4</b> A distributional regression model of the effect of cloze probability on the N400.</a></li>
</ul></li>
<li class="chapter" data-level="G.10" data-path="exercises.html"><a href="exercises.html#sec-customexercises"><i class="fa fa-check"></i><b>G.10</b> Custom distributions in Stan</a>
<ul>
<li class="chapter" data-level="G.10.1" data-path="exercises.html"><a href="exercises.html#exr:shiftedlogn"><i class="fa fa-check"></i><b>G.10.1</b> Fitting a  shifted log-normal distribution.</a></li>
<li class="chapter" data-level="G.10.2" data-path="exercises.html"><a href="exercises.html#exr:wald"><i class="fa fa-check"></i><b>G.10.2</b> Fitting a Wald distribution.</a></li>
</ul></li>
<li class="chapter" data-level="G.11" data-path="exercises.html"><a href="exercises.html#sec-REMAMEexercises"><i class="fa fa-check"></i><b>G.11</b> Meta-analysis and measurement error models</a>
<ul>
<li class="chapter" data-level="G.11.1" data-path="exercises.html"><a href="exercises.html#exr:REMAMEExtracting"><i class="fa fa-check"></i><b>G.11.1</b> Extracting estimates from published papers</a></li>
<li class="chapter" data-level="G.11.2" data-path="exercises.html"><a href="exercises.html#exr:REMAMEBuerki"><i class="fa fa-check"></i><b>G.11.2</b> A meta-analysis of picture-word interference data</a></li>
<li class="chapter" data-level="G.11.3" data-path="exercises.html"><a href="exercises.html#exr:REMAMELiEnglish"><i class="fa fa-check"></i><b>G.11.3</b> Measurement error model for English VOT data</a></li>
</ul></li>
<li class="chapter" data-level="G.12" data-path="exercises.html"><a href="exercises.html#introduction-to-model-comparison"><i class="fa fa-check"></i><b>G.12</b> Introduction to model comparison</a></li>
<li class="chapter" data-level="G.13" data-path="exercises.html"><a href="exercises.html#bayes-factors"><i class="fa fa-check"></i><b>G.13</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="G.13.1" data-path="exercises.html"><a href="exercises.html#exr:bysubjects"><i class="fa fa-check"></i><b>G.13.1</b> Is there evidence for differences in the effect of cloze probability among the subjects?</a></li>
<li class="chapter" data-level="G.13.2" data-path="exercises.html"><a href="exercises.html#exr:bf-logn"><i class="fa fa-check"></i><b>G.13.2</b> Is there evidence for the claim that English subject relative clauses are easier to process than object relative clauses?</a></li>
<li class="chapter" data-level="G.13.3" data-path="exercises.html"><a href="exercises.html#exr:bf-logistic"><i class="fa fa-check"></i><b>G.13.3</b> In the Grodner and Gibson 2005 data, in question-response accuracies, is there evidence for the claim that sentences with subject relative clauses are easier to comprehend?</a></li>
<li class="chapter" data-level="G.13.4" data-path="exercises.html"><a href="exercises.html#exr:lognstan"><i class="fa fa-check"></i><b>G.13.4</b> Bayes factor and bounded parameters using Stan.</a></li>
</ul></li>
<li class="chapter" data-level="G.14" data-path="exercises.html"><a href="exercises.html#cross-validation"><i class="fa fa-check"></i><b>G.14</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="G.14.1" data-path="exercises.html"><a href="exercises.html#exr:logcv"><i class="fa fa-check"></i><b>G.14.1</b> Predictive accuracy of the linear and the logarithm effect of cloze probability.</a></li>
<li class="chapter" data-level="G.14.2" data-path="exercises.html"><a href="exercises.html#exr:stroopcv"><i class="fa fa-check"></i><b>G.14.2</b> Log-normal model</a></li>
<li class="chapter" data-level="G.14.3" data-path="exercises.html"><a href="exercises.html#exr:logrec"><i class="fa fa-check"></i><b>G.14.3</b> Log-normal vs rec-normal model in Stan</a></li>
</ul></li>
<li class="chapter" data-level="G.15" data-path="exercises.html"><a href="exercises.html#introduction-to-cognitive-modeling"><i class="fa fa-check"></i><b>G.15</b> Introduction to cognitive modeling</a></li>
<li class="chapter" data-level="G.16" data-path="exercises.html"><a href="exercises.html#multinomial-processing-trees"><i class="fa fa-check"></i><b>G.16</b> Multinomial processing trees</a>
<ul>
<li class="chapter" data-level="G.16.1" data-path="exercises.html"><a href="exercises.html#exr:mult"><i class="fa fa-check"></i><b>G.16.1</b> Modeling multiple categorical responses.</a></li>
<li class="chapter" data-level="G.16.2" data-path="exercises.html"><a href="exercises.html#exr:mpt-mnm"><i class="fa fa-check"></i><b>G.16.2</b> An alternative MPT to model the picture recognition task.</a></li>
<li class="chapter" data-level="G.16.3" data-path="exercises.html"><a href="exercises.html#exr:edit-mpt-cat"><i class="fa fa-check"></i><b>G.16.3</b> A simple MPT model that incorporates phonological complexity in the picture recognition task.</a></li>
<li class="chapter" data-level="G.16.4" data-path="exercises.html"><a href="exercises.html#exr:mpt"><i class="fa fa-check"></i><b>G.16.4</b> A more hierarchical MPT.</a></li>
<li class="chapter" data-level="G.16.5" data-path="exercises.html"><a href="exercises.html#exr:mpt-adv"><i class="fa fa-check"></i><b>G.16.5</b> <strong>Advanced</strong>: Multinomial processing trees.</a></li>
</ul></li>
<li class="chapter" data-level="G.17" data-path="exercises.html"><a href="exercises.html#mixture-models"><i class="fa fa-check"></i><b>G.17</b> Mixture models</a>
<ul>
<li class="chapter" data-level="G.17.1" data-path="exercises.html"><a href="exercises.html#exr:pcorrect"><i class="fa fa-check"></i><b>G.17.1</b> Changes in the true point values.</a></li>
<li class="chapter" data-level="G.17.2" data-path="exercises.html"><a href="exercises.html#exr:mixhier"><i class="fa fa-check"></i><b>G.17.2</b> RTs in schizophrenic patients and control.</a></li>
<li class="chapter" data-level="G.17.3" data-path="exercises.html"><a href="exercises.html#exr:mixbias"><i class="fa fa-check"></i><b>G.17.3</b> <strong>Advanced:</strong> Guessing bias in the model.</a></li>
</ul></li>
<li class="chapter" data-level="G.18" data-path="exercises.html"><a href="exercises.html#a-simple-accumulator-model-to-account-for-choice-response-time"><i class="fa fa-check"></i><b>G.18</b> A simple accumulator model to account for choice response time</a>
<ul>
<li class="chapter" data-level="G.18.1" data-path="exercises.html"><a href="exercises.html#exr:recovery"><i class="fa fa-check"></i><b>G.18.1</b> Can we recover the true point values of the parameters of a model when dealing with a contaminant distribution?</a></li>
<li class="chapter" data-level="G.18.2" data-path="exercises.html"><a href="exercises.html#exr:lnracescale"><i class="fa fa-check"></i><b>G.18.2</b> Can the log-normal race model account for fast errors?</a></li>
<li class="chapter" data-level="G.18.3" data-path="exercises.html"><a href="exercises.html#exr:lnldt"><i class="fa fa-check"></i><b>G.18.3</b> Accounting for response time and choice in the lexical decision task using the log-normal race model.</a></li>
</ul></li>
<li class="chapter" data-level="G.19" data-path="exercises.html"><a href="exercises.html#sec-priorsexercises"><i class="fa fa-check"></i><b>G.19</b> The Art and Science of  Prior Elicitation</a>
<ul>
<li class="chapter" data-level="G.19.1" data-path="exercises.html"><a href="exercises.html#exr:PriorsRCs"><i class="fa fa-check"></i><b>G.19.1</b> Develop a plausible informative prior for the difference between object and subject relative clause reading times</a></li>
<li class="chapter" data-level="G.19.2" data-path="exercises.html"><a href="exercises.html#exr:Priorslocalcoherence"><i class="fa fa-check"></i><b>G.19.2</b> Extracting an informative prior from a published paper for a future study</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-remame" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span>  Meta-analysis and  measurement error models<a href="ch-remame.html#ch-remame" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter, we introduce two relatively underutilized modeling approaches that are potentially very important for cognitive science: meta-analysis and measurement-error models.</p>
<p>Meta-analysis can be very informative when carrying out systematic reviews, and measurement-error models are able to take into account uncertainty in one’s dependent or independent variable (or both). What’s common to these two classes of model is that they both assume that the <span class="math inline">\(n\)</span>-th measured data point <span class="math inline">\(y_n\)</span> has a location parameter, say <span class="math inline">\(\zeta_n\)</span> (pronounced <em>zeta en</em>), that is measured with some uncertainty that can be represented by the standard error <span class="math inline">\(SE_n\)</span> of the measurement <span class="math inline">\(y_n\)</span>:</p>
<p><span class="math inline">\(y_n \sim \mathit{Normal}(\zeta_n,SE_n)\)</span></p>
<p>In both classes of model, the goal is to obtain a posterior distribution of a latent parameter <span class="math inline">\(\zeta\)</span> which is assumed to generate the <span class="math inline">\(\zeta_n\)</span>, with some standard deviation <span class="math inline">\(\tau\)</span>. The parameter <span class="math inline">\(\tau\)</span> quantifies the noise in the measurement process or the between-study variability in a meta-analysis.</p>
<p><span class="math inline">\(\zeta_n \sim \mathit{Normal}(\zeta,\tau)\)</span></p>
<p>The main parameter of interest is usually <span class="math inline">\(\zeta\)</span>, but the posterior distributions of <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\zeta_n\)</span> can also be informative. The above model specification should remind you of the hierarchical models we saw in earlier chapters.</p>
<div id="meta-analysis" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Meta-analysis<a href="ch-remame.html#meta-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Once a number of studies have accumulated on a particular topic, it can be very informative to synthesize the data. Here is a commonly used approach–a random-effects meta-analysis.</p>
<div id="a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> A meta-analysis of similarity-based interference in sentence comprehension<a href="ch-remame.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The model is set up as follows. For each study <span class="math inline">\(n\)</span>, let effect<span class="math inline">\(_n\)</span> be the effect of interest, and let <span class="math inline">\(SE_n\)</span> be the  standard error of the effect. A concrete example of a recent meta-analysis is the effect of  similarity-based interference in sentence comprehension <span class="citation">(Jäger, Engelmann, and Vasishth <a href="#ref-JaegerEngelmannVasishth2017" role="doc-biblioref">2017</a>)</span>; when two nouns are more similar to each other, there is greater processing difficulty (i.e., longer  reading times in milliseconds) when an attempt is made to retrieve one of the nouns to complete a linguistic dependency (such as a subject-verb dependency). The estimate of the effect and its standard error is the information we have from each study <span class="math inline">\(n\)</span>.</p>
<p>First, load the data, and add an id variable that identifies each experiment.</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb674-1"><a href="ch-remame.html#cb674-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_sbi&quot;</span>)</span>
<span id="cb674-2"><a href="ch-remame.html#cb674-2" aria-hidden="true"></a>(df_sbi &lt;-<span class="st"> </span>df_sbi <span class="op">%&gt;%</span></span>
<span id="cb674-3"><a href="ch-remame.html#cb674-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">study_id =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()))</span></code></pre></div>
<pre><code>## # A tibble: 12 × 4
##   publication      effect    SE study_id
##   &lt;chr&gt;             &lt;int&gt; &lt;int&gt;    &lt;int&gt;
## 1 VanDyke07E1LoSem     13    30        1
## 2 VanDyke07E2LoSem     37    21        2
## 3 VanDyke07E3LoSem     20    11        3
## # ℹ 9 more rows</code></pre>
<p>The effect size and standard errors were estimated from published summary statistics in the respective article. In some cases, this involved a certain amount of guesswork; the details are documented in the online material accompanying <span class="citation">Jäger, Engelmann, and Vasishth (<a href="#ref-JaegerEngelmannVasishth2017" role="doc-biblioref">2017</a>)</span>.</p>
<p>We begin with the assumption that there is a true (unknown) effect <span class="math inline">\(\zeta_n\)</span> that lies behind each of these studies. Each of the observed effects has an uncertainty associated with it, <span class="math inline">\(SE_n\)</span>. We can therefore assume that each observed effect, effect<span class="math inline">\(_n\)</span>, is generated as follows:</p>
<p><span class="math display">\[\begin{equation}
\text{effect}_n \sim \mathit{Normal}(\zeta_n,SE_n)
\end{equation}\]</span></p>
<p>Each study is assumed to have a different true effect <span class="math inline">\(\zeta_n\)</span> because each study will have been carried out under different conditions: in a different lab with different protocols and workflows, with different subjects, possibly with different languages, with slightly different experimental designs, etc.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a></p>
<p>Further, each of the true underlying effects <span class="math inline">\(\zeta_n\)</span> has behind it some true unknown value <span class="math inline">\(\zeta\)</span>. The parameter <span class="math inline">\(\zeta\)</span> represents the underlying effect of similarity-based interference across experiments. Our goal is to obtain the posterior distribution of this overall effect.</p>
<p>We can write the above statement as follows:</p>
<p><span class="math display">\[\begin{equation}
\zeta_n \sim\mathit{Normal}(\zeta,\tau)
\end{equation}\]</span></p>
<p><span class="math inline">\(\tau\)</span> is the between-study standard deviation; this expresses the assumption that there will be some variability between the true effects <span class="math inline">\(\zeta_n\)</span>.</p>
<p>To summarize the model:</p>
<ul>
<li>effect<span class="math inline">\(_n\)</span> is the observed effect (in this example, in milliseconds) in the <span class="math inline">\(n\)</span>-th study.</li>
<li><span class="math inline">\(\zeta_n\)</span> is the true (unknown) effect in each study.</li>
<li><span class="math inline">\(\zeta\)</span> is the true (unknown) effect of the experimental manipulation, namely, the similarity-based interference effect.</li>
<li>Each <span class="math inline">\(SE_n\)</span> is estimated from the standard error available from study <span class="math inline">\(n\)</span>.</li>
<li>The parameter <span class="math inline">\(\tau\)</span> represents  between-study standard deviation.</li>
</ul>
<p>We can construct a  hierarchical model as follows:</p>
<p><span class="math display" id="eq:ma0">\[\begin{equation}
\begin{aligned}
\text{effect}_n \sim &amp; \mathit{Normal}(\zeta_n, SE_n) \quad n=1,\dots, N_{studies}\\
\zeta_n \sim &amp; \mathit{Normal}(\zeta, \tau) \\
\zeta \sim &amp; \mathit{Normal}(0,100)\\
 \tau \sim &amp; \mathit{Normal}_+(0,100)
\end{aligned}
\tag{11.1}
\end{equation}\]</span></p>
<p>The priors are based on domain knowledge; it seems reasonable to allow the effect to range a priori from <span class="math inline">\(-200\)</span> to <span class="math inline">\(+200\)</span> ms with probability <span class="math inline">\(95\)</span>%. Of course, a sensitivity analysis is necessary (but skipped here).</p>
<p>This model can be implemented in  <code>brms</code> in a relatively straightforward way as shown below. We show the Stan version later in the chapter (section <a href="ch-remame.html#sec-stanma">11.1.1.2</a>); the Stan version presents some interesting challenges that can be useful for the reader interested in deepening their Stan modeling knowledge.</p>
<div id="sec-brmsmeta" class="section level4 hasAnchor" number="11.1.1.1">
<h4><span class="header-section-number">11.1.1.1</span> <code>brms</code> version of the meta-analysis model<a href="ch-remame.html#sec-brmsmeta" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>First, define the priors:</p>
<div class="sourceCode" id="cb676"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb676-1"><a href="ch-remame.html#cb676-1" aria-hidden="true"></a>priors &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb676-2"><a href="ch-remame.html#cb676-2" aria-hidden="true"></a>            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> sd))</span></code></pre></div>
<p>Fit the model as follows. Because of our relatively uninformative priors and the few data points, the models of this chapter require us to tune the <code>control</code> parameter, increasing  <code>adapt_delta</code> and  <code>max_treedepth</code>.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb677-1"><a href="ch-remame.html#cb677-1" aria-hidden="true"></a>fit_sbi &lt;-<span class="st"> </span><span class="kw">brm</span>(effect <span class="op">|</span><span class="st"> </span><span class="kw">resp_se</span>(<span class="st">`</span><span class="dt">SE</span><span class="st">`</span>, <span class="dt">sigma =</span> <span class="ot">FALSE</span>) <span class="op">~</span></span>
<span id="cb677-2"><a href="ch-remame.html#cb677-2" aria-hidden="true"></a><span class="st">                 </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>study_id),</span>
<span id="cb677-3"><a href="ch-remame.html#cb677-3" aria-hidden="true"></a>               <span class="dt">data =</span> df_sbi,</span>
<span id="cb677-4"><a href="ch-remame.html#cb677-4" aria-hidden="true"></a>               <span class="dt">prior =</span> priors,</span>
<span id="cb677-5"><a href="ch-remame.html#cb677-5" aria-hidden="true"></a>               <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>, <span class="dt">max_treedepth =</span> <span class="dv">10</span>))</span></code></pre></div>
<p>The posterior of <span class="math inline">\(\zeta\)</span> and <span class="math inline">\(\tau\)</span> are summarized below as <code>Intercept</code> and <code>sd(Intercept)</code>.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb678-1"><a href="ch-remame.html#cb678-1" aria-hidden="true"></a>fit_sbi</span></code></pre></div>
<pre><code>## ...
## Group-Level Effects: 
## ~study_id (Number of levels: 12) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)    11.51      7.68     0.52    29.52 1.00      860
##               Tail_ESS
## sd(Intercept)     1474
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    13.27      6.23     2.62    27.09 1.00     1105      966
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.00      0.00     0.00     0.00   NA       NA       NA
## 
## ...</code></pre>
<p>The <code>sigma</code> parameter does not play any role in this model, but appears in the <code>brms</code> output anyway. In the model specification, <code>sigma</code> was explicitly removed by writing <code>sigma = FALSE</code>. For this reason, we can ignore that parameter in the model summary output above. Online section <a href="evidence-synthesis-and-measurements-with-error---extended.html#app-sigmatrue">C.1</a> explains what happens if we set <code>sigma = TRUE</code>.</p>
<p>As theory predicts, the overall effect from these studies has a positive sign.</p>
<p>One advantage of such a meta-analysis is that the posterior can now be used as an informative prior for a future study. This is especially important when doing an analysis using Bayes factors. But this meta-analysis posterior could also be used as an informative prior in a future experiment; that would allow the researcher to build on what is known so far from published studies.</p>
<p>Another interesting by-product of a random-effects meta-analysis is the possibility of displaying a  forest plot (Figure <a href="ch-remame.html#fig:forest">11.1</a>). A forest plot shows the meta-analytic estimate (the parameter <code>b_Intercept</code> in <code>brms</code>) alongside the original estimates effect<span class="math inline">\(_n\)</span> (and their SE<span class="math inline">\(_n\)</span>) and the posterior distributions of the <span class="math inline">\(\zeta_n\)</span> for each study (we reconstruct these estimates by adding <code>b_Intercept</code> to the parameters starting with <code>r_</code> in <code>brms</code>). The original estimates are the ones fed to the model as data and the posterior distributions of the <span class="math inline">\(\zeta_n\)</span> are calculated, as in previous hierarchical models, after the information from all studies is pooled together. The <span class="math inline">\(\zeta_n\)</span> estimates are shrunken estimates of each study’s (unknown) true effect, shrunken towards the grand mean <span class="math inline">\(\zeta\)</span>, and weighted by the standard error observed in each study <span class="math inline">\(n\)</span>. The <span class="math inline">\(\zeta_n\)</span> for a particular study is shrunk more towards the grand mean <span class="math inline">\(\zeta\)</span> when the study’s standard error is large (i.e., when the estimate is very imprecise). The code below shows how to build a forest plot step by step.</p>
<p>First, change the format of the data so that it looks like the output of <code>brms</code>:</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb680-1"><a href="ch-remame.html#cb680-1" aria-hidden="true"></a>df_sbi &lt;-<span class="st"> </span>df_sbi <span class="op">%&gt;%</span></span>
<span id="cb680-2"><a href="ch-remame.html#cb680-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Q2.5 =</span> effect <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>SE,</span>
<span id="cb680-3"><a href="ch-remame.html#cb680-3" aria-hidden="true"></a>         <span class="dt">Q97.5 =</span> effect <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>SE,</span>
<span id="cb680-4"><a href="ch-remame.html#cb680-4" aria-hidden="true"></a>         <span class="dt">Estimate =</span> effect,</span>
<span id="cb680-5"><a href="ch-remame.html#cb680-5" aria-hidden="true"></a>         <span class="dt">type =</span> <span class="st">&quot;original&quot;</span>)</span></code></pre></div>
<p>Extract the meta-analytical estimate:</p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb681-1"><a href="ch-remame.html#cb681-1" aria-hidden="true"></a>df_Intercept &lt;-<span class="st"> </span><span class="kw">posterior_summary</span>(fit_sbi,</span>
<span id="cb681-2"><a href="ch-remame.html#cb681-2" aria-hidden="true"></a>                                  <span class="dt">variable =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb681-3"><a href="ch-remame.html#cb681-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb681-4"><a href="ch-remame.html#cb681-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">publication =</span> <span class="st">&quot;M.A. estimate&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p>For the pooled estimated effect (or fitted value) of the individual studies, we need the sum of the meta-analytical estimate (intercept) and each of the by-study adjustment. Obtain this with the <code>fitted()</code> function:</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb682-1"><a href="ch-remame.html#cb682-1" aria-hidden="true"></a>df_model &lt;-<span class="st"> </span><span class="kw">fitted</span>(fit_sbi) <span class="op">%&gt;%</span></span>
<span id="cb682-2"><a href="ch-remame.html#cb682-2" aria-hidden="true"></a><span class="st">  </span><span class="co"># Convert matrix to data frame:</span></span>
<span id="cb682-3"><a href="ch-remame.html#cb682-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb682-4"><a href="ch-remame.html#cb682-4" aria-hidden="true"></a><span class="st">  </span><span class="co"># Add a column to identify the estimates,</span></span>
<span id="cb682-5"><a href="ch-remame.html#cb682-5" aria-hidden="true"></a><span class="st">  </span><span class="co"># and another column to identify the publication:</span></span>
<span id="cb682-6"><a href="ch-remame.html#cb682-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">type =</span> <span class="st">&quot;adjusted&quot;</span>,</span>
<span id="cb682-7"><a href="ch-remame.html#cb682-7" aria-hidden="true"></a>         <span class="dt">publication =</span> df_sbi<span class="op">$</span>publication)</span></code></pre></div>
<p>Bind the observed effects, the meta-analytical estimate, and the fitted values of the studies together, and plot the data:</p>

<div class="sourceCode" id="cb683"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb683-1"><a href="ch-remame.html#cb683-1" aria-hidden="true"></a><span class="co"># the adjusted estimates and the meta-analysis estimate:</span></span>
<span id="cb683-2"><a href="ch-remame.html#cb683-2" aria-hidden="true"></a><span class="kw">bind_rows</span>(df_sbi, df_model, df_Intercept) <span class="op">%&gt;%</span></span>
<span id="cb683-3"><a href="ch-remame.html#cb683-3" aria-hidden="true"></a><span class="st">  </span><span class="co"># Plot:</span></span>
<span id="cb683-4"><a href="ch-remame.html#cb683-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Estimate,</span>
<span id="cb683-5"><a href="ch-remame.html#cb683-5" aria-hidden="true"></a>             <span class="dt">y =</span> publication,</span>
<span id="cb683-6"><a href="ch-remame.html#cb683-6" aria-hidden="true"></a>             <span class="dt">xmin =</span> Q2<span class="fl">.5</span>,</span>
<span id="cb683-7"><a href="ch-remame.html#cb683-7" aria-hidden="true"></a>             <span class="dt">xmax =</span> Q97<span class="fl">.5</span>,</span>
<span id="cb683-8"><a href="ch-remame.html#cb683-8" aria-hidden="true"></a>             <span class="dt">color =</span> type)) <span class="op">+</span></span>
<span id="cb683-9"><a href="ch-remame.html#cb683-9" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">position =</span> <span class="kw">position_dodge</span>(.<span class="dv">5</span>)) <span class="op">+</span></span>
<span id="cb683-10"><a href="ch-remame.html#cb683-10" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_errorbarh</span>(<span class="dt">position =</span> <span class="kw">position_dodge</span>(.<span class="dv">5</span>)) <span class="op">+</span></span>
<span id="cb683-11"><a href="ch-remame.html#cb683-11" aria-hidden="true"></a><span class="st">  </span><span class="co"># Add the meta-analytic estimate and Credible Interval:</span></span>
<span id="cb683-12"><a href="ch-remame.html#cb683-12" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> df_Intercept<span class="op">$</span>Q2<span class="fl">.5</span>,</span>
<span id="cb683-13"><a href="ch-remame.html#cb683-13" aria-hidden="true"></a>             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</span>
<span id="cb683-14"><a href="ch-remame.html#cb683-14" aria-hidden="true"></a>             <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb683-15"><a href="ch-remame.html#cb683-15" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> df_Intercept<span class="op">$</span>Q97<span class="fl">.5</span>,</span>
<span id="cb683-16"><a href="ch-remame.html#cb683-16" aria-hidden="true"></a>             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</span>
<span id="cb683-17"><a href="ch-remame.html#cb683-17" aria-hidden="true"></a>             <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb683-18"><a href="ch-remame.html#cb683-18" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> df_Intercept<span class="op">$</span>Estimate,</span>
<span id="cb683-19"><a href="ch-remame.html#cb683-19" aria-hidden="true"></a>             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</span>
<span id="cb683-20"><a href="ch-remame.html#cb683-20" aria-hidden="true"></a>             <span class="dt">alpha =</span> <span class="fl">.5</span>) <span class="op">+</span></span>
<span id="cb683-21"><a href="ch-remame.html#cb683-21" aria-hidden="true"></a><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="st">&quot;adjusted&quot;</span>, <span class="st">&quot;original&quot;</span>))</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:forest"></span>
<img src="bayescogsci_files/figure-html/forest-1.svg" alt="Forest plot showing the original and the adjusted estimates computed from each study from the random-effects meta-analysis. The error bars on the original estimates show 95% confidence intervals, and those on the adjusted estimates show 95% credible intervals." width="672" />
<p class="caption">
FIGURE 11.1: Forest plot showing the original and the adjusted estimates computed from each study from the random-effects meta-analysis. The error bars on the original estimates show 95% confidence intervals, and those on the adjusted estimates show 95% credible intervals.
</p>
</div>
<p>It is important to keep in mind that a meta-analysis is always going to yield  biased estimates as long as we have  publication bias: if a field has a tendency to allow only “big news” studies to be published, then the literature that will appear in the public domain will be biased, and any meta-analysis based on such information will be biased. Despite this limitation, a meta-analysis is still a useful way to synthesize the known evidence; one just has to remember that the estimate from the meta-analysis is almost certain to be biased.</p>
</div>
<div id="sec-stanma" class="section level4 hasAnchor" number="11.1.1.2">
<h4><span class="header-section-number">11.1.1.2</span> Stan version of the meta-analysis model<a href="ch-remame.html#sec-stanma" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Even though <code>brms</code> can handle meta-analyses, fitting them in Stan allows us for more flexibility, which might be necessary in some cases. As a first attempt we could build a model that closely follows the formal specification given in Equation <a href="ch-remame.html#eq:ma0">(11.1)</a>.</p>
<pre class="stan fold-show"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] effect;
  vector[N] SE;
  vector[N] study_id;
}
parameters {
  real zeta;
  real&lt;lower = 0&gt; tau;
  vector[N] zeta_n;
}
model {
  target += normal_lpdf(effect| zeta_n, SE);
  target += normal_lpdf(zeta_n | zeta, tau);
  target += normal_lpdf(zeta | 0, 100);
  target += normal_lpdf(tau | 0, 100)
    - normal_lccdf(0 | 0, 100);
}</code></pre>
<p>Fit the model as follows:</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb685-1"><a href="ch-remame.html#cb685-1" aria-hidden="true"></a>ma0 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb685-2"><a href="ch-remame.html#cb685-2" aria-hidden="true"></a>                   <span class="st">&quot;meta-analysis0.stan&quot;</span>,</span>
<span id="cb685-3"><a href="ch-remame.html#cb685-3" aria-hidden="true"></a>                   <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb685-4"><a href="ch-remame.html#cb685-4" aria-hidden="true"></a>ls_sbi &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">nrow</span>(df_sbi),</span>
<span id="cb685-5"><a href="ch-remame.html#cb685-5" aria-hidden="true"></a>               <span class="dt">effect =</span> df_sbi<span class="op">$</span>effect,</span>
<span id="cb685-6"><a href="ch-remame.html#cb685-6" aria-hidden="true"></a>               <span class="dt">SE =</span> df_sbi<span class="op">$</span>SE,</span>
<span id="cb685-7"><a href="ch-remame.html#cb685-7" aria-hidden="true"></a>               <span class="dt">study_id =</span> df_sbi<span class="op">$</span>study_id)</span>
<span id="cb685-8"><a href="ch-remame.html#cb685-8" aria-hidden="true"></a>fit_sbi0 &lt;-<span class="st"> </span><span class="kw">stan</span>(ma0,</span>
<span id="cb685-9"><a href="ch-remame.html#cb685-9" aria-hidden="true"></a>                 <span class="dt">data =</span> ls_sbi,</span>
<span id="cb685-10"><a href="ch-remame.html#cb685-10" aria-hidden="true"></a>                 <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.999</span>, <span class="dt">max_treedepth =</span> <span class="dv">12</span>))</span></code></pre></div>
<pre><code> ## Warning: There were 3 divergent transitions after
 ## warmup. See
 ## https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
 ## to find out why this is a problem and how to eliminate
 ## them. </code></pre>
<pre><code> ## Warning: There were 1 chains where the estimated
 ## Bayesian Fraction of Missing Information was low. See
 ## https://mc-stan.org/misc/warnings.html#bfmi-low </code></pre>
<pre><code> ## Warning: Examine the pairs() plot to diagnose sampling
 ## problems </code></pre>
<pre><code> ## Warning: Bulk Effective Samples Size (ESS) is too low,
 ## indicating posterior means and medians may be unreliable.
 ## Running the chains for more iterations may help. See
 ## https://mc-stan.org/misc/warnings.html#bulk-ess </code></pre>
<pre><code> ## Warning: Tail Effective Samples Size (ESS) is too low,
 ## indicating posterior variances and tail quantiles may be
 ## unreliable. Running the chains for more iterations may
 ## help. See
 ## https://mc-stan.org/misc/warnings.html#tail-ess </code></pre>
<p>We see that there are warnings. As discussed in section <a href="ch-complexstan.html#sec-uncorrstan">9.1.2</a>, we can use pairs plots to uncover pathologies in the sampling. Here we see the samples of <code>zeta</code> and <code>tau</code> are highly correlated:</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb691-1"><a href="ch-remame.html#cb691-1" aria-hidden="true"></a><span class="kw">pairs</span>(fit_sbi0, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;zeta&quot;</span>, <span class="st">&quot;tau&quot;</span>))</span></code></pre></div>
<p><img src="bayescogsci_files/figure-html/unnamed-chunk-372-1.svg" width="672" /></p>
<p>We face a similar problem as we faced in section <a href="ch-complexstan.html#sec-uncorrstan">9.1.2</a>, namely, the sampler cannot properly explore the neck of the funnel-shaped space, because of the strong correlation between the parameters. The solution is, as in section <a href="ch-complexstan.html#sec-uncorrstan">9.1.2</a>, a non-centered parameterization. Re-write Equation <a href="ch-remame.html#eq:ma0">(11.1)</a> as follows:</p>
<p><span class="math display" id="eq:ma1">\[\begin{equation}
\begin{aligned}
z_n &amp; \sim \mathit{Normal}(0, 1)\\
\zeta_n &amp;= z_n \cdot \tau + \zeta \\
\text{effect}_n &amp; \sim  \mathit{Normal}(\zeta_n, SE_n)\\
\zeta &amp;\sim \mathit{Normal}(0,100)\\
\tau &amp;\sim  \mathit{Normal}_+(0,100)
\end{aligned}
\tag{11.2}
\end{equation}\]</span></p>
<p>This works because if <span class="math inline">\(X \sim\mathit{Normal}(a, b)\)</span> and <span class="math inline">\(Y \sim \mathit{Normal}(0, 1)\)</span>, then <span class="math inline">\(X = a + Y \cdot b\)</span>. You can re-visit section <a href="ch-complexstan.html#sec-uncorrstan">9.1.2</a> for more details.</p>
<p>Translate Equation <a href="ch-remame.html#eq:ma1">(11.2)</a> into Stan code as follows in <code>meta-analysis1.stan</code>:</p>
<pre class="stan fold-show"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] effect;
  vector[N] SE;
  vector[N] study_id;
}
parameters {
  real zeta;
  real&lt;lower = 0&gt; tau;
  vector[N] z;
}
transformed parameters {
  vector[N] zeta_n = z * tau + zeta;
}
model {
  target += normal_lpdf(effect| zeta_n, SE);
  target += std_normal_lpdf(z);
  target += normal_lpdf(zeta | 0, 100);
  target += normal_lpdf(tau | 0, 100)
    - normal_lccdf(0 | 0, 100);
}</code></pre>
<p>The model converges with values virtually identical to the ones of the <code>brms</code> model.</p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb693-1"><a href="ch-remame.html#cb693-1" aria-hidden="true"></a>ma1 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb693-2"><a href="ch-remame.html#cb693-2" aria-hidden="true"></a>                   <span class="st">&quot;meta-analysis1.stan&quot;</span>,</span>
<span id="cb693-3"><a href="ch-remame.html#cb693-3" aria-hidden="true"></a>                   <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb693-4"><a href="ch-remame.html#cb693-4" aria-hidden="true"></a>fit_sbi1 &lt;-<span class="st"> </span><span class="kw">stan</span>(ma1,</span>
<span id="cb693-5"><a href="ch-remame.html#cb693-5" aria-hidden="true"></a>                 <span class="dt">data =</span> ls_sbi,</span>
<span id="cb693-6"><a href="ch-remame.html#cb693-6" aria-hidden="true"></a>                 <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.999</span>,</span>
<span id="cb693-7"><a href="ch-remame.html#cb693-7" aria-hidden="true"></a>                                <span class="dt">max_treedepth =</span> <span class="dv">12</span>))</span></code></pre></div>
<div class="sourceCode" id="cb694"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb694-1"><a href="ch-remame.html#cb694-1" aria-hidden="true"></a><span class="kw">print</span>(fit_sbi1, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;zeta&quot;</span>, <span class="st">&quot;tau&quot;</span>))</span></code></pre></div>
<pre><code>##      mean 2.5% 97.5% n_eff Rhat
## zeta 13.4 2.71  28.3   739    1
## tau  11.6 0.55  30.2   729    1</code></pre>
<p>We can also reparameterize the model slightly differently, if we set <span class="math inline">\(U_{n} \sim\mathit{Normal}(0 , SE_n)\)</span> then,</p>
<p><span class="math display">\[\begin{equation}
\text{effect}_n =  U_n + \zeta_n
\end{equation}\]</span></p>
<p>Then, given that <span class="math inline">\(\zeta_n \sim \mathit{Normal}(\zeta, \tau)\)</span>,</p>
<p><span class="math display" id="eq:ma2-again2">\[\begin{equation}
\text{effect}_n \sim \mathit{Normal}(\zeta, \sqrt{SE^2 + \tau^2}) \tag{11.3}
\end{equation}\]</span></p>
<p>See online section <a href="evidence-synthesis-and-measurements-with-error---extended.html#app-sigmatrue">C.1</a> if it’s not clear why this reparameterization works.</p>
<p>This is equivalent to the <code>brms</code> model where <code>sigma = TRUE</code>. Parameterizing the model in this way causes us to lose the possibility of estimating the posterior of the true effect of the individual studies.</p>
<p>Write this in Stan as follows; this code is available in the file <code>meta-analysis2.stan</code> within the <code>bcogsci</code> package:</p>
<pre class="stan fold-show"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] effect;
  vector[N] SE;
  vector[N] study_id;
}
parameters {
  real zeta;
  real&lt;lower = 0&gt; tau;
}
model {
  target += normal_lpdf(effect| zeta,
                        sqrt(square(SE) + square(tau)));
  target += normal_lpdf(zeta | 0, 100);
  target += normal_lpdf(tau | 0, 100)
    - normal_lccdf(0 | 0, 100);
}</code></pre>
<p>Fit the model:</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb697-1"><a href="ch-remame.html#cb697-1" aria-hidden="true"></a>ma2 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb697-2"><a href="ch-remame.html#cb697-2" aria-hidden="true"></a>                   <span class="st">&quot;meta-analysis2.stan&quot;</span>,</span>
<span id="cb697-3"><a href="ch-remame.html#cb697-3" aria-hidden="true"></a>                   <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb697-4"><a href="ch-remame.html#cb697-4" aria-hidden="true"></a>fit_sbi2 &lt;-<span class="st"> </span><span class="kw">stan</span>(ma2,</span>
<span id="cb697-5"><a href="ch-remame.html#cb697-5" aria-hidden="true"></a>                 <span class="dt">data =</span> ls_sbi,</span>
<span id="cb697-6"><a href="ch-remame.html#cb697-6" aria-hidden="true"></a>                 <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.9</span>))</span></code></pre></div>
<div class="sourceCode" id="cb698"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb698-1"><a href="ch-remame.html#cb698-1" aria-hidden="true"></a><span class="kw">print</span>(fit_sbi2, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;zeta&quot;</span>, <span class="st">&quot;tau&quot;</span>))</span></code></pre></div>
<pre><code>##      mean 2.5% 97.5% n_eff Rhat
## zeta 13.7 3.23  29.6   822    1
## tau  11.7 0.70  29.3  1000    1</code></pre>
<p>This summary could be reported in an article by displaying the posterior means and 95% credible intervals of the parameters.</p>
</div>
</div>
</div>
<div id="measurement-error-models" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span>  Measurement-error models<a href="ch-remame.html#measurement-error-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Measurement error models deal with the situation where some predictor or the dependent variable, or both, are observed with measurement error. This measurement error could arise because a variable is an average (i.e., its standard error can also be estimated), or because we know that our measurement is noisy due to limitations of our equipment (e.g., delays in the signal from the keyboard to the motherboard, impedance in the electrodes in an EEG system, etc.).</p>
<div id="accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Accounting for measurement error in individual differences in working memory capacity and reading fluency<a href="ch-remame.html#accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As a motivating example, consider the following data from <span class="citation">Nicenboim, Vasishth, et al. (<a href="#ref-NicenboimEtAlCogSci2018" role="doc-biblioref">2018</a>)</span>.
For each subject, we have the partial-credit unit (PCU) scores of an operation span task as a measure of their  working memory capacity <span class="citation">(Conway et al. <a href="#ref-conway2005working" role="doc-biblioref">2005</a>)</span> along with their  standard error. In addition, the reading fluency of each subject is calculated from a separate set of data based on the mean reading speeds (character/second) in a  rapid automatized naming task <span class="citation">(RAN, Denckla and Rudel <a href="#ref-DenklaRudel1976" role="doc-biblioref">1976</a>)</span>; the standard error of the reading speed is also available.</p>
<p>Of interest here is the extent of the association between working memory capacity (measured as PCU) and  reading fluency (measured as reading speed in 50 characters per second). We avoid making any causal claims: It could be that our measure of working memory capacity really affects reading fluency or it could be the other way around. A third possibility is that there is a third variable (or several) that affects both reading fluency and working memory capacity. A treatment of causal inference in Bayesian models can be found in chapters 5 and 6 of <span class="citation">McElreath (<a href="#ref-mcelreath2015statistical" role="doc-biblioref">2020</a>)</span>.</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb700-1"><a href="ch-remame.html#cb700-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_indiv&quot;</span>)</span>
<span id="cb700-2"><a href="ch-remame.html#cb700-2" aria-hidden="true"></a>df_indiv</span></code></pre></div>
<pre><code>## # A tibble: 100 × 5
##    subj mean_rspeed se_rspeed mean_pcu se_pcu
##   &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
## 1     1      0.0521   0.00113    0.738 0.0648
## 2     2      0.0479   0.00121    0.292 0.0315
## 3     3      0.0601   0.00117    0.408 0.0900
## # ℹ 97 more rows</code></pre>
<p>At first glance, we see a relationship between mean PCU scores and mean reading speed; see Figure <a href="ch-remame.html#fig:relmeanVOTvdur">11.2</a>. However, this relationship seems to be driven by two extreme data points on the top left corner of the plot.</p>
<div class="sourceCode" id="cb702"><pre class="sourceCode r fold-hide"><code class="sourceCode r"><span id="cb702-1"><a href="ch-remame.html#cb702-1" aria-hidden="true"></a></span>
<span id="cb702-2"><a href="ch-remame.html#cb702-2" aria-hidden="true"></a>df_indiv &lt;-<span class="st"> </span>df_indiv <span class="op">%&gt;%</span></span>
<span id="cb702-3"><a href="ch-remame.html#cb702-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_mean_pcu =</span> mean_pcu <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(mean_pcu))</span>
<span id="cb702-4"><a href="ch-remame.html#cb702-4" aria-hidden="true"></a><span class="kw">ggplot</span>(df_indiv, <span class="kw">aes</span>(<span class="dt">x =</span> c_mean_pcu, <span class="dt">y =</span> mean_rspeed)) <span class="op">+</span></span>
<span id="cb702-5"><a href="ch-remame.html#cb702-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb702-6"><a href="ch-remame.html#cb702-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:relmeanVOTvdur"></span>
<img src="bayescogsci_files/figure-html/relmeanVOTvdur-1.svg" alt="The relationship between (centered) mean PCU scores and mean reading speed." width="672" />
<p class="caption">
FIGURE 11.2: The relationship between (centered) mean PCU scores and mean reading speed.
</p>
</div>
<p>A simple linear model shows a somewhat weak association between mean reading speed and centered mean PCU. The priors are relatively arbitrary but they are in the right order of magnitude given that reading speeds are quite short and well below 1.</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb703-1"><a href="ch-remame.html#cb703-1" aria-hidden="true"></a>df_indiv &lt;-<span class="st"> </span>df_indiv <span class="op">%&gt;%</span></span>
<span id="cb703-2"><a href="ch-remame.html#cb703-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_mean_pcu =</span> mean_pcu <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(mean_pcu))</span>
<span id="cb703-3"><a href="ch-remame.html#cb703-3" aria-hidden="true"></a>priors &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb703-4"><a href="ch-remame.html#cb703-4" aria-hidden="true"></a>  <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> b),</span>
<span id="cb703-5"><a href="ch-remame.html#cb703-5" aria-hidden="true"></a>  <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> sigma))</span>
<span id="cb703-6"><a href="ch-remame.html#cb703-6" aria-hidden="true"></a>fit_indiv &lt;-<span class="st"> </span><span class="kw">brm</span>(mean_rspeed <span class="op">~</span><span class="st"> </span>c_mean_pcu,</span>
<span id="cb703-7"><a href="ch-remame.html#cb703-7" aria-hidden="true"></a>                 <span class="dt">data =</span> df_indiv,</span>
<span id="cb703-8"><a href="ch-remame.html#cb703-8" aria-hidden="true"></a>                 <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb703-9"><a href="ch-remame.html#cb703-9" aria-hidden="true"></a>                 <span class="dt">prior =</span> priors)</span></code></pre></div>
<div class="sourceCode" id="cb704"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb704-1"><a href="ch-remame.html#cb704-1" aria-hidden="true"></a>fit_indiv</span></code></pre></div>
<pre><code>## ...
## Population-Level Effects: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept      0.06      0.00     0.05     0.06 1.00     5562
## c_mean_pcu    -0.01      0.01    -0.03     0.00 1.00     2155
##            Tail_ESS
## Intercept      3214
## c_mean_pcu     1993
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.01      0.00     0.01     0.01 1.00     1869     1967
## 
## ...</code></pre>
<div class="sourceCode" id="cb706"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb706-1"><a href="ch-remame.html#cb706-1" aria-hidden="true"></a><span class="co"># Proportion of samples below zero</span></span>
<span id="cb706-2"><a href="ch-remame.html#cb706-2" aria-hidden="true"></a>(Pb &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">as_draws_df</span>(fit_indiv)<span class="op">$</span>b_c_mean_pcu <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.945</code></pre>
<p>Figure <a href="ch-remame.html#fig:meplotstanplot">11.3</a>(a) shows the posterior distribution of the slope in this model. Most of the probability mass is negative (94.525%), suggesting that a better PCU score is associated with slower reading speed rather than faster; that is, that a larger working memory capacity is associated with less reading fluency. This is not a very intuitive result and it could be the case that is driven by the two extreme data points. Rather than removing these data points, we’ll examine what happens when the uncertainty of the measurements is taken into account.</p>
<p>Taking this uncertainty of the measurement is important; in many practical research problems, researchers will often take average measurements like these and examine the correlation between them. However, each of those data points is being measured with some error (uncertainty), but this error is being ignored when we take the averaged values. Ignoring this uncertainty leads to over-enthusiastic inferences. A measurement-error model solves this issue.</p>
<p>The measurement error model is stated as follows. There is assumed to be a true unobserved value <span class="math inline">\(y_{n,TRUE}\)</span> for the dependent variable, and a true unobserved value <span class="math inline">\(x_{n,TRUE}\)</span> for the predictor, where <span class="math inline">\(n\)</span> is indexing the observation number.
The observed values <span class="math inline">\(y_n\)</span> and the predictor <span class="math inline">\(x_n\)</span> are assumed to be generated with some error:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
y_n &amp;\sim\mathit{Normal}(y_{n,TRUE},SE_{y_n}) \\
x_n &amp;\sim\mathit{Normal}(x_{n,TRUE},SE_{x_n})
\end{aligned}
\end{equation}\]</span></p>
<p>The regression is fit to the (unknown) <em>true</em> values of the dependent and independent variables:</p>
<p><span class="math display" id="eq:masquare">\[\begin{equation}
y_{n,TRUE} \sim\mathit{Normal}(\alpha + \beta x_{n,TRUE},\sigma)
\tag{11.4}
\end{equation}\]</span></p>
<p>In addition, there is also an unknown standard deviation (standard error) of the latent unknown means that generate the underlying PCU means. I.e., we assume that each of the observed centered PCU scores is normally distributed with an underlying mean, <span class="math inline">\(\chi\)</span>, and a standard deviation <span class="math inline">\(\tau\)</span>. This is very similar to the meta-analysis situation we saw earlier: <span class="math inline">\(\zeta_n \sim\mathit{Normal}(\zeta,\tau)\)</span>, where <span class="math inline">\(\zeta_n\)</span> was the location parameter of each study, and <span class="math inline">\(\zeta\)</span> was the (unknown) location parameter representing the effect of interest, and <span class="math inline">\(\tau\)</span> was the between-study variability.</p>
<p><span class="math display">\[\begin{equation}
x_{n,TRUE} \sim\mathit{Normal}(\chi,\tau)
\end{equation}\]</span></p>
<p>The goal of the modeling is to obtain posterior distributions for the intercept and slope <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> (and the residual error standard deviation <span class="math inline">\(\sigma\)</span>).</p>
<p>We need to decide on priors for all the parameters now. We use relatively vague priors, which can still be considered regularizing priors based on our knowledge of the order of magnitude of the measurements. In situations where not much is known about a research question, one could use such vague priors.</p>
<p><span class="math display" id="eq:me">\[\begin{equation}
\begin{aligned}
\alpha &amp;\sim\mathit{Normal}(0, 0.5)\\
\beta &amp;\sim\mathit{Normal}(0, 0.5)\\
\chi &amp;\sim\mathit{Normal}(0, 0.5)\\
\sigma &amp;\sim\mathit{Normal}_+(0, 0.5)\\
\tau &amp;\sim\mathit{Normal}_+(0, 0.5)
\end{aligned}
\tag{11.5}
\end{equation}\]</span></p>
<div id="the-brms-version-of-the-measurement-error-model" class="section level4 hasAnchor" number="11.2.1.1">
<h4><span class="header-section-number">11.2.1.1</span> The <code>brms</code> version of the measurement error model<a href="ch-remame.html#the-brms-version-of-the-measurement-error-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In <code>brms</code>, the model specification would be as follows:</p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb708-1"><a href="ch-remame.html#cb708-1" aria-hidden="true"></a>priors_me &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb708-2"><a href="ch-remame.html#cb708-2" aria-hidden="true"></a>               <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> b),</span>
<span id="cb708-3"><a href="ch-remame.html#cb708-3" aria-hidden="true"></a>               <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> meanme),</span>
<span id="cb708-4"><a href="ch-remame.html#cb708-4" aria-hidden="true"></a>               <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> sdme),</span>
<span id="cb708-5"><a href="ch-remame.html#cb708-5" aria-hidden="true"></a>               <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> sigma))</span></code></pre></div>
<p>Here, the parameter with class  <code>meanme</code> and  <code>sdme</code> refer to the unknown mean and standard deviation (standard error) of the  latent unknown means that generate the underlying PCU means, <span class="math inline">\(\chi\)</span> and <span class="math inline">\(\tau\)</span> in Equation <a href="ch-remame.html#eq:me">(11.5)</a>. Once we decide on the priors, we use  <code>resp_se(.)</code> with <code>sigma = TRUE</code> (i.e, we don’t estimate <span class="math inline">\(y_{n,TRUE}\)</span> explicitly) and we use <code>me(c_meanpcu, se_pcu)</code> to indicate that the dependent variable <code>c_mean_pcu</code> is measured with error and <code>se_pcu</code> is its SE.</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb709-1"><a href="ch-remame.html#cb709-1" aria-hidden="true"></a>fit_indiv_me &lt;-<span class="st"> </span><span class="kw">brm</span>(mean_rspeed <span class="op">|</span><span class="st"> </span><span class="kw">resp_se</span>(se_rspeed, <span class="dt">sigma =</span> <span class="ot">TRUE</span>) <span class="op">~</span></span>
<span id="cb709-2"><a href="ch-remame.html#cb709-2" aria-hidden="true"></a><span class="st">                      </span><span class="kw">me</span>(c_mean_pcu, se_pcu),</span>
<span id="cb709-3"><a href="ch-remame.html#cb709-3" aria-hidden="true"></a>                    <span class="dt">data =</span> df_indiv,</span>
<span id="cb709-4"><a href="ch-remame.html#cb709-4" aria-hidden="true"></a>                    <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb709-5"><a href="ch-remame.html#cb709-5" aria-hidden="true"></a>                    <span class="dt">prior =</span> priors_me)</span></code></pre></div>
<div class="sourceCode" id="cb710"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb710-1"><a href="ch-remame.html#cb710-1" aria-hidden="true"></a>fit_indiv_me</span></code></pre></div>
<pre><code>## ...
## Population-Level Effects: 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept              0.05      0.00     0.05     0.06 1.00     4098
## mec_mean_pcuse_pcu    -0.00      0.01    -0.01     0.01 1.00     7097
##                    Tail_ESS
## Intercept              2810
## mec_mean_pcuse_pcu     3136
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.01      0.00     0.01     0.01 1.00     6201     2938
## 
## ...</code></pre>
<div class="sourceCode" id="cb712"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb712-1"><a href="ch-remame.html#cb712-1" aria-hidden="true"></a><span class="co"># Proportion of samples below zero</span></span>
<span id="cb712-2"><a href="ch-remame.html#cb712-2" aria-hidden="true"></a><span class="co"># Parameter names can be found out with `variables(fit_indiv_me)`</span></span>
<span id="cb712-3"><a href="ch-remame.html#cb712-3" aria-hidden="true"></a>(Pb_me &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">as_draws_df</span>(fit_indiv_me)<span class="op">$</span>bsp_mec_mean_pcuse_pcu <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.609</code></pre>
<p>The posterior for the slope is plotted in Figure <a href="ch-remame.html#fig:meplotstanplot">11.3</a>(b); this figure shows that the association between PCU scores and reading speed is much weaker once measurement error is taken into account: The posterior is much more uncertain (much more widely distributed) than in the simple linear model we fit above (compare Figure <a href="ch-remame.html#fig:meplotstanplot">11.3</a>(b) with Figure <a href="ch-remame.html#fig:meplotstanplot">11.3</a>(a)), and the direction of the association is now unclear, with 61% of the probability mass below zero, rather than 95%.</p>

<div class="sourceCode" id="cb714"><pre class="sourceCode r fold-hide"><code class="sourceCode r"><span id="cb714-1"><a href="ch-remame.html#cb714-1" aria-hidden="true"></a></span>
<span id="cb714-2"><a href="ch-remame.html#cb714-2" aria-hidden="true"></a><span class="co"># Plot a</span></span>
<span id="cb714-3"><a href="ch-remame.html#cb714-3" aria-hidden="true"></a><span class="kw">mcmc_plot</span>(fit_indiv,</span>
<span id="cb714-4"><a href="ch-remame.html#cb714-4" aria-hidden="true"></a>          <span class="dt">variable =</span> <span class="st">&quot;^b_c&quot;</span>,</span>
<span id="cb714-5"><a href="ch-remame.html#cb714-5" aria-hidden="true"></a>          <span class="dt">regex =</span> <span class="ot">TRUE</span>,</span>
<span id="cb714-6"><a href="ch-remame.html#cb714-6" aria-hidden="true"></a>          <span class="dt">type =</span> <span class="st">&quot;hist&quot;</span>) <span class="op">+</span></span>
<span id="cb714-7"><a href="ch-remame.html#cb714-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;(a) No  measurement error&quot;</span>) <span class="op">+</span></span>
<span id="cb714-8"><a href="ch-remame.html#cb714-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">0.03</span>))</span>
<span id="cb714-9"><a href="ch-remame.html#cb714-9" aria-hidden="true"></a></span>
<span id="cb714-10"><a href="ch-remame.html#cb714-10" aria-hidden="true"></a><span class="co"># Plot b</span></span>
<span id="cb714-11"><a href="ch-remame.html#cb714-11" aria-hidden="true"></a><span class="kw">mcmc_plot</span>(fit_indiv_me, <span class="dt">variable =</span> <span class="st">&quot;^bsp&quot;</span>, <span class="dt">regex =</span> <span class="ot">TRUE</span>, <span class="dt">type =</span> <span class="st">&quot;hist&quot;</span>) <span class="op">+</span></span>
<span id="cb714-12"><a href="ch-remame.html#cb714-12" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;(b) With measurement error&quot;</span>) <span class="op">+</span></span>
<span id="cb714-13"><a href="ch-remame.html#cb714-13" aria-hidden="true"></a><span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">0.03</span>))</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:meplotstanplot"></span>
<img src="bayescogsci_files/figure-html/meplotstanplot-1.svg" alt="(a) Posterior distribution of the slope for the effect of centered mean PCU on mean reading speed (50 characters per second) in a model without measurement error (fit_indiv). (b) Posterior distribution of the slope for the same dependent variable (mean reading speed) and predictor (centered mean PCU) in a model that accounts for measurement error (fit_indiv_me)." width="49%" /><img src="bayescogsci_files/figure-html/meplotstanplot-2.svg" alt="(a) Posterior distribution of the slope for the effect of centered mean PCU on mean reading speed (50 characters per second) in a model without measurement error (fit_indiv). (b) Posterior distribution of the slope for the same dependent variable (mean reading speed) and predictor (centered mean PCU) in a model that accounts for measurement error (fit_indiv_me)." width="49%" />
<p class="caption">
FIGURE 11.3: (a) Posterior distribution of the slope for the effect of centered mean PCU on mean reading speed (50 characters per second) in a model without measurement error (<code>fit_indiv</code>). (b) Posterior distribution of the slope for the same dependent variable (mean reading speed) and predictor (centered mean PCU) in a model that accounts for measurement error (<code>fit_indiv_me</code>).
</p>
</div>
<p>Figure <a href="ch-remame.html#fig:seerrors">11.4</a> visualizes the main reason why we have no clear association in the measurement error analysis: the two points at the top left part of the plot that were driving the effect have very large SE for the measurement of reading speed. The code to produce Figure <a href="ch-remame.html#fig:seerrors">11.4</a> appears below and overlays several (250) regression lines that correspond to different samples of the posterior distribution with the measurements of reading speed and PCU.</p>
<div class="sourceCode" id="cb715"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb715-1"><a href="ch-remame.html#cb715-1" aria-hidden="true"></a>df_reg &lt;-<span class="st"> </span><span class="kw">as_draws_df</span>(fit_indiv_me) <span class="op">%&gt;%</span></span>
<span id="cb715-2"><a href="ch-remame.html#cb715-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">select</span>(<span class="dt">alpha =</span> b_Intercept, <span class="dt">beta =</span> bsp_mec_mean_pcuse_pcu) <span class="op">%&gt;%</span></span>
<span id="cb715-3"><a href="ch-remame.html#cb715-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">250</span>)</span>
<span id="cb715-4"><a href="ch-remame.html#cb715-4" aria-hidden="true"></a><span class="kw">ggplot</span>(df_indiv, <span class="kw">aes</span>(<span class="dt">x =</span> c_mean_pcu, <span class="dt">y =</span> mean_rspeed)) <span class="op">+</span></span>
<span id="cb715-5"><a href="ch-remame.html#cb715-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb715-6"><a href="ch-remame.html#cb715-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_errorbarh</span>(<span class="kw">aes</span>(<span class="dt">xmin =</span> c_mean_pcu <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>se_pcu,</span>
<span id="cb715-7"><a href="ch-remame.html#cb715-7" aria-hidden="true"></a>                     <span class="dt">xmax =</span> c_mean_pcu <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>se_pcu),</span>
<span id="cb715-8"><a href="ch-remame.html#cb715-8" aria-hidden="true"></a>                 <span class="dt">alpha =</span> <span class="fl">.5</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>) <span class="op">+</span></span>
<span id="cb715-9"><a href="ch-remame.html#cb715-9" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> mean_rspeed <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>se_rspeed,</span>
<span id="cb715-10"><a href="ch-remame.html#cb715-10" aria-hidden="true"></a>                    <span class="dt">ymax =</span> mean_rspeed <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>se_rspeed),</span>
<span id="cb715-11"><a href="ch-remame.html#cb715-11" aria-hidden="true"></a>                <span class="dt">alpha =</span> <span class="fl">.5</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>) <span class="op">+</span></span>
<span id="cb715-12"><a href="ch-remame.html#cb715-12" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept =</span> alpha, <span class="dt">slope =</span> beta),</span>
<span id="cb715-13"><a href="ch-remame.html#cb715-13" aria-hidden="true"></a>              <span class="dt">data =</span> df_reg,</span>
<span id="cb715-14"><a href="ch-remame.html#cb715-14" aria-hidden="true"></a>              <span class="dt">alpha =</span> <span class="fl">.02</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:seerrors"></span>
<img src="bayescogsci_files/figure-html/seerrors-1.svg" alt="The relationship between centered mean PCU scores and  mean reading speed accounting for measurement error. The error bars represent two standard errors. The regression lines are produced with 250 samples of the intercept and slope from the posterior distribution." width="672" />
<p class="caption">
FIGURE 11.4: The relationship between centered mean PCU scores and mean reading speed accounting for measurement error. The error bars represent two standard errors. The regression lines are produced with 250 samples of the intercept and slope from the posterior distribution.
</p>
</div>
<p>Of course, the conclusion here cannot be that there is no association between PCU scores and reading speed. In order to claim an absence of an effect, we would need to use Bayes factors (see chapter <a href="ch-bf.html#ch-bf">13</a>) or cross-validation (see chapter <a href="ch-cv.html#ch-cv">14</a>).</p>
</div>
<div id="sec-stanme" class="section level4 hasAnchor" number="11.2.1.2">
<h4><span class="header-section-number">11.2.1.2</span> The Stan version of the measurement error model<a href="ch-remame.html#sec-stanme" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>As it happened when we carried out the meta-analysis, the main difficulty for modeling measurement error models directly in Stan is that we need to reparameterize the models to avoid dependencies between samples of different parameters.
The two changes that we need to do to the parameterization of our model presented in Equation <a href="ch-remame.html#eq:me">(11.5)</a> are the following.</p>
<ol style="list-style-type: decimal">
<li>Sample from an auxiliary parameter <span class="math inline">\(z_n\)</span> rather than directly from <span class="math inline">\(x_{n,TRUE}\)</span>, as we did in Equation <a href="ch-remame.html#eq:ma1">(11.2)</a>:</li>
</ol>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
z_n &amp; \sim\mathit{Normal}(0, 1)\\
x_{n,TRUE} &amp;= z_n \cdot \tau + \chi \\
x_n &amp; \sim \mathit{Normal}(x_{n,TRUE}, SE_{x_n})
\end{aligned}
\end{equation}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Don’t model <span class="math inline">\(y_{n,TRUE}\)</span> explicitly as in Equation <a href="ch-remame.html#eq:masquare">(11.4)</a>; rather take into account the SE and the variation on <span class="math inline">\(y_{n,TRUE}\)</span> in the following way:</li>
</ol>
<p><span class="math display">\[\begin{equation}
y_{n} \sim\mathit{Normal}\left(\alpha + \beta x_{n,TRUE},\sqrt{SE_{y_n}^2 + \sigma^2}\right)
\end{equation}\]</span></p>
<p>We are now ready to write this in Stan; the code is in the model called <code>me.stan</code>:</p>
<pre class="stan fold-show"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] x;
  vector[N] SE_x;
  vector[N] y;
  vector[N] SE_y;
}
parameters {
  real alpha;
  real beta;
  real chi;
  real&lt;lower = 0&gt; sigma;
  real&lt;lower = 0&gt; tau;
  vector[N] z;
}
transformed parameters {
  vector[N] x_true = z * tau + chi;
}
model {
  target += normal_lpdf(x | x_true, SE_x);
  target += normal_lpdf(y | alpha + beta * x_true,
                        sqrt(square(SE_y) + square(sigma)));
  target += std_normal_lpdf(z);
  target += normal_lpdf(alpha | 0, 0.5);
  target += normal_lpdf(beta | 0, 0.5);
  target += normal_lpdf(chi | 0, 0.5);
  target += normal_lpdf(sigma| 0, 0.5)
    - normal_lccdf(0 | 0, 0.5);
  target += normal_lpdf(tau | 0, 0.5)
    - normal_lccdf(0 | 0, 0.5);
}</code></pre>
<p>Fit the model:</p>
<div class="sourceCode" id="cb717"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb717-1"><a href="ch-remame.html#cb717-1" aria-hidden="true"></a>me &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</span>
<span id="cb717-2"><a href="ch-remame.html#cb717-2" aria-hidden="true"></a>                  <span class="st">&quot;me.stan&quot;</span>,</span>
<span id="cb717-3"><a href="ch-remame.html#cb717-3" aria-hidden="true"></a>                  <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</span>
<span id="cb717-4"><a href="ch-remame.html#cb717-4" aria-hidden="true"></a>ls_me &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">nrow</span>(df_indiv),</span>
<span id="cb717-5"><a href="ch-remame.html#cb717-5" aria-hidden="true"></a>              <span class="dt">y =</span> df_indiv<span class="op">$</span>mean_rspeed,</span>
<span id="cb717-6"><a href="ch-remame.html#cb717-6" aria-hidden="true"></a>              <span class="dt">SE_y =</span> df_indiv<span class="op">$</span>se_rspeed,</span>
<span id="cb717-7"><a href="ch-remame.html#cb717-7" aria-hidden="true"></a>              <span class="dt">x =</span> df_indiv<span class="op">$</span>c_mean_pcu,</span>
<span id="cb717-8"><a href="ch-remame.html#cb717-8" aria-hidden="true"></a>              <span class="dt">SE_x =</span> df_indiv<span class="op">$</span>se_pcu)</span>
<span id="cb717-9"><a href="ch-remame.html#cb717-9" aria-hidden="true"></a>fit_indiv_me_stan &lt;-<span class="st"> </span><span class="kw">stan</span>(me, <span class="dt">data =</span> ls_me)</span></code></pre></div>
<div class="sourceCode" id="cb718"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb718-1"><a href="ch-remame.html#cb718-1" aria-hidden="true"></a><span class="kw">print</span>(fit_indiv_me_stan, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</span></code></pre></div>
<pre><code>##       mean  2.5% 97.5% n_eff Rhat
## alpha 0.05  0.05  0.06  3610    1
## beta  0.00 -0.01  0.01  5216    1
## sigma 0.01  0.01  0.01  5592    1</code></pre>
<p>The posterior distributions are similar to those that we obtained with <code>brms</code>.</p>
</div>
</div>
</div>
<div id="summary-10" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Summary<a href="ch-remame.html#summary-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter introduced two statistical tools that are potentially of great relevance to cognitive science: random-effects meta-analysis and measurement error models. Despite the inherent limitations of meta-analysis, these should be used routinely to accumulate knowledge through systematic evidence synthesis. Measurement errors can also prevent over-enthusiastic conclusions that are often made based on noisy data.</p>
</div>
<div id="further-reading-8" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Further reading<a href="ch-remame.html#further-reading-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For some examples of Bayesian meta-analyses in psycholinguistics, see <span class="citation">Vasishth et al. (<a href="#ref-VasishthetalPLoSOne2013" role="doc-biblioref">2013</a>)</span>, <span class="citation">Jäger, Engelmann, and Vasishth (<a href="#ref-JaegerEngelmannVasishth2017" role="doc-biblioref">2017</a>)</span>,
<span class="citation">Nicenboim, Roettger, and Vasishth (<a href="#ref-NicenboimRoettgeretal" role="doc-biblioref">2018</a>)</span>, <span class="citation">Nicenboim, Vasishth, and Rösler (<a href="#ref-NicenboimPreactivation2019" role="doc-biblioref">2020</a>)</span>, <span class="citation">Bürki et al. (<a href="#ref-BuerkiEtAl2020" role="doc-biblioref">2020</a>)</span>, <span class="citation">Cox et al. (<a href="#ref-cox2022bayesian" role="doc-biblioref">2022</a>)</span>, and <span class="citation">Bürki, Alario, and Vasishth (<a href="#ref-Buerki2022" role="doc-biblioref">2023</a>)</span>. A frequentist meta-analysis of priming effects in psycholinguistics appears in <span class="citation">Mahowald et al. (<a href="#ref-mahowald2016meta" role="doc-biblioref">2016</a>)</span>. <span class="citation">Sutton et al. (<a href="#ref-sutton2012evidence" role="doc-biblioref">2012</a>)</span> and <span class="citation">Higgins and Green (<a href="#ref-cochrane" role="doc-biblioref">2008</a>)</span> are two useful general introductions that discuss systematic reviews, meta-analysis, and evidence synthesis; these two references are from medicine, where meta-analysis is more widely used than in cognitive science. A potentially important article for meta-analysis introduces a methodology for modeling bias, to adjust for different kinds of bias in the data <span class="citation">(Turner et al. <a href="#ref-turner2008bias" role="doc-biblioref">2008</a>)</span>. Meta-analyses have important limitations and should not be taken at face value; this point is discussed in, e.g., <span class="citation">Spector and Thompson (<a href="#ref-spector1991potential" role="doc-biblioref">1991</a>)</span>. A practical book-length introduction to Bayesian meta-analysis is <span class="citation">Grant and Di Tanna (<a href="#ref-grantmetaanalysis" role="doc-biblioref">2025</a>)</span>.</p>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references hanging-indent">
<div id="ref-Buerki2022">
<p>Bürki, Audrey, Francois-Xavier Alario, and Shravan Vasishth. 2023. “When Words Collide: Bayesian Meta-Analyses of Distractor and Target Properties in the Picture-Word Interference Paradigm.” <em>Quarterly Journal of Experimental Psychology</em> 76 (6): 1410–30. <a href="https://doi.org/https://doi.org/10.1177/17470218221114644">https://doi.org/https://doi.org/10.1177/17470218221114644</a>.</p>
</div>
<div id="ref-BuerkiEtAl2020">
<p>Bürki, Audrey, Shereen Elbuy, Sylvain Madec, and Shravan Vasishth. 2020. “What Did We Learn from Forty Years of Research on Semantic Interference? A Bayesian Meta-Analysis.” <em>Journal of Memory and Language</em> 114. <a href="https://doi.org/10.1016/j.jml.2020.104125">https://doi.org/10.1016/j.jml.2020.104125</a>.</p>
</div>
<div id="ref-conway2005working">
<p>Conway, Andrew R. A., Michael J. Kane, Michael F. Bunting, D. Zach Hambrick, Oliver Wilhelm, and Randall W. Engle. 2005. “Working Memory Span Tasks: A Methodological Review and User’s Guide.” <em>Psychonomic Bulletin &amp; Review</em> 12 (5): 769–86.</p>
</div>
<div id="ref-cox2022bayesian">
<p>Cox, Christopher Martin Mikkelsen, Tamar Keren-Portnoy, Andreas Roepstorff, and Riccardo Fusaroli. 2022. “A Bayesian Meta-Analysis of Infants’ Ability to Perceive Audio–Visual Congruence for Speech.” <em>Infancy</em> 27 (1): 67–96.</p>
</div>
<div id="ref-DenklaRudel1976">
<p>Denckla, Martha Bridge, and Rita G. Rudel. 1976. “Rapid ‘Automatized’ Naming (R.A.N.): Dyslexia Differentiated from Other Learning Disabilities.” <em>Neuropsychologia</em> 14 (4): 471–79. <a href="https://doi.org/https://doi.org/10.1016/0028-3932(76)90075-0">https://doi.org/https://doi.org/10.1016/0028-3932(76)90075-0</a>.</p>
</div>
<div id="ref-grantmetaanalysis">
<p>Grant, Robert, and Gian Luca Di Tanna. 2025. <em>Bayesian Meta-Analysis: A Practical Introduction</em>. Cambridge University Press.</p>
</div>
<div id="ref-cochrane">
<p>Higgins, Julian, and Sally Green. 2008. <em>Cochrane Handbook for Systematics Reviews of Interventions</em>. New York: Wiley-Blackwell.</p>
</div>
<div id="ref-JaegerEngelmannVasishth2017">
<p>Jäger, Lena A., Felix Engelmann, and Shravan Vasishth. 2017. “Similarity-Based Interference in Sentence Comprehension: Literature review and Bayesian meta-analysis.” <em>Journal of Memory and Language</em> 94: 316–39. <a href="https://doi.org/https://doi.org/10.1016/j.jml.2017.01.004">https://doi.org/https://doi.org/10.1016/j.jml.2017.01.004</a>.</p>
</div>
<div id="ref-mahowald2016meta">
<p>Mahowald, Kyle, Ariel James, Richard Futrell, and Edward Gibson. 2016. “A Meta-Analysis of Syntactic Priming in Language Production.” <em>Journal of Memory and Language</em> 91: 5–27. <a href="https://doi.org/https://doi.org/10.1016/j.jml.2016.03.009">https://doi.org/https://doi.org/10.1016/j.jml.2016.03.009</a>.</p>
</div>
<div id="ref-mcelreath2015statistical">
<p>McElreath, Richard. 2020. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</em>. Boca Raton, Florida: Chapman; Hall/CRC.</p>
</div>
<div id="ref-NicenboimRoettgeretal">
<p>Nicenboim, Bruno, Timo B. Roettger, and Shravan Vasishth. 2018. “Using Meta-Analysis for Evidence Synthesis: The case of incomplete neutralization in German.” <em>Journal of Phonetics</em> 70: 39–55. <a href="https://doi.org/https://doi.org/10.1016/j.wocn.2018.06.001">https://doi.org/https://doi.org/10.1016/j.wocn.2018.06.001</a>.</p>
</div>
<div id="ref-NicenboimEtAlCogSci2018">
<p>Nicenboim, Bruno, Shravan Vasishth, Felix Engelmann, and Katja Suckow. 2018. “Exploratory and Confirmatory Analyses in Sentence Processing: A case study of number interference in German.” <em>Cognitive Science</em> 42 (S4). <a href="https://doi.org/10.1111/cogs.12589">https://doi.org/10.1111/cogs.12589</a>.</p>
</div>
<div id="ref-NicenboimPreactivation2019">
<p>Nicenboim, Bruno, Shravan Vasishth, and Frank Rösler. 2020. “Are Words Pre-Activated Probabilistically During Sentence Comprehension? Evidence from New Data and a Bayesian Random-Effects Meta-Analysis Using Publicly Available Data.” <em>Neuropsychologia</em> 142. <a href="https://doi.org/10.1016/j.neuropsychologia.2020.107427">https://doi.org/10.1016/j.neuropsychologia.2020.107427</a>.</p>
</div>
<div id="ref-spector1991potential">
<p>Spector, Tim D., and Simon G. Thompson. 1991. “The Potential and Limitations of Meta-Analysis.” <em>Journal of Epidemiology and Community Health</em> 45 (2): 89.</p>
</div>
<div id="ref-sutton2012evidence">
<p>Sutton, Alexander J., Nicky J. Welton, Nicola Cooper, Keith R. Abrams, and A. E. Ades. 2012. <em>Evidence Synthesis for Decision Making in Healthcare</em>. Vol. 132. John Wiley &amp; Sons.</p>
</div>
<div id="ref-turner2008bias">
<p>Turner, R. M., David J. Spiegelhalter, G. Smith, and Simon G. Thompson. 2008. “Bias Modelling in Evidence Synthesis.” <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em> 172 (1): 21–47. <a href="https://doi.org/https://doi.org/10.1111/j.1467-985X.2008.00547.x">https://doi.org/https://doi.org/10.1111/j.1467-985X.2008.00547.x</a>.</p>
</div>
<div id="ref-VasishthetalPLoSOne2013">
<p>Vasishth, Shravan, Zhong Chen, Qiang Li, and Gueilan Guo. 2013. “Processing Chinese Relative Clauses: Evidence for the Subject-Relative Advantage.” <em>PLoS ONE</em> 8 (10): 1–14. <a href="https://doi.org/https://doi.org/10.1371/journal.pone.0077006">https://doi.org/https://doi.org/10.1371/journal.pone.0077006</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="45">
<li id="fn45"><p>In the current example, the dependent variable is either self-paced reading time or first-pass reading time from eyetracking. A possible criticism here is that these two different dependent measures should not appear in the same meta-analysis. Despite these being quite different dependent variables, the simplifying assumption we made was that the dependent measure, which is in milliseconds in both the self-paced reading studies and eyetracking studies, is a difference of means between two (sets of) conditions, and therefore gives an estimate of the effect of interest. An alternative approach would have been to standardize the effect size (Cohen’s d) in each study; but this would be difficult to carry out in this example as much of the published work did not provide the original data; in many of the cases, only summary statistics from the publication were available. Such standardized effect sizes would also be open to criticism, because the effect size in self-paced reading and eyetracking may also not be comparable.<a href="ch-remame.html#fnref45" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-custom.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-comparison.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
