<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>D Model comparison - Extended | Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="Introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="D Model comparison - Extended | Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://bruno.nicenboim.me/bayescogsci/images/temporarycover.jpg" />
  <meta property="og:description" content="Introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/bnicenboim/bayescogsci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="D Model comparison - Extended | Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="Introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://bruno.nicenboim.me/bayescogsci/images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel J. Schad, and Shravan Vasishth" />


<meta name="date" content="2026-01-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="evidence-synthesis-and-measurements-with-error---extended.html"/>
<link rel="next" href="ch-priors.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block/empty-anchor.js"></script>
<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />
<script>
// FOLD code from 
// https://github.com/bblodfon/rtemps/blob/master/docs/bookdown-lite/hide_code.html
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // if code block has been labeled with class `fold-show`, show the code on init!
    var classList = $(this).attr('class').split(/\s+/);
    for (var i = 0; i < classList.length; i++) {
    if (classList[i] === 'fold-show') {
        show = true;
      }
    }

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // CRITICAL FIX: Create button with aria-hidden text that won't be copied
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id)
        .attr('aria-label', show ? 'Hide code' : 'Show code');
    
    // Use aria-hidden to prevent screen readers and copy from seeing text
    var showCodeText = $('<span aria-hidden="true" style="user-select: none; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; pointer-events: none;">' + (show ? 'Hide' : 'Code') + '</span>');
    showCodeButton.append(showCodeText);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // update the text of the button when it's clicked
    div.on('hide.bs.collapse', function () {
      showCodeText.text('Code');
      showCodeButton.attr('aria-label', 'Show code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
      showCodeButton.attr('aria-label', 'Hide code');
    });

    // hack: return show to false, otherwise all next codeBlocks will be shown!
    show = false;
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>

<!-- NUCLEAR OPTION: Intercept ALL copy events and strip button text -->
<script>
$(document).ready(function() {
  
  // Method 1: Make button spans completely invisible to selection
  function protectButtons() {
    $('.code-folding-btn span').each(function() {
      this.style.setProperty('user-select', 'none', 'important');
      this.style.setProperty('-webkit-user-select', 'none', 'important');
      this.style.setProperty('-moz-user-select', 'none', 'important');
      this.style.setProperty('-ms-user-select', 'none', 'important');
      this.style.setProperty('pointer-events', 'none', 'important');
      $(this).attr('unselectable', 'on');
      $(this).attr('aria-hidden', 'true');
    });
    
    $('.code-folding-btn').each(function() {
      this.style.setProperty('user-select', 'none', 'important');
      this.style.setProperty('-webkit-user-select', 'none', 'important');
      this.style.setProperty('-moz-user-select', 'none', 'important');
      this.style.setProperty('-ms-user-select', 'none', 'important');
    });
  }
  
  protectButtons();
  setTimeout(protectButtons, 100);
  setTimeout(protectButtons, 500);
  setTimeout(protectButtons, 1000);
  
  // Method 2: Aggressive copy event interception
  document.addEventListener('copy', function(e) {
    var selection = window.getSelection();
    var selectedText = selection.toString();
    
    // Remove "Hide" or "Code" from the start
    if (selectedText) {
      var cleanedText = selectedText
        .replace(/^(Hide|Code)\s*/gm, '')  // Remove from start of any line
        .replace(/\s+(Hide|Code)\s*$/gm, '');  // Remove from end
      
      if (cleanedText !== selectedText) {
        e.preventDefault();
        
        if (e.clipboardData) {
          e.clipboardData.setData('text/plain', cleanedText);
        } else if (window.clipboardData) {
          window.clipboardData.setData('Text', cleanedText);
        }
      }
    }
  }, true);  // Use capture phase
  
  // Method 3: Override native copy for code blocks
  $('body').on('copy', 'pre, pre.sourceCode, .sourceCode, code', function(e) {
    var selection = window.getSelection();
    var selectedText = selection.toString();
    
    if (selectedText && (selectedText.startsWith('Hide') || selectedText.startsWith('Code'))) {
      e.preventDefault();
      e.stopPropagation();
      
      var cleanedText = selectedText.replace(/^(Hide|Code)\s*/, '');
      
      if (e.originalEvent.clipboardData) {
        e.originalEvent.clipboardData.setData('text/plain', cleanedText);
      } else if (window.clipboardData) {
        window.clipboardData.setData('Text', cleanedText);
      }
    }
  });
});
</script>

<script data-goatcounter="https://bayescogsci.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science (DRAFT)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-read-this-book-and-what-is-its-target-audience"><i class="fa fa-check"></i>Why read this book, and what is its target audience?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#developing-the-right-mindset-for-this-book"><i class="fa fa-check"></i>Developing the right mindset for this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-read-this-book"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#some-conventions-used-in-this-book"><i class="fa fa-check"></i>Some conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#online-materials"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-needed"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#introprob"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#condprob"><i class="fa fa-check"></i><b>1.2</b>  Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#the-law-of-total-probability"><i class="fa fa-check"></i><b>1.3</b> The  law of total probability</a></li>
<li class="chapter" data-level="1.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-binomialcloze"><i class="fa fa-check"></i><b>1.4</b>  Discrete random variables: An example using the  binomial distribution</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="ch-intro.html"><a href="ch-intro.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.4.1</b> The mean and variance of the binomial distribution</a></li>
<li class="chapter" data-level="1.4.2" data-path="ch-intro.html"><a href="ch-intro.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.4.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-intro.html"><a href="ch-intro.html#continuous-random-variables-an-example-using-the-normal-distribution"><i class="fa fa-check"></i><b>1.5</b>  Continuous random variables: An example using the  normal distribution</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="ch-intro.html"><a href="ch-intro.html#an-important-distinction-probability-vs.-density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.5.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-intro.html"><a href="ch-intro.html#truncating-a-normal-distribution"><i class="fa fa-check"></i><b>1.5.2</b> Truncating a normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-intro.html"><a href="ch-intro.html#bivariate-and-multivariate-distributions"><i class="fa fa-check"></i><b>1.6</b> Bivariate and multivariate distributions</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="ch-intro.html"><a href="ch-intro.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.1</b> Example 1:  Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-intro.html"><a href="ch-intro.html#sec-contbivar"><i class="fa fa-check"></i><b>1.6.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-intro.html"><a href="ch-intro.html#sec-generatebivariatedata"><i class="fa fa-check"></i><b>1.6.3</b> Generate simulated bivariate (or multivariate) data</a></li>
<li class="chapter" data-level="1.6.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-decomposevcovmatrix"><i class="fa fa-check"></i><b>1.6.4</b> Decomposing a variance-covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-intro.html"><a href="ch-intro.html#sec-marginal"><i class="fa fa-check"></i><b>1.7</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.8" data-path="ch-intro.html"><a href="ch-intro.html#summary-of-some-useful-r-functions"><i class="fa fa-check"></i><b>1.8</b> Summary of some useful R functions</a></li>
<li class="chapter" data-level="1.9" data-path="ch-intro.html"><a href="ch-intro.html#summary"><i class="fa fa-check"></i><b>1.9</b> Summary</a></li>
<li class="chapter" data-level="1.10" data-path="ch-intro.html"><a href="ch-intro.html#further-reading"><i class="fa fa-check"></i><b>1.10</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-introBDA.html"><a href="ch-introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#bayes-rule"><i class="fa fa-check"></i><b>2.1</b>  Bayes’ rule</a></li>
<li class="chapter" data-level="2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-analytical"><i class="fa fa-check"></i><b>2.2</b> Deriving the  posterior using Bayes’ rule: An analytical example</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.2.1</b> Choosing a  likelihood</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-choosepriortheta"><i class="fa fa-check"></i><b>2.2.2</b> Choosing a  prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.2.3</b> Using  Bayes’ rule to compute the  posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.2.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#visualizing-the-prior-likelihood-and-posterior"><i class="fa fa-check"></i><b>2.2.5</b> Visualizing the prior, likelihood, and posterior</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch-introBDA.html"><a href="ch-introBDA.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.2.6</b> The  posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.2.7" data-path="ch-introBDA.html"><a href="ch-introBDA.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.2.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
<li class="chapter" data-level="2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#further-reading-1"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>II Regression models with brms</b></span></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sampling"><i class="fa fa-check"></i><b>3.1</b> Deriving the  posterior through  sampling</a></li>
<li class="chapter" data-level="3.2" data-path="ch-compbda.html"><a href="ch-compbda.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.2</b>  Bayesian Regression Models using Stan:  brms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-simplenormal"><i class="fa fa-check"></i><b>3.2.1</b> A simple linear model: A single subject pressing a button repeatedly (a finger tapping task)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-priorpred"><i class="fa fa-check"></i><b>3.3</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.4" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sensitivity"><i class="fa fa-check"></i><b>3.4</b> The influence of priors:  sensitivity analysis</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch-compbda.html"><a href="ch-compbda.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.4.1</b>  Flat, uninformative priors</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-compbda.html"><a href="ch-compbda.html#regularizing-priors"><i class="fa fa-check"></i><b>3.4.2</b>  Regularizing priors</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-compbda.html"><a href="ch-compbda.html#principled-priors"><i class="fa fa-check"></i><b>3.4.3</b>  Principled priors</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-compbda.html"><a href="ch-compbda.html#informative-priors"><i class="fa fa-check"></i><b>3.4.4</b>  Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-revisit"><i class="fa fa-check"></i><b>3.5</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.6" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ppd"><i class="fa fa-check"></i><b>3.6</b>  Posterior predictive distribution</a></li>
<li class="chapter" data-level="3.7" data-path="ch-compbda.html"><a href="ch-compbda.html#the-influence-of-the-likelihood"><i class="fa fa-check"></i><b>3.7</b> The influence of the likelihood</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lnfirst"><i class="fa fa-check"></i><b>3.7.1</b> The  log-normal likelihood</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lognormal"><i class="fa fa-check"></i><b>3.7.2</b> Using a log-normal likelihood to fit data from a single subject pressing a button repeatedly</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="ch-compbda.html"><a href="ch-compbda.html#list-of-the-most-important-commands"><i class="fa fa-check"></i><b>3.8</b> List of the most important commands</a></li>
<li class="chapter" data-level="3.9" data-path="ch-compbda.html"><a href="ch-compbda.html#summary-2"><i class="fa fa-check"></i><b>3.9</b> Summary</a></li>
<li class="chapter" data-level="3.10" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ch3furtherreading"><i class="fa fa-check"></i><b>3.10</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupil"><i class="fa fa-check"></i><b>4.1</b> A first  linear regression: Does attentional load affect pupil size?</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b>  Likelihood and  priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The  <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-trial"><i class="fa fa-check"></i><b>4.2</b>  Log-normal model: Does trial affect response times?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The  <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.2.4" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.2.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-reg.html"><a href="ch-reg.html#sec-logistic"><i class="fa fa-check"></i><b>4.3</b>  Logistic regression: Does  set size affect  free recall?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ch-reg.html"><a href="ch-reg.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-priorslogisticregression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-comlogis"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy-1"><i class="fa fa-check"></i><b>4.3.5</b>  Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-reg.html"><a href="ch-reg.html#summary-3"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="ch-reg.html"><a href="ch-reg.html#sec-ch4furtherreading"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#exchangeability-and-hierarchical-models"><i class="fa fa-check"></i><b>5.1</b> Exchangeability and hierarchical models</a></li>
<li class="chapter" data-level="5.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-N400hierarchical"><i class="fa fa-check"></i><b>5.2</b> A hierarchical model with a normal likelihood: The N400 effect</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-Mcp"><i class="fa fa-check"></i><b>5.2.1</b>  Complete pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.2.2</b>  No pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.2.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-uncorrelated"><i class="fa fa-check"></i><b>5.2.3</b>  Varying intercepts and  varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.2.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-mcvivs"><i class="fa fa-check"></i><b>5.2.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.2.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-sih"><i class="fa fa-check"></i><b>5.2.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.2.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-distrmodel"><i class="fa fa-check"></i><b>5.2.6</b> Beyond the maximal model–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-stroop"><i class="fa fa-check"></i><b>5.3</b> A  hierarchical log-normal model: The  Stroop effect</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.3.1</b> A correlated varying intercept varying slopes  log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort"><i class="fa fa-check"></i><b>5.4</b> Why fitting a Bayesian hierarchical model is worth the effort</a></li>
<li class="chapter" data-level="5.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#summary-4"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
<li class="chapter" data-level="5.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#further-reading-2"><i class="fa fa-check"></i><b>5.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>6</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch-contr.html"><a href="ch-contr.html#basic-concepts-illustrated-using-a-two-level-factor"><i class="fa fa-check"></i><b>6.1</b> Basic concepts illustrated using a two-level factor</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ch-contr.html"><a href="ch-contr.html#treatmentcontrasts"><i class="fa fa-check"></i><b>6.1.1</b> Default contrast coding:  Treatment contrasts</a></li>
<li class="chapter" data-level="6.1.2" data-path="ch-contr.html"><a href="ch-contr.html#inverseMatrix"><i class="fa fa-check"></i><b>6.1.2</b> Defining comparisons</a></li>
<li class="chapter" data-level="6.1.3" data-path="ch-contr.html"><a href="ch-contr.html#effectcoding"><i class="fa fa-check"></i><b>6.1.3</b>  Sum contrasts</a></li>
<li class="chapter" data-level="6.1.4" data-path="ch-contr.html"><a href="ch-contr.html#sec-cellMeans"><i class="fa fa-check"></i><b>6.1.4</b>  Cell means parameterization and  posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix-illustrated-with-a-three-level-factor"><i class="fa fa-check"></i><b>6.2</b> The hypothesis matrix illustrated with a three-level factor</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ch-contr.html"><a href="ch-contr.html#sumcontrasts"><i class="fa fa-check"></i><b>6.2.1</b>  Sum contrasts</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>6.2.2</b> The  hypothesis matrix</a></li>
<li class="chapter" data-level="6.2.3" data-path="ch-contr.html"><a href="ch-contr.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>6.2.3</b> Generating contrasts: The  <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-contr.html"><a href="ch-contr.html#sec-4levelFactor"><i class="fa fa-check"></i><b>6.3</b> Other types of contrasts: illustration with a factor of four levels</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ch-contr.html"><a href="ch-contr.html#repeatedcontrasts"><i class="fa fa-check"></i><b>6.3.1</b>  Repeated contrasts</a></li>
<li class="chapter" data-level="6.3.2" data-path="ch-contr.html"><a href="ch-contr.html#helmertcontrasts"><i class="fa fa-check"></i><b>6.3.2</b>  Helmert contrasts</a></li>
<li class="chapter" data-level="6.3.3" data-path="ch-contr.html"><a href="ch-contr.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>6.3.3</b> Contrasts in linear regression analysis: The design or  model matrix</a></li>
<li class="chapter" data-level="6.3.4" data-path="ch-contr.html"><a href="ch-contr.html#polynomialContrasts"><i class="fa fa-check"></i><b>6.3.4</b>  Polynomial contrasts</a></li>
<li class="chapter" data-level="6.3.5" data-path="ch-contr.html"><a href="ch-contr.html#an-alternative-to-contrasts-monotonic-effects"><i class="fa fa-check"></i><b>6.3.5</b> An alternative to contrasts:  Monotonic effects</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ch-contr.html"><a href="ch-contr.html#nonOrthogonal"><i class="fa fa-check"></i><b>6.4</b> What makes a good set of contrasts?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ch-contr.html"><a href="ch-contr.html#centered-contrasts"><i class="fa fa-check"></i><b>6.4.1</b>  Centered contrasts</a></li>
<li class="chapter" data-level="6.4.2" data-path="ch-contr.html"><a href="ch-contr.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>6.4.2</b>  Orthogonal contrasts</a></li>
<li class="chapter" data-level="6.4.3" data-path="ch-contr.html"><a href="ch-contr.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> The role of the  intercept in  non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ch-contr.html"><a href="ch-contr.html#computing-condition-means-from-estimated-contrasts"><i class="fa fa-check"></i><b>6.5</b> Computing condition means from estimated contrasts</a></li>
<li class="chapter" data-level="6.6" data-path="ch-contr.html"><a href="ch-contr.html#summary-5"><i class="fa fa-check"></i><b>6.6</b> Summary</a></li>
<li class="chapter" data-level="6.7" data-path="ch-contr.html"><a href="ch-contr.html#further-reading-3"><i class="fa fa-check"></i><b>6.7</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html"><i class="fa fa-check"></i><b>7</b> Contrast coding with two predictor variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-MR-ANOVA"><i class="fa fa-check"></i><b>7.1</b> Contrast coding in a factorial <span class="math inline">\(2 \times 2\)</span> design</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#nestedEffects"><i class="fa fa-check"></i><b>7.1.1</b>  Nested effects</a></li>
<li class="chapter" data-level="7.1.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>7.1.2</b>  Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-contrast-covariate"><i class="fa fa-check"></i><b>7.2</b> One factor and one  covariate</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>7.2.1</b> Estimating a  group difference and controlling for a covariate</a></li>
<li class="chapter" data-level="7.2.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>7.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-interactions-NLM"><i class="fa fa-check"></i><b>7.3</b> Interactions in generalized linear models (with non-linear link functions) and non-linear models</a></li>
<li class="chapter" data-level="7.4" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#summary-6"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#further-reading-4"><i class="fa fa-check"></i><b>7.5</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>III Advanced models with Stan</b></span></li>
<li class="chapter" data-level="8" data-path="ch-introstan.html"><a href="ch-introstan.html"><i class="fa fa-check"></i><b>8</b> Introduction to the probabilistic programming language Stan</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch-introstan.html"><a href="ch-introstan.html#stan-syntax"><i class="fa fa-check"></i><b>8.1</b> Stan syntax</a></li>
<li class="chapter" data-level="8.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-firststan"><i class="fa fa-check"></i><b>8.2</b> A first simple example with Stan:  Normal likelihood</a></li>
<li class="chapter" data-level="8.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-clozestan"><i class="fa fa-check"></i><b>8.3</b> Another simple example:  Cloze probability with Stan with the  binomial likelihood</a></li>
<li class="chapter" data-level="8.4" data-path="ch-introstan.html"><a href="ch-introstan.html#regression-models-in-stan"><i class="fa fa-check"></i><b>8.4</b>  Regression models in Stan</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-pupilstan"><i class="fa fa-check"></i><b>8.4.1</b> A first  linear regression in Stan: Does attentional load affect  pupil size?</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-interstan"><i class="fa fa-check"></i><b>8.4.2</b>  Interactions in Stan: Does attentional load interact with trial number affecting  pupil size?</a></li>
<li class="chapter" data-level="8.4.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-logisticstan"><i class="fa fa-check"></i><b>8.4.3</b>  Logistic regression in Stan: Does set size and trial affect free recall?</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-introstan.html"><a href="ch-introstan.html#summary-7"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="ch-introstan.html"><a href="ch-introstan.html#further-reading-5"><i class="fa fa-check"></i><b>8.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-complexstan.html"><a href="ch-complexstan.html"><i class="fa fa-check"></i><b>9</b> Hierarchical models and reparameterization </a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-hierstan"><i class="fa fa-check"></i><b>9.1</b> Hierarchical models with Stan</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#varying-intercept-model-with-stan"><i class="fa fa-check"></i><b>9.1.1</b> Varying intercept model with Stan</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-uncorrstan"><i class="fa fa-check"></i><b>9.1.2</b> Uncorrelated  varying intercept and slopes model with Stan</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-corrstan"><i class="fa fa-check"></i><b>9.1.3</b>  Correlated varying intercept varying slopes model</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-crosscorrstan"><i class="fa fa-check"></i><b>9.1.4</b> By-subject and by-items correlated varying intercept varying slopes model</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#summary-8"><i class="fa fa-check"></i><b>9.2</b> Summary</a></li>
<li class="chapter" data-level="9.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#further-reading-6"><i class="fa fa-check"></i><b>9.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-custom.html"><a href="ch-custom.html"><i class="fa fa-check"></i><b>10</b> Custom distributions in Stan</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch-custom.html"><a href="ch-custom.html#sec-change"><i class="fa fa-check"></i><b>10.1</b> A change of variables with the reciprocal normal distribution</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="ch-custom.html"><a href="ch-custom.html#scaling-a-probability-density-with-the-jacobian-adjustment"><i class="fa fa-check"></i><b>10.1.1</b> Scaling a probability density with the Jacobian adjustment</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ch-custom.html"><a href="ch-custom.html#sec-validSBC"><i class="fa fa-check"></i><b>10.2</b>  Validation of a computed posterior distribution</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ch-custom.html"><a href="ch-custom.html#the-simulation-based-calibration-procedure"><i class="fa fa-check"></i><b>10.2.1</b> The  simulation-based calibration procedure</a></li>
<li class="chapter" data-level="10.2.2" data-path="ch-custom.html"><a href="ch-custom.html#an-example-where-simulation-based-calibration-reveals-a-problem"><i class="fa fa-check"></i><b>10.2.2</b> An example where simulation-based calibration reveals a problem</a></li>
<li class="chapter" data-level="10.2.3" data-path="ch-custom.html"><a href="ch-custom.html#issues-with-and-limitations-of-simulation-based-calibration"><i class="fa fa-check"></i><b>10.2.3</b> Issues with and limitations of simulation-based calibration</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ch-custom.html"><a href="ch-custom.html#another-custom-distribution-the-exponential-distribution-implemented-manually"><i class="fa fa-check"></i><b>10.3</b> Another  custom distribution: The exponential distribution  implemented manually</a></li>
<li class="chapter" data-level="10.4" data-path="ch-custom.html"><a href="ch-custom.html#summary-9"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
<li class="chapter" data-level="10.5" data-path="ch-custom.html"><a href="ch-custom.html#further-reading-7"><i class="fa fa-check"></i><b>10.5</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence synthesis and measurements with error</b></span></li>
<li class="chapter" data-level="11" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>11</b>  Meta-analysis and  measurement error models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch-remame.html"><a href="ch-remame.html#meta-analysis"><i class="fa fa-check"></i><b>11.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ch-remame.html"><a href="ch-remame.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension"><i class="fa fa-check"></i><b>11.1.1</b> A meta-analysis of similarity-based interference in sentence comprehension</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-remame.html"><a href="ch-remame.html#measurement-error-models"><i class="fa fa-check"></i><b>11.2</b>  Measurement-error models</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ch-remame.html"><a href="ch-remame.html#accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency"><i class="fa fa-check"></i><b>11.2.1</b> Accounting for measurement error in individual differences in working memory capacity and reading fluency</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-remame.html"><a href="ch-remame.html#summary-10"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
<li class="chapter" data-level="11.4" data-path="ch-remame.html"><a href="ch-remame.html#further-reading-8"><i class="fa fa-check"></i><b>11.4</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>V Model comparison</b></span></li>
<li class="chapter" data-level="12" data-path="ch-comparison.html"><a href="ch-comparison.html"><i class="fa fa-check"></i><b>12</b> Introduction to model comparison</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch-comparison.html"><a href="ch-comparison.html#prior-predictive-vs.-posterior-predictive-model-comparison"><i class="fa fa-check"></i><b>12.1</b> Prior predictive vs. posterior predictive model comparison</a></li>
<li class="chapter" data-level="12.2" data-path="ch-comparison.html"><a href="ch-comparison.html#some-important-points-to-consider-when-comparing-models"><i class="fa fa-check"></i><b>12.2</b> Some important points to consider when comparing models</a></li>
<li class="chapter" data-level="12.3" data-path="ch-comparison.html"><a href="ch-comparison.html#further-reading-9"><i class="fa fa-check"></i><b>12.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>13</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ch-bf.html"><a href="ch-bf.html#hypothesis-testing-using-the-bayes-factor"><i class="fa fa-check"></i><b>13.1</b> Hypothesis testing using the Bayes factor</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ch-bf.html"><a href="ch-bf.html#marginal-likelihood"><i class="fa fa-check"></i><b>13.1.1</b> Marginal likelihood</a></li>
<li class="chapter" data-level="13.1.2" data-path="ch-bf.html"><a href="ch-bf.html#the-bayes-factor"><i class="fa fa-check"></i><b>13.1.2</b> The Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-N400BF"><i class="fa fa-check"></i><b>13.2</b> Examining the N400 effect with the Bayes factor</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ch-bf.html"><a href="ch-bf.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>13.2.1</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="13.2.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFnonnested"><i class="fa fa-check"></i><b>13.2.2</b>  Non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ch-bf.html"><a href="ch-bf.html#the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest"><i class="fa fa-check"></i><b>13.3</b> The influence of the priors on Bayes factors: beyond the effect of interest</a></li>
<li class="chapter" data-level="13.4" data-path="ch-bf.html"><a href="ch-bf.html#sec-stanBF"><i class="fa fa-check"></i><b>13.4</b>  The Bayes factor in Stan</a></li>
<li class="chapter" data-level="13.5" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-and-in-practice"><i class="fa fa-check"></i><b>13.5</b> Bayes factors in theory and in practice</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-stability-and-accuracy"><i class="fa fa-check"></i><b>13.5.1</b> Bayes factors in theory: Stability and  accuracy</a></li>
<li class="chapter" data-level="13.5.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFvar"><i class="fa fa-check"></i><b>13.5.2</b> Bayes factors in practice: Variability with the data</a></li>
<li class="chapter" data-level="13.5.3" data-path="ch-bf.html"><a href="ch-bf.html#sec-caution"><i class="fa fa-check"></i><b>13.5.3</b> A cautionary note about Bayes factors</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="ch-bf.html"><a href="ch-bf.html#sample-size-determination-using-bayes-factors"><i class="fa fa-check"></i><b>13.6</b> Sample size determination using Bayes factors</a></li>
<li class="chapter" data-level="13.7" data-path="ch-bf.html"><a href="ch-bf.html#summary-11"><i class="fa fa-check"></i><b>13.7</b> Summary</a></li>
<li class="chapter" data-level="13.8" data-path="ch-bf.html"><a href="ch-bf.html#further-reading-10"><i class="fa fa-check"></i><b>13.8</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ch-cv.html"><a href="ch-cv.html"><i class="fa fa-check"></i><b>14</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch-cv.html"><a href="ch-cv.html#the-expected-log-predictive-density-of-a-model"><i class="fa fa-check"></i><b>14.1</b> The expected log predictive density of a model</a></li>
<li class="chapter" data-level="14.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-and-leave-one-out-cross-validation"><i class="fa fa-check"></i><b>14.2</b> K-fold and leave-one-out cross-validation</a></li>
<li class="chapter" data-level="14.3" data-path="ch-cv.html"><a href="ch-cv.html#testing-the-n400-effect-using-cross-validation"><i class="fa fa-check"></i><b>14.3</b> Testing the N400 effect using cross-validation</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-psis-loo"><i class="fa fa-check"></i><b>14.3.1</b> Cross-validation with PSIS-LOO</a></li>
<li class="chapter" data-level="14.3.2" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-k-fold"><i class="fa fa-check"></i><b>14.3.2</b> Cross-validation with K-fold</a></li>
<li class="chapter" data-level="14.3.3" data-path="ch-cv.html"><a href="ch-cv.html#leave-one-group-out-cross-validation"><i class="fa fa-check"></i><b>14.3.3</b> Leave-one-group-out cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ch-cv.html"><a href="ch-cv.html#sec-logcv"><i class="fa fa-check"></i><b>14.4</b>  Comparing different likelihoods with cross-validation</a></li>
<li class="chapter" data-level="14.5" data-path="ch-cv.html"><a href="ch-cv.html#sec-issuesCV"><i class="fa fa-check"></i><b>14.5</b> Issues with cross-validation</a></li>
<li class="chapter" data-level="14.6" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-in-stan"><i class="fa fa-check"></i><b>14.6</b> Cross-validation in Stan</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="ch-cv.html"><a href="ch-cv.html#psis-loo-cv-in-stan"><i class="fa fa-check"></i><b>14.6.1</b>  PSIS-LOO-CV in Stan</a></li>
<li class="chapter" data-level="14.6.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-cv-in-stan"><i class="fa fa-check"></i><b>14.6.2</b>  K-fold-CV in Stan</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="ch-cv.html"><a href="ch-cv.html#summary-12"><i class="fa fa-check"></i><b>14.7</b> Summary</a></li>
<li class="chapter" data-level="14.8" data-path="ch-cv.html"><a href="ch-cv.html#further-reading-11"><i class="fa fa-check"></i><b>14.8</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>VI Cognitive modeling with Stan</b></span></li>
<li class="chapter" data-level="15" data-path="ch-cogmod.html"><a href="ch-cogmod.html"><i class="fa fa-check"></i><b>15</b> Introduction to cognitive modeling</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch-cogmod.html"><a href="ch-cogmod.html#what-characterizes-a-computational-cognitive-model"><i class="fa fa-check"></i><b>15.1</b> What characterizes a computational cognitive model?</a></li>
<li class="chapter" data-level="15.2" data-path="ch-cogmod.html"><a href="ch-cogmod.html#some-advantages-of-taking-the-latent-variable-modeling-approach"><i class="fa fa-check"></i><b>15.2</b> Some advantages of taking the latent-variable modeling approach</a></li>
<li class="chapter" data-level="15.3" data-path="ch-cogmod.html"><a href="ch-cogmod.html#types-of-computational-cognitive-model"><i class="fa fa-check"></i><b>15.3</b> Types of computational cognitive model</a></li>
<li class="chapter" data-level="15.4" data-path="ch-cogmod.html"><a href="ch-cogmod.html#summary-13"><i class="fa fa-check"></i><b>15.4</b> Summary</a></li>
<li class="chapter" data-level="15.5" data-path="ch-cogmod.html"><a href="ch-cogmod.html#further-reading-12"><i class="fa fa-check"></i><b>15.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-MPT.html"><a href="ch-MPT.html"><i class="fa fa-check"></i><b>16</b> Multinomial processing trees</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-multiple-categorical-responses"><i class="fa fa-check"></i><b>16.1</b> Modeling  multiple categorical responses</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mult"><i class="fa fa-check"></i><b>16.1.1</b> A model for multiple responses using the multinomial likelihood</a></li>
<li class="chapter" data-level="16.1.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-cat"><i class="fa fa-check"></i><b>16.1.2</b> A model for multiple responses using the categorical distribution</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-picture-naming-abilities-in-aphasia-with-mpt-models"><i class="fa fa-check"></i><b>16.2</b> Modeling picture naming abilities in aphasia with MPT models</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ch-MPT.html"><a href="ch-MPT.html#calculation-of-the-probabilities-in-the-mpt-branches"><i class="fa fa-check"></i><b>16.2.1</b> Calculation of the probabilities in the MPT branches</a></li>
<li class="chapter" data-level="16.2.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mpt-data"><i class="fa fa-check"></i><b>16.2.2</b> A simple MPT model</a></li>
<li class="chapter" data-level="16.2.3" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-reg"><i class="fa fa-check"></i><b>16.2.3</b> An MPT model assuming by-item variability</a></li>
<li class="chapter" data-level="16.2.4" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-h"><i class="fa fa-check"></i><b>16.2.4</b> A  hierarchical MPT</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ch-MPT.html"><a href="ch-MPT.html#summary-14"><i class="fa fa-check"></i><b>16.3</b> Summary</a></li>
<li class="chapter" data-level="16.4" data-path="ch-MPT.html"><a href="ch-MPT.html#further-reading-13"><i class="fa fa-check"></i><b>16.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-mixture.html"><a href="ch-mixture.html"><i class="fa fa-check"></i><b>17</b> Mixture models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ch-mixture.html"><a href="ch-mixture.html#a-mixture-model-of-the-speed-accuracy-trade-off-the-fast-guess-model-account"><i class="fa fa-check"></i><b>17.1</b> A mixture model of the speed-accuracy trade-off: The fast-guess model account</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="ch-mixture.html"><a href="ch-mixture.html#the-global-motion-detection-task"><i class="fa fa-check"></i><b>17.1.1</b> The global motion detection task</a></li>
<li class="chapter" data-level="17.1.2" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-simplefastguess"><i class="fa fa-check"></i><b>17.1.2</b> A very simple implementation of the fast-guess model</a></li>
<li class="chapter" data-level="17.1.3" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-multmix"><i class="fa fa-check"></i><b>17.1.3</b> A  multivariate implementation of the fast-guess model</a></li>
<li class="chapter" data-level="17.1.4" data-path="ch-mixture.html"><a href="ch-mixture.html#an-implementation-of-the-fast-guess-model-that-takes-instructions-into-account"><i class="fa fa-check"></i><b>17.1.4</b> An implementation of the fast-guess model that takes instructions into account</a></li>
<li class="chapter" data-level="17.1.5" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-fastguessh"><i class="fa fa-check"></i><b>17.1.5</b> A  hierarchical implementation of the fast-guess model</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="ch-mixture.html"><a href="ch-mixture.html#summary-15"><i class="fa fa-check"></i><b>17.2</b> Summary</a></li>
<li class="chapter" data-level="17.3" data-path="ch-mixture.html"><a href="ch-mixture.html#further-reading-14"><i class="fa fa-check"></i><b>17.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html"><i class="fa fa-check"></i><b>18</b> A simple accumulator model to account for choice response time</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#modeling-a-lexical-decision-task"><i class="fa fa-check"></i><b>18.1</b> Modeling a lexical decision task</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-acccoding"><i class="fa fa-check"></i><b>18.1.1</b> Modeling the lexical decision task with the log-normal race model</a></li>
<li class="chapter" data-level="18.1.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-genaccum"><i class="fa fa-check"></i><b>18.1.2</b> A generative model for a race between accumulators</a></li>
<li class="chapter" data-level="18.1.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#fitting-the-log-normal-race-model"><i class="fa fa-check"></i><b>18.1.3</b> Fitting the log-normal race model</a></li>
<li class="chapter" data-level="18.1.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-lognormalh"><i class="fa fa-check"></i><b>18.1.4</b> A hierarchical implementation of the log-normal race model</a></li>
<li class="chapter" data-level="18.1.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-contaminant"><i class="fa fa-check"></i><b>18.1.5</b> Dealing with  contaminant responses</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#posterior-predictive-check-with-the-quantile-probability-plots"><i class="fa fa-check"></i><b>18.2</b> Posterior predictive check with the quantile probability plots</a></li>
<li class="chapter" data-level="18.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#summary-16"><i class="fa fa-check"></i><b>18.3</b> Summary</a></li>
<li class="chapter" data-level="18.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#further-reading-15"><i class="fa fa-check"></i><b>18.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-closing.html"><a href="ch-closing.html"><i class="fa fa-check"></i><b>19</b> In closing</a></li>
<li class="appendix"><span><b>Online materials</b></span></li>
<li class="chapter" data-level="A" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html"><i class="fa fa-check"></i><b>A</b> Regression models with <code>brms</code> - Extended</a>
<ul>
<li class="chapter" data-level="A.1" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-efficientpriorpd"><i class="fa fa-check"></i><b>A.1</b> An efficient function for generating prior predictive distributions in R</a></li>
<li class="chapter" data-level="A.2" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-truncation"><i class="fa fa-check"></i><b>A.2</b> Truncated distributions</a></li>
<li class="chapter" data-level="A.3" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-intercept"><i class="fa fa-check"></i><b>A.3</b> Intercepts in <code>brms</code></a></li>
<li class="chapter" data-level="A.4" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-lognormal"><i class="fa fa-check"></i><b>A.4</b> Understanding the log-normal likelihood</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#log-normal-distributions-everywhere"><i class="fa fa-check"></i><b>A.4.1</b> Log-normal distributions everywhere</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-priorR"><i class="fa fa-check"></i><b>A.5</b> Prior predictive checks in R</a></li>
<li class="chapter" data-level="A.6" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-exch"><i class="fa fa-check"></i><b>A.6</b> Finitely exchangeable random variables</a></li>
<li class="chapter" data-level="A.7" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-matrixHierachicalModel"><i class="fa fa-check"></i><b>A.7</b> The Matrix Formulation of Hierarchical Models (the Laird-Ware form)</a></li>
<li class="chapter" data-level="A.8" data-path="regression-models-with-brms---extended.html"><a href="regression-models-with-brms---extended.html#app-cTreatGM"><i class="fa fa-check"></i><b>A.8</b> Treatment contrast with intercept as the grand mean</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html"><i class="fa fa-check"></i><b>B</b> Advanced models with Stan - Extended</a>
<ul>
<li class="chapter" data-level="B.1" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-target"><i class="fa fa-check"></i><b>B.1</b> What does <code>target</code> do in Stan models?</a></li>
<li class="chapter" data-level="B.2" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-tilde"><i class="fa fa-check"></i><b>B.2</b> Explicitly incrementing the log probability function (<code>target</code>) vs. using the sampling or distribution <code>~</code> notation</a></li>
<li class="chapter" data-level="B.3" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-cmdstanr"><i class="fa fa-check"></i><b>B.3</b> An alternative R interface to Stan: <code>cmdstanr</code></a></li>
<li class="chapter" data-level="B.4" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-stancontainers"><i class="fa fa-check"></i><b>B.4</b> Matrix, vector, or array in Stan?</a></li>
<li class="chapter" data-level="B.5" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-noncenterparam"><i class="fa fa-check"></i><b>B.5</b> A simple non-centered parameterization</a></li>
<li class="chapter" data-level="B.6" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-cholesky"><i class="fa fa-check"></i><b>B.6</b> Cholesky factorization for reparameterizing hierarchical models with correlations between adjustments to different parameters</a></li>
<li class="chapter" data-level="B.7" data-path="advanced-models-with-stan---extended.html"><a href="advanced-models-with-stan---extended.html#app-sbc"><i class="fa fa-check"></i><b>B.7</b> Different rank visualizations and the <code>SBC</code> package.</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="evidence-synthesis-and-measurements-with-error---extended.html"><a href="evidence-synthesis-and-measurements-with-error---extended.html"><i class="fa fa-check"></i><b>C</b> Evidence synthesis and measurements with error - Extended</a>
<ul>
<li class="chapter" data-level="C.1" data-path="evidence-synthesis-and-measurements-with-error---extended.html"><a href="evidence-synthesis-and-measurements-with-error---extended.html#app-sigmatrue"><i class="fa fa-check"></i><b>C.1</b> What happens if we set <code>sigma = TRUE</code> in <code>resp_se()</code> function in <code>brms</code>?</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html"><i class="fa fa-check"></i><b>D</b> Model comparison - Extended</a>
<ul>
<li class="chapter" data-level="D.1" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-null"><i class="fa fa-check"></i><b>D.1</b> Credible intervals should not be used to reject a null hypothesis</a></li>
<li class="chapter" data-level="D.2" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-likR"><i class="fa fa-check"></i><b>D.2</b> The likelihood ratio vs the Bayes factor</a></li>
<li class="chapter" data-level="D.3" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-integral"><i class="fa fa-check"></i><b>D.3</b> Approximation of the (expected) log predictive density of a model without integration</a></li>
<li class="chapter" data-level="D.4" data-path="model-comparison---extended.html"><a href="model-comparison---extended.html#app-CV-alg"><i class="fa fa-check"></i><b>D.4</b> The cross-validation algorithm for the expected log predictive density of a model</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="ch-priors.html"><a href="ch-priors.html"><i class="fa fa-check"></i><b>E</b> The Art and Science of Prior Elicitation</a>
<ul>
<li class="chapter" data-level="E.1" data-path="ch-priors.html"><a href="ch-priors.html#sec-simpleexamplepriors"><i class="fa fa-check"></i><b>E.1</b> Eliciting priors from oneself for a self-paced reading study: An example</a>
<ul>
<li class="chapter" data-level="E.1.1" data-path="ch-priors.html"><a href="ch-priors.html#an-example-english-relative-clauses"><i class="fa fa-check"></i><b>E.1.1</b> An example: English  relative clauses</a></li>
<li class="chapter" data-level="E.1.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-intercept"><i class="fa fa-check"></i><b>E.1.2</b> Eliciting a prior for the intercept</a></li>
<li class="chapter" data-level="E.1.3" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-slope"><i class="fa fa-check"></i><b>E.1.3</b> Eliciting a prior for the slope</a></li>
<li class="chapter" data-level="E.1.4" data-path="ch-priors.html"><a href="ch-priors.html#sec-varcomppriors"><i class="fa fa-check"></i><b>E.1.4</b> Eliciting priors for the  variance components</a></li>
</ul></li>
<li class="chapter" data-level="E.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-priors-from-experts"><i class="fa fa-check"></i><b>E.2</b>  Eliciting priors from experts</a></li>
<li class="chapter" data-level="E.3" data-path="ch-priors.html"><a href="ch-priors.html#deriving-priors-from-meta-analyses"><i class="fa fa-check"></i><b>E.3</b> Deriving priors from  meta-analyses</a></li>
<li class="chapter" data-level="E.4" data-path="ch-priors.html"><a href="ch-priors.html#using-previous-experiments-posteriors-as-priors-for-a-new-study"><i class="fa fa-check"></i><b>E.4</b> Using previous experiments’  posteriors as priors for a new study</a></li>
<li class="chapter" data-level="E.5" data-path="ch-priors.html"><a href="ch-priors.html#summary-17"><i class="fa fa-check"></i><b>E.5</b> Summary</a></li>
<li class="chapter" data-level="E.6" data-path="ch-priors.html"><a href="ch-priors.html#further-reading-16"><i class="fa fa-check"></i><b>E.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="ch-workflow.html"><a href="ch-workflow.html"><i class="fa fa-check"></i><b>F</b> Workflow</a>
<ul>
<li class="chapter" data-level="F.1" data-path="ch-workflow.html"><a href="ch-workflow.html#building-a-model"><i class="fa fa-check"></i><b>F.1</b>  Building a model</a></li>
<li class="chapter" data-level="F.2" data-path="ch-workflow.html"><a href="ch-workflow.html#principled-questions-to-ask-on-a-model"><i class="fa fa-check"></i><b>F.2</b> Principled questions to ask on a model</a>
<ul>
<li class="chapter" data-level="F.2.1" data-path="ch-workflow.html"><a href="ch-workflow.html#checking-whether-assumptions-are-consistent-with-domain-expertise-prior-predictive-checks"><i class="fa fa-check"></i><b>F.2.1</b>  Checking whether assumptions are consistent with  domain expertise: Prior predictive checks</a></li>
<li class="chapter" data-level="F.2.2" data-path="ch-workflow.html"><a href="ch-workflow.html#testing-for-correct-posterior-approximations-checks-of-computational-faithfulness"><i class="fa fa-check"></i><b>F.2.2</b>  Testing for correct posterior approximations: Checks of computational faithfulness</a></li>
<li class="chapter" data-level="F.2.3" data-path="ch-workflow.html"><a href="ch-workflow.html#sensitivity-of-the-model"><i class="fa fa-check"></i><b>F.2.3</b>  Sensitivity of the model</a></li>
<li class="chapter" data-level="F.2.4" data-path="ch-workflow.html"><a href="ch-workflow.html#does-the-model-adequately-capture-the-dataposterior-predictive-checks"><i class="fa fa-check"></i><b>F.2.4</b>  Does the model adequately capture the data?–Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="F.3" data-path="ch-workflow.html"><a href="ch-workflow.html#further-reading-17"><i class="fa fa-check"></i><b>F.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>G</b> Exercises</a>
<ul>
<li class="chapter" data-level="G.1" data-path="exercises.html"><a href="exercises.html#sec-Foundationsexercises"><i class="fa fa-check"></i><b>G.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="G.1.1" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisespnormPart1"><i class="fa fa-check"></i><b>G.1.1</b> Practice using the <code>pnorm()</code> function–Part 1</a></li>
<li class="chapter" data-level="G.1.2" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisespnormPart2"><i class="fa fa-check"></i><b>G.1.2</b> Practice using the <code>pnorm()</code> function–Part 2</a></li>
<li class="chapter" data-level="G.1.3" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisespnormPart3"><i class="fa fa-check"></i><b>G.1.3</b> Practice using the <code>pnorm()</code> function–Part 3</a></li>
<li class="chapter" data-level="G.1.4" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisesqnormPart1"><i class="fa fa-check"></i><b>G.1.4</b> Practice using the <code>qnorm()</code> function–Part 1</a></li>
<li class="chapter" data-level="G.1.5" data-path="exercises.html"><a href="exercises.html#exr:FoundationsexercisesqnormPart2"><i class="fa fa-check"></i><b>G.1.5</b> Practice using the <code>qnorm()</code> function–Part 2</a></li>
<li class="chapter" data-level="G.1.6" data-path="exercises.html"><a href="exercises.html#exr:Foundationsexercisessamples1"><i class="fa fa-check"></i><b>G.1.6</b> Practice getting summaries from samples–Part 1</a></li>
<li class="chapter" data-level="G.1.7" data-path="exercises.html"><a href="exercises.html#exr:Foundationsexercisessamples2"><i class="fa fa-check"></i><b>G.1.7</b> Practice getting summaries from samples–Part 2.</a></li>
<li class="chapter" data-level="G.1.8" data-path="exercises.html"><a href="exercises.html#exr:Foundationsexercisesvcov1"><i class="fa fa-check"></i><b>G.1.8</b> Practice with a variance-covariance matrix for a bivariate distribution.</a></li>
</ul></li>
<li class="chapter" data-level="G.2" data-path="exercises.html"><a href="exercises.html#sec-BDAexercises"><i class="fa fa-check"></i><b>G.2</b> Introduction to Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="G.2.1" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesDerivingBayes"><i class="fa fa-check"></i><b>G.2.1</b> Deriving Bayes’ rule</a></li>
<li class="chapter" data-level="G.2.2" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj1"><i class="fa fa-check"></i><b>G.2.2</b> Conjugate forms 1</a></li>
<li class="chapter" data-level="G.2.3" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj2"><i class="fa fa-check"></i><b>G.2.3</b> Conjugate forms 2</a></li>
<li class="chapter" data-level="G.2.4" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj3"><i class="fa fa-check"></i><b>G.2.4</b> Conjugate forms 3</a></li>
<li class="chapter" data-level="G.2.5" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesConj4"><i class="fa fa-check"></i><b>G.2.5</b> Conjugate forms 4</a></li>
<li class="chapter" data-level="G.2.6" data-path="exercises.html"><a href="exercises.html#exr:BDAexercisesWeightedMean"><i class="fa fa-check"></i><b>G.2.6</b> The posterior mean is a weighted mean of the prior mean and the MLE (Poisson-Gamma conjugate case)</a></li>
</ul></li>
<li class="chapter" data-level="G.3" data-path="exercises.html"><a href="exercises.html#ex:compbda"><i class="fa fa-check"></i><b>G.3</b> Computational Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="G.3.1" data-path="exercises.html"><a href="exercises.html#exr:simulatedlinearmod"><i class="fa fa-check"></i><b>G.3.1</b> Check for parameter recovery in a linear model using simulated data.</a></li>
<li class="chapter" data-level="G.3.2" data-path="exercises.html"><a href="exercises.html#exr:linearmod"><i class="fa fa-check"></i><b>G.3.2</b> A simple linear model.</a></li>
<li class="chapter" data-level="G.3.3" data-path="exercises.html"><a href="exercises.html#exr:compbda-biasedpost"><i class="fa fa-check"></i><b>G.3.3</b> Revisiting the button-pressing example with different priors.</a></li>
<li class="chapter" data-level="G.3.4" data-path="exercises.html"><a href="exercises.html#exr:ppd"><i class="fa fa-check"></i><b>G.3.4</b> Posterior predictive checks with a log-normal model.</a></li>
<li class="chapter" data-level="G.3.5" data-path="exercises.html"><a href="exercises.html#exr:skew"><i class="fa fa-check"></i><b>G.3.5</b> A skew normal distribution.</a></li>
</ul></li>
<li class="chapter" data-level="G.4" data-path="exercises.html"><a href="exercises.html#sec-LMexercises"><i class="fa fa-check"></i><b>G.4</b> Bayesian regression models</a>
<ul>
<li class="chapter" data-level="G.4.1" data-path="exercises.html"><a href="exercises.html#exr:powerposing"><i class="fa fa-check"></i><b>G.4.1</b> A simple linear regression: Power posing and testosterone.</a></li>
<li class="chapter" data-level="G.4.2" data-path="exercises.html"><a href="exercises.html#exr:pupils"><i class="fa fa-check"></i><b>G.4.2</b> Another linear regression model: Revisiting attentional load effect on pupil size.</a></li>
<li class="chapter" data-level="G.4.3" data-path="exercises.html"><a href="exercises.html#exr:lognormalm"><i class="fa fa-check"></i><b>G.4.3</b> Log-normal model: Revisiting the effect of trial on finger tapping times.</a></li>
<li class="chapter" data-level="G.4.4" data-path="exercises.html"><a href="exercises.html#exr:reg-logistic"><i class="fa fa-check"></i><b>G.4.4</b> Logistic regression: Revisiting the effect of set size on free recall.</a></li>
<li class="chapter" data-level="G.4.5" data-path="exercises.html"><a href="exercises.html#exr:red"><i class="fa fa-check"></i><b>G.4.5</b> Red is the sexiest color.</a></li>
</ul></li>
<li class="chapter" data-level="G.5" data-path="exercises.html"><a href="exercises.html#sec-HLMexercises"><i class="fa fa-check"></i><b>G.5</b> Bayesian hierarchical models</a>
<ul>
<li class="chapter" data-level="G.5.1" data-path="exercises.html"><a href="exercises.html#exr:hierarchical-normal"><i class="fa fa-check"></i><b>G.5.1</b> A hierarchical model (normal likelihood) of cognitive load on pupil size.</a></li>
<li class="chapter" data-level="G.5.2" data-path="exercises.html"><a href="exercises.html#exr:hierarchical-logn"><i class="fa fa-check"></i><b>G.5.2</b> Are subject relatives easier to process than object relatives (log-normal likelihood)?</a></li>
<li class="chapter" data-level="G.5.3" data-path="exercises.html"><a href="exercises.html#exr:HLMExerciseMandarinRC"><i class="fa fa-check"></i><b>G.5.3</b> Relative clause processing in Mandarin Chinese</a></li>
<li class="chapter" data-level="G.5.4" data-path="exercises.html"><a href="exercises.html#exr:HLMExerciseEnglishAgrmt"><i class="fa fa-check"></i><b>G.5.4</b>  Agreement attraction in comprehension</a></li>
<li class="chapter" data-level="G.5.5" data-path="exercises.html"><a href="exercises.html#exr:ab"><i class="fa fa-check"></i><b>G.5.5</b>  Attentional blink (Bernoulli likelihood)</a></li>
<li class="chapter" data-level="G.5.6" data-path="exercises.html"><a href="exercises.html#exr:strooplogis-brms"><i class="fa fa-check"></i><b>G.5.6</b> Is there a Stroop effect in accuracy?</a></li>
<li class="chapter" data-level="G.5.7" data-path="exercises.html"><a href="exercises.html#exr:stroop-dist"><i class="fa fa-check"></i><b>G.5.7</b>  Distributional regression for the Stroop effect.</a></li>
<li class="chapter" data-level="G.5.8" data-path="exercises.html"><a href="exercises.html#exr:HLMExerciseGramCE"><i class="fa fa-check"></i><b>G.5.8</b> The  grammaticality illusion</a></li>
</ul></li>
<li class="chapter" data-level="G.6" data-path="exercises.html"><a href="exercises.html#sec-Contrastsexercises"><i class="fa fa-check"></i><b>G.6</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="G.6.1" data-path="exercises.html"><a href="exercises.html#exr:ContrastsPersian"><i class="fa fa-check"></i><b>G.6.1</b> Contrast coding for a four-condition design</a></li>
<li class="chapter" data-level="G.6.2" data-path="exercises.html"><a href="exercises.html#exr:ContrastsNPIHelmert"><i class="fa fa-check"></i><b>G.6.2</b>  Helmert coding for a six-condition design.</a></li>
<li class="chapter" data-level="G.6.3" data-path="exercises.html"><a href="exercises.html#exr:ContrastsNcomparisons"><i class="fa fa-check"></i><b>G.6.3</b> Number of possible comparisons in a single model.</a></li>
</ul></li>
<li class="chapter" data-level="G.7" data-path="exercises.html"><a href="exercises.html#sec-Contrasts2x2exercises"><i class="fa fa-check"></i><b>G.7</b> Contrast coding with two predictor variables</a>
<ul>
<li class="chapter" data-level="G.7.1" data-path="exercises.html"><a href="exercises.html#exr:ContrastsPersianANOVA"><i class="fa fa-check"></i><b>G.7.1</b> ANOVA coding for a four-condition design.</a></li>
<li class="chapter" data-level="G.7.2" data-path="exercises.html"><a href="exercises.html#exr:Contrasts2x2x2Dillon2013"><i class="fa fa-check"></i><b>G.7.2</b> ANOVA and nested comparisons in a <span class="math inline">\(2\times 2\times 2\)</span> design</a></li>
</ul></li>
<li class="chapter" data-level="G.8" data-path="exercises.html"><a href="exercises.html#introduction-to-the-probabilistic-programming-language-stan"><i class="fa fa-check"></i><b>G.8</b> Introduction to the probabilistic programming language Stan</a>
<ul>
<li class="chapter" data-level="G.8.1" data-path="exercises.html"><a href="exercises.html#exr:first"><i class="fa fa-check"></i><b>G.8.1</b> A very simple model.</a></li>
<li class="chapter" data-level="G.8.2" data-path="exercises.html"><a href="exercises.html#exr:badstan"><i class="fa fa-check"></i><b>G.8.2</b> Incorrect Stan model.</a></li>
<li class="chapter" data-level="G.8.3" data-path="exercises.html"><a href="exercises.html#exr:skewstan"><i class="fa fa-check"></i><b>G.8.3</b> Using Stan documentation.</a></li>
<li class="chapter" data-level="G.8.4" data-path="exercises.html"><a href="exercises.html#exr:linkfunction"><i class="fa fa-check"></i><b>G.8.4</b> The probit link function as an alternative to the logit function.</a></li>
<li class="chapter" data-level="G.8.5" data-path="exercises.html"><a href="exercises.html#exr:logisticstan"><i class="fa fa-check"></i><b>G.8.5</b> Examining the position of the queued word on recall.</a></li>
<li class="chapter" data-level="G.8.6" data-path="exercises.html"><a href="exercises.html#exr:fallacy"><i class="fa fa-check"></i><b>G.8.6</b> The conjunction fallacy.</a></li>
</ul></li>
<li class="chapter" data-level="G.9" data-path="exercises.html"><a href="exercises.html#hierarchical-models-and-reparameterization"><i class="fa fa-check"></i><b>G.9</b> Hierarchical models and reparameterization</a>
<ul>
<li class="chapter" data-level="G.9.1" data-path="exercises.html"><a href="exercises.html#exr:stroop"><i class="fa fa-check"></i><b>G.9.1</b> A log-normal model in Stan.</a></li>
<li class="chapter" data-level="G.9.2" data-path="exercises.html"><a href="exercises.html#exr:hierarchical-logn-stan"><i class="fa fa-check"></i><b>G.9.2</b> A by-subjects and by-items hierarchical model with a log-normal likelihood.</a></li>
<li class="chapter" data-level="G.9.3" data-path="exercises.html"><a href="exercises.html#exr:strooplogis"><i class="fa fa-check"></i><b>G.9.3</b> A hierarchical logistic regression with Stan.</a></li>
<li class="chapter" data-level="G.9.4" data-path="exercises.html"><a href="exercises.html#exr:distr-stan"><i class="fa fa-check"></i><b>G.9.4</b> A distributional regression model of the effect of cloze probability on the N400.</a></li>
</ul></li>
<li class="chapter" data-level="G.10" data-path="exercises.html"><a href="exercises.html#sec-customexercises"><i class="fa fa-check"></i><b>G.10</b> Custom distributions in Stan</a>
<ul>
<li class="chapter" data-level="G.10.1" data-path="exercises.html"><a href="exercises.html#exr:shiftedlogn"><i class="fa fa-check"></i><b>G.10.1</b> Fitting a  shifted log-normal distribution.</a></li>
<li class="chapter" data-level="G.10.2" data-path="exercises.html"><a href="exercises.html#exr:wald"><i class="fa fa-check"></i><b>G.10.2</b> Fitting a Wald distribution.</a></li>
</ul></li>
<li class="chapter" data-level="G.11" data-path="exercises.html"><a href="exercises.html#sec-REMAMEexercises"><i class="fa fa-check"></i><b>G.11</b> Meta-analysis and measurement error models</a>
<ul>
<li class="chapter" data-level="G.11.1" data-path="exercises.html"><a href="exercises.html#exr:REMAMEExtracting"><i class="fa fa-check"></i><b>G.11.1</b> Extracting estimates from published papers</a></li>
<li class="chapter" data-level="G.11.2" data-path="exercises.html"><a href="exercises.html#exr:REMAMEBuerki"><i class="fa fa-check"></i><b>G.11.2</b> A meta-analysis of picture-word interference data</a></li>
<li class="chapter" data-level="G.11.3" data-path="exercises.html"><a href="exercises.html#exr:REMAMELiEnglish"><i class="fa fa-check"></i><b>G.11.3</b> Measurement error model for English VOT data</a></li>
</ul></li>
<li class="chapter" data-level="G.12" data-path="exercises.html"><a href="exercises.html#introduction-to-model-comparison"><i class="fa fa-check"></i><b>G.12</b> Introduction to model comparison</a></li>
<li class="chapter" data-level="G.13" data-path="exercises.html"><a href="exercises.html#bayes-factors"><i class="fa fa-check"></i><b>G.13</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="G.13.1" data-path="exercises.html"><a href="exercises.html#exr:bysubjects"><i class="fa fa-check"></i><b>G.13.1</b> Is there evidence for differences in the effect of cloze probability among the subjects?</a></li>
<li class="chapter" data-level="G.13.2" data-path="exercises.html"><a href="exercises.html#exr:bf-logn"><i class="fa fa-check"></i><b>G.13.2</b> Is there evidence for the claim that English subject relative clauses are easier to process than object relative clauses?</a></li>
<li class="chapter" data-level="G.13.3" data-path="exercises.html"><a href="exercises.html#exr:bf-logistic"><i class="fa fa-check"></i><b>G.13.3</b> In the Grodner and Gibson 2005 data, in question-response accuracies, is there evidence for the claim that sentences with subject relative clauses are easier to comprehend?</a></li>
<li class="chapter" data-level="G.13.4" data-path="exercises.html"><a href="exercises.html#exr:lognstan"><i class="fa fa-check"></i><b>G.13.4</b> Bayes factor and bounded parameters using Stan.</a></li>
</ul></li>
<li class="chapter" data-level="G.14" data-path="exercises.html"><a href="exercises.html#cross-validation"><i class="fa fa-check"></i><b>G.14</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="G.14.1" data-path="exercises.html"><a href="exercises.html#exr:logcv"><i class="fa fa-check"></i><b>G.14.1</b> Predictive accuracy of the linear and the logarithm effect of cloze probability.</a></li>
<li class="chapter" data-level="G.14.2" data-path="exercises.html"><a href="exercises.html#exr:stroopcv"><i class="fa fa-check"></i><b>G.14.2</b> Log-normal model</a></li>
<li class="chapter" data-level="G.14.3" data-path="exercises.html"><a href="exercises.html#exr:logrec"><i class="fa fa-check"></i><b>G.14.3</b> Log-normal vs rec-normal model in Stan</a></li>
</ul></li>
<li class="chapter" data-level="G.15" data-path="exercises.html"><a href="exercises.html#introduction-to-cognitive-modeling"><i class="fa fa-check"></i><b>G.15</b> Introduction to cognitive modeling</a></li>
<li class="chapter" data-level="G.16" data-path="exercises.html"><a href="exercises.html#multinomial-processing-trees"><i class="fa fa-check"></i><b>G.16</b> Multinomial processing trees</a>
<ul>
<li class="chapter" data-level="G.16.1" data-path="exercises.html"><a href="exercises.html#exr:mult"><i class="fa fa-check"></i><b>G.16.1</b> Modeling multiple categorical responses.</a></li>
<li class="chapter" data-level="G.16.2" data-path="exercises.html"><a href="exercises.html#exr:mpt-mnm"><i class="fa fa-check"></i><b>G.16.2</b> An alternative MPT to model the picture recognition task.</a></li>
<li class="chapter" data-level="G.16.3" data-path="exercises.html"><a href="exercises.html#exr:edit-mpt-cat"><i class="fa fa-check"></i><b>G.16.3</b> A simple MPT model that incorporates phonological complexity in the picture recognition task.</a></li>
<li class="chapter" data-level="G.16.4" data-path="exercises.html"><a href="exercises.html#exr:mpt"><i class="fa fa-check"></i><b>G.16.4</b> A more hierarchical MPT.</a></li>
<li class="chapter" data-level="G.16.5" data-path="exercises.html"><a href="exercises.html#exr:mpt-adv"><i class="fa fa-check"></i><b>G.16.5</b> <strong>Advanced</strong>: Multinomial processing trees.</a></li>
</ul></li>
<li class="chapter" data-level="G.17" data-path="exercises.html"><a href="exercises.html#mixture-models"><i class="fa fa-check"></i><b>G.17</b> Mixture models</a>
<ul>
<li class="chapter" data-level="G.17.1" data-path="exercises.html"><a href="exercises.html#exr:pcorrect"><i class="fa fa-check"></i><b>G.17.1</b> Changes in the true point values.</a></li>
<li class="chapter" data-level="G.17.2" data-path="exercises.html"><a href="exercises.html#exr:mixhier"><i class="fa fa-check"></i><b>G.17.2</b> RTs in schizophrenic patients and control.</a></li>
<li class="chapter" data-level="G.17.3" data-path="exercises.html"><a href="exercises.html#exr:mixbias"><i class="fa fa-check"></i><b>G.17.3</b> <strong>Advanced:</strong> Guessing bias in the model.</a></li>
</ul></li>
<li class="chapter" data-level="G.18" data-path="exercises.html"><a href="exercises.html#a-simple-accumulator-model-to-account-for-choice-response-time"><i class="fa fa-check"></i><b>G.18</b> A simple accumulator model to account for choice response time</a>
<ul>
<li class="chapter" data-level="G.18.1" data-path="exercises.html"><a href="exercises.html#exr:recovery"><i class="fa fa-check"></i><b>G.18.1</b> Can we recover the true point values of the parameters of a model when dealing with a contaminant distribution?</a></li>
<li class="chapter" data-level="G.18.2" data-path="exercises.html"><a href="exercises.html#exr:lnracescale"><i class="fa fa-check"></i><b>G.18.2</b> Can the log-normal race model account for fast errors?</a></li>
<li class="chapter" data-level="G.18.3" data-path="exercises.html"><a href="exercises.html#exr:lnldt"><i class="fa fa-check"></i><b>G.18.3</b> Accounting for response time and choice in the lexical decision task using the log-normal race model.</a></li>
</ul></li>
<li class="chapter" data-level="G.19" data-path="exercises.html"><a href="exercises.html#sec-priorsexercises"><i class="fa fa-check"></i><b>G.19</b> The Art and Science of  Prior Elicitation</a>
<ul>
<li class="chapter" data-level="G.19.1" data-path="exercises.html"><a href="exercises.html#exr:PriorsRCs"><i class="fa fa-check"></i><b>G.19.1</b> Develop a plausible informative prior for the difference between object and subject relative clause reading times</a></li>
<li class="chapter" data-level="G.19.2" data-path="exercises.html"><a href="exercises.html#exr:Priorslocalcoherence"><i class="fa fa-check"></i><b>G.19.2</b> Extracting an informative prior from a published paper for a future study</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class="book-banner">
  <div class="banner-content">
    📚 Get the print version of the book from 
    <a href="https://www.routledge.com/Introduction-to-Bayesian-Data-Analysis-for-Cognitive-Science/Nicenboim-Schad-Vasishth/p/book/9780367359331" target="_blank" rel="noopener">CRC Press</a> or your favorite store.
    <button class="banner-close" onclick="this.parentElement.parentElement.style.display='none';" aria-label="Close banner">&times;</button>
  </div>
</div>
<div id="model-comparison---extended" class="section level1 hasAnchor" number="23">
<h1><span class="header-section-number">D</span> Model comparison - Extended<a href="model-comparison---extended.html#model-comparison---extended" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="app-null" class="section level2 hasAnchor" number="23.1">
<h2><span class="header-section-number">D.1</span> Credible intervals should not be used to reject a null hypothesis<a href="model-comparison---extended.html#app-null" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Researchers often incorrectly use  credible intervals for null hypothesis testing, that is, to test whether a parameter <span class="math inline">\(\beta\)</span> is zero or not. A common approach is to check whether zero is included in the 95% credible interval for the parameter <span class="math inline">\(\beta\)</span>; if it is, then the null hypothesis that the effect is zero is accepted; and if zero is outside the interval, then the null is rejected. For example, in a tutorial paper that two of the authors of this book wrote <span class="citation">(Nicenboim and Vasishth <a href="#ref-NicenboimVasishth2016" role="doc-biblioref">2016</a>)</span>, we incorrectly suggest that the credible interval can be used to reject the hypothesis that the <span class="math inline">\(\beta\)</span> is zero. This is generally not the correct approach.
The problem with this approach is that it is a heuristic that will work in some cases and might be misleading in others <span class="citation">(for an example, see Vasishth, Yadav, et al. <a href="#ref-SampleSizeCBB2021" role="doc-biblioref">2022</a>)</span>. Unfortunately, when they will work or not is in fact not well-defined.</p>
<p>Why is the credible-interval approach only a  heuristic?
One line of (generally incorrect) reasoning that justifies looking at the overlap between credible intervals and zero is based on the fact that the most likely values of <span class="math inline">\(\beta\)</span> lie within 95% credible interval.<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a> This entails that if zero is outside the interval, it must have a low probability density. This is true, but it’s meaningless: Regardless of where zero lies (or any point value), zero will have a probability mass of exactly zero since we are dealing with a continuous distribution.
The lack of overlap doesn’t tell us how much posterior probability the null model has.</p>
<p>A partial solution could be to look at a probability interval close to zero rather than zero (e.g., an interval of, say, <span class="math inline">\(-2\)</span> to <span class="math inline">\(2\)</span> ms in a response time experiment), so that we obtain a non-zero probability mass. While the lack of overlap would be slightly more informative, excluding a small interval can be problematic when the prior probability mass of that interval is very small to begin with (as was the case with the regularizing priors we assigned to our parameters). <span class="citation">Rouder, Haaf, and Vandekerckhove (<a href="#ref-rouder2018bayesian" role="doc-biblioref">2018</a>)</span> show that if prior probability mass is added to the point value zero using a  <em>spike-and-slab</em> prior (or if probability mass is added to the small interval close to zero if one considers that equivalent to the null model), looking at whether zero is in the 95% credible interval is analogous to the Bayes factor. Unfortunately, the <em>spike-and-slab</em> prior cannot be incorporated in Stan, because it relies on a discrete parameter. However, other programming tools (like PyMC3, JAGS, or Turing) can be used if such a prior needs to be fit; see the further readings at the end of the chapter.</p>
<p>Rather than looking at the overlap of the 95% credible interval, we might be tempted to conclude that there is evidence for an effect because the probability that a parameter is positive is high, that is <span class="math inline">\(P(\beta &gt; 0) &gt;&gt; 0.5\)</span>. However, the same logic from the previous paragraph renders this meaningless. Given that the probability mass of a point value, <span class="math inline">\(P(\beta = 0)\)</span>, is zero, what we can conclude from <span class="math inline">\(P(\beta &gt; 0) &gt;&gt; 0.5\)</span> is that <span class="math inline">\(\beta\)</span> is very likely to be positive rather than negative, but we can’t make any assertions about whether <span class="math inline">\(\beta\)</span> is exactly zero.</p>
<p>As we saw, the main problem with these heuristics is that they ignore that the  null model is a separate hypothesis. In many situations, the null hypothesis may not be of interest, and it might be perfectly fine to base our conclusions on credible intervals or <span class="math inline">\(P(\beta &gt; 0)\)</span>. The problem arises when these heuristics are used to provide  evidence in favor or against the null hypothesis. If one wants to argue about the evidence in favor of or against a null hypothesis, Bayes factors or cross-validation will be needed. These are discussed in the next two chapters.</p>
<p>How can credible intervals be used sensibly? The  region of practical equivalence  (ROPE) approach <span class="citation">(Spiegelhalter, Freedman, and Parmar <a href="#ref-spiegelhalter1994bayesian" role="doc-biblioref">1994</a>; Freedman, Lowe, and Macaskill <a href="#ref-Freedman1984" role="doc-biblioref">1984</a>; and, more recently, Kruschke and Liddell <a href="#ref-kruschke2018bayesian" role="doc-biblioref">2018</a>; Kruschke <a href="#ref-kruschke2014doing" role="doc-biblioref">2014</a>)</span> is a reasonable alternative to hypothesis testing and arguing for or against a null. This approach is related to the spike-and-slab discussion above. In the ROPE approach, one can define a range of values for a target parameter that is predicted before the data are seen. Of course, there has to be a principled justification for choosing this range a priori; an example of a principled justification would be the prior predictions of a computational model. Then, the overlap (or lack thereof) between this predicted range and the observed credible interval can be used to infer whether one has estimates consistent (or partly consistent) with the predicted range. Here, we are not ruling out any null hypothesis, and we are not using the credible interval to make a decision like “the null hypothesis is true/false.”</p>
<p>There is one situation where credible intervals could arguably be used to carry out a null hypothesis test. When priors are flat, credible intervals can show frequentist properties, making it reasonable to check whether zero falls within the credible interval. For example, <span class="citation">Newall et al. (<a href="#ref-newall2023evaluation" role="doc-biblioref">2023</a>)</span> use credible intervals as confidence intervals after calibration. They explicitly verify that 5% of the 95% credible intervals exclude zero when no effect exists. When using such an approach, a verification step would be necessary. We don’t discuss this approach any further because our aim in this part of the book is not to derive frequentist statistics from Bayesian analysis, but to use Bayesian methods for obtaining posterior probabilities and Bayes factors, focusing on Bayesian hypothesis testing.</p>
</div>
<div id="app-likR" class="section level2 hasAnchor" number="23.2">
<h2><span class="header-section-number">D.2</span> The likelihood ratio vs the Bayes factor<a href="model-comparison---extended.html#app-likR" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The  likelihood ratio test is a very similar, but  frequentist, approach to model comparison and hypothesis testing, which also compares the likelihood for the data given two different models. We show this here to highlight the similarities and differences between frequentist and Bayesian hypothesis testing. In contrast to the Bayes factor, the likelihood ratio test depends on the “best” (i.e., the maximum likelihood) estimate for the model parameter(s), that is, the model parameter <span class="math inline">\(\theta\)</span> occurs on the right side of the semi-colon in the equation for each likelihood. (An aside: we do not use a  conditional statement, i.e., the vertical bar, when talking about likelihood in the frequentist context; instead, we use a semi-colon. This is because the statement <span class="math inline">\(f(y\mid \theta)\)</span> is a conditional statement, implying that <span class="math inline">\(\theta\)</span> has a probability density function associated with it; in the frequentist framework, parameters cannot have a pdf associated with them, they are assumed to have fixed, point values.)</p>
<p><span class="math display">\[\begin{equation}
LikRat = \frac{P(\boldsymbol{y} ; \boldsymbol{\hat{\Theta}_1}, \mathcal{M}_1)}{P(\boldsymbol{y} ; \boldsymbol{\hat{\Theta}_2}, \mathcal{M}_2)}
\end{equation}\]</span></p>
<p>That means that in the likelihood ratio test, each model is tested on its ability to explain the data using this “best” estimate for the model parameter (here, the  maximum likelihood estimate <span class="math inline">\(\hat{\theta}\)</span>). That is, the likelihood ratio test reduces the full range of possible parameter values to a  point value, leading to overfitting the model to the maximum likelihood estimate  (MLE). If the MLE badly misestimates the true value of the parameter (point value), due to  Type M error <span class="citation">(Gelman and Carlin <a href="#ref-gelmancarlin" role="doc-biblioref">2014</a>)</span>, we could end up with a “significant” effect that is just a consequence of this misestimation <span class="citation">(it will not be consistently replicable; see Vasishth et al. <a href="#ref-VasishthMertzenJaegerGelman2018" role="doc-biblioref">2018</a> for an example)</span>. By contrast, the Bayes factor involves range hypotheses, which are implemented via  integrals over the model parameter; that is, it uses marginal likelihoods that are averaged across all possible prior values of the model parameter(s). Thus, if, due to Type M error, the best point estimate (the MLE) for the model parameter(s) is not very representative of the possible values for the model parameter(s), then Bayes factors will be superior to the frequentist likelihood ratio test (see exercise <a href="exercises.html#exr:bf-logn">G.13.2</a>). An additional difference, of course, is that Bayes factors rely on priors for estimating each model’s parameter(s), whereas the frequentist likelihood ratio test does not (and cannot) consider priors in the estimation of the best-fitting model parameter(s). As we show in this chapter, this has far-reaching consequences for Bayes factor-based model comparison.</p>
</div>
<div id="app-integral" class="section level2 hasAnchor" number="23.3">
<h2><span class="header-section-number">D.3</span> Approximation of the (expected) log predictive density of a model without integration<a href="model-comparison---extended.html#app-integral" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To compare models based on their predictive accuracy, we often use the expected log predictive density (<span class="math inline">\(elpd\)</span>), which evaluates how well a model’s predictions align with likely future data. In previous sections, we introduced the idea that the <span class="math inline">\(elpd\)</span> can be calculated by integrating over all possible future data, weighting predictions by their likelihood under the true data-generating process. However, because the true data-generating distribution, <span class="math inline">\(p_t\)</span>, is unknown, we instead use the observed data distribution as a proxy. This allows us to approximate the <span class="math inline">\(elpd\)</span> by summing the posterior predictive density of our observed data points, assuming they reflect the distribution of future data.</p>
<p>As an example, imagine that there are <span class="math inline">\(N\)</span> observations in an experiment. Suppose also that the  true generative process (which is normally always unknown to us) is a  Beta distribution:</p>
<p><span class="math display">\[\begin{equation}
p_t(y) = \mathit{ Beta}(y | 1, 3)
\end{equation}\]</span></p>
<p>Set <span class="math inline">\(N\)</span> and observe some simulated data <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb1162"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1162-1"><a href="model-comparison---extended.html#cb1162-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">10000</span></span>
<span id="cb1162-2"><a href="model-comparison---extended.html#cb1162-2" aria-hidden="true"></a>y_data &lt;-<span class="st"> </span><span class="kw">rbeta</span>(N, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb1162-3"><a href="model-comparison---extended.html#cb1162-3" aria-hidden="true"></a><span class="kw">head</span>(y_data)</span></code></pre></div>
<pre><code>## [1] 0.5239 0.0487 0.3031 0.0625 0.4269 0.0669</code></pre>
<p>Let’s say that we fit the Bayesian model <span class="math inline">\(\mathcal{M}_{1}\)</span>, and somehow, after getting the posterior distribution, we are able to derive the analytical form of its posterior predictive distribution for the model:</p>
<p><span class="math display">\[\begin{equation}
p(y_{pred} | y, \mathcal{M}_1) = \mathit{Beta}(y_{pred} | 2, 2)
\end{equation}\]</span></p>
<p>This distribution will tell us how likely different future observations will be, and it also entails that our future observations will be bounded by <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. (Any observation outside this range will have a probability density of zero).</p>
<p>Imagine that we could know the true distribution of the data, <span class="math inline">\(p_t\)</span>, which is conveniently close to our posterior predictive distribution. This means that Equation <a href="ch-cv.html#eq:elpd">(14.4)</a>, repeated below, is simple enough, and we know all its terms:</p>
<p><span class="math display">\[\begin{equation}
elpd = u(\mathcal{M}_1) = \int_{y_{pred}} p_t(y_{pred}) \log p(y_{pred} \mid y, \mathcal{M}_1)\, dy_{pred}
\end{equation}\]</span></p>
<p>We can compute this quantity in R. Notice that we don’t introduce the data at any point. However, the data had to be used when <code>p</code>, the posterior predictive distribution, was derived; we skipped that step here.</p>
<div class="sourceCode" id="cb1164"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1164-1"><a href="model-comparison---extended.html#cb1164-1" aria-hidden="true"></a><span class="co"># True distribution:</span></span>
<span id="cb1164-2"><a href="model-comparison---extended.html#cb1164-2" aria-hidden="true"></a>p_t &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">dbeta</span>(y, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb1164-3"><a href="model-comparison---extended.html#cb1164-3" aria-hidden="true"></a><span class="co"># Predictive distribution:</span></span>
<span id="cb1164-4"><a href="model-comparison---extended.html#cb1164-4" aria-hidden="true"></a>p &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">dbeta</span>(y, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb1164-5"><a href="model-comparison---extended.html#cb1164-5" aria-hidden="true"></a><span class="co"># Integration:</span></span>
<span id="cb1164-6"><a href="model-comparison---extended.html#cb1164-6" aria-hidden="true"></a>integrand &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">p_t</span>(y) <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(<span class="kw">p</span>(y))</span>
<span id="cb1164-7"><a href="model-comparison---extended.html#cb1164-7" aria-hidden="true"></a><span class="kw">integrate</span>(<span class="dt">f =</span> integrand, <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">1</span>)<span class="op">$</span>value</span></code></pre></div>
<pre><code>## [1] -0.375</code></pre>
<p>Because we will never know <code>p_t</code>, this integral can be approximated using the data, <code>y_data</code>. It is possible to approximate the integration without any reference to <code>p_t</code>; see Equation <a href="ch-cv.html#eq:elpdapprox">(14.5)</a>:</p>
<div class="sourceCode" id="cb1166"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb1166-1"><a href="model-comparison---extended.html#cb1166-1" aria-hidden="true"></a><span class="dv">1</span><span class="op">/</span>N <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">p</span>(y_data)))</span></code></pre></div>
<pre><code>## [1] -0.358</code></pre>
<p>The main problem with this approach is that we are using <code>y_data</code> twice, once to derive <code>p</code>, the predictive posterior distribution, and once for the approximation of <span class="math inline">\(elpd\)</span>. We’ll see that cross-validation approaches rely on deriving the posterior predictive distribution with part of the data, and estimating the approximation to <span class="math inline">\(elpd\)</span> with unseen data. (Don’t worry that we don’t know the analytical form of the posterior predictive distribution: we saw that we could generate samples from that distribution based on the distribution we use as the likelihood and our posterior samples.)</p>
</div>
<div id="app-CV-alg" class="section level2 hasAnchor" number="23.4">
<h2><span class="header-section-number">D.4</span> The cross-validation algorithm for the expected log predictive density of a model<a href="model-comparison---extended.html#app-CV-alg" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here we spell out the Bayesian  cross-validation algorithm in detail:</p>
<ol style="list-style-type: decimal">
<li><p>Split the data pseudo-randomly into <span class="math inline">\(K\)</span> held-out or validation sets <span class="math inline">\(D_k\)</span>, (where <span class="math inline">\(k=1,\dots,K\)</span>) that are a fraction of the original data, and <span class="math inline">\(K\)</span> training sets, <span class="math inline">\(D_{-k}\)</span>. The length of the held-out data vector <span class="math inline">\(D_k\)</span> is approximately <span class="math inline">\(1/K\)</span>-th the size of the full data set. It is common to use <span class="math inline">\(K=10\)</span> for K-fold-CV. For LOO-CV, K should be set to the number of observations.</p></li>
<li><p>Fit <span class="math inline">\(K\)</span> models using each of the <span class="math inline">\(K\)</span> training sets, and obtain posterior distributions <span class="math inline">\(p_{-k} (\Theta) = p(\Theta\mid D_{-k})\)</span>, where <span class="math inline">\(\Theta\)</span> is the vector of model parameters.</p></li>
<li><p>Each posterior distribution <span class="math inline">\(p(\Theta\mid D_{-k})\)</span> is used to compute the predictive accuracy (calculated as <span class="math inline">\(\widehat{elpd}\)</span>) for each held-out data-point <span class="math inline">\(y_n\)</span> in the vector <span class="math inline">\(D_{k}\)</span>:</p></li>
</ol>
<p><span class="math display">\[\begin{equation}
    \widehat{elpd}_n = \log p(y_n \mid D_{-k}) \text{ with } y_n \in D_k
  \end{equation}\]</span></p>
<p>Given that the posterior distribution <span class="math inline">\(p(\Theta\mid D_{-k})\)</span> is summarized by <span class="math inline">\(S\)</span> samples, the log predictive density for each data point <span class="math inline">\(y_n\)</span> in a data vector <span class="math inline">\(D_k\)</span> can be approximated as follows:</p>
<p><span class="math display" id="eq:pwkfold">\[\begin{equation}
    \widehat{elpd}_n = \log \left(\frac{1}{S} \sum_{s=1}^S p(y_n\mid \Theta^{k,s})\right)
    \tag{D.1}
  \end{equation}\]</span></p>
<p>where <span class="math inline">\(\Theta^{k,s}\)</span> corresponds to the sample <span class="math inline">\(s\)</span> of the posterior of the model fit to the training set <span class="math inline">\(D_-k\)</span>.</p>
<ol start="5" style="list-style-type: decimal">
<li>We obtain the <span class="math inline">\(elpd_{kfold}\)</span> (or <span class="math inline">\(elpd_{loo}\)</span>) for all the held-out data points by summing up the <span class="math inline">\(\widehat{elpd}_n\)</span>:</li>
</ol>
<p><span class="math display" id="eq:totalkfold">\[\begin{equation}
    elpd_{kfold} = \sum_{n=1}^N \widehat{elpd}_n
    \tag{D.2}
  \end{equation}\]</span></p>
<p>The  standard deviation of the sampling distribution (the  standard error) can be computed by multiplying the standard deviation (or square root of variance) of the <span class="math inline">\(N\)</span> components by <span class="math inline">\(\sqrt{N}\)</span>. Letting <span class="math inline">\(\widehat{ELPD}\)</span> be the vector <span class="math inline">\(\widehat{elpd}_1,\dots,\widehat{elpd}_N\)</span>, the standard error is computed as follows:</p>
<p><span class="math display" id="eq:sekfold">\[\begin{equation}
se(\widehat{elpd}) = \sqrt{N \mathit{Var}(\widehat{ELPD})}
\tag{D.3}
\end{equation}\]</span></p>
<p>The difference between the <span class="math inline">\(elpd_{kfold}\)</span> of two competing models, <span class="math inline">\(\mathcal{M}_1\)</span> and <span class="math inline">\(\mathcal{M}_2\)</span>, is a measure of  relative predictive performance. The standard error of their difference can be computed using the formula discussed in <span class="citation">Vehtari, Gelman, and Gabry (<a href="#ref-vehtariPracticalBayesianModel2017" role="doc-biblioref">2017</a>)</span>:</p>
<p><span class="math display" id="eq:sekfolddiff">\[\begin{equation}
se(\widehat{elpd}_{\mathcal{M}1} - \widehat{elpd}_{\mathcal{M}2}) = \sqrt{N \mathit{Var}(\widehat{ELPD_{\mathcal{M}1}} - \widehat{ELPD_{\mathcal{M}2}})}
\tag{D.4}
\end{equation}\]</span></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references hanging-indent">
<div id="ref-Freedman1984">
<p>Freedman, Laurence S., D. Lowe, and P. Macaskill. 1984. “Stopping Rules for Clinical Trials Incorporating Clinical Opinion.” <em>Biometrics</em> 40 (3): 575–86.</p>
</div>
<div id="ref-gelmancarlin">
<p>Gelman, Andrew, and John B. Carlin. 2014. “Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors.” <em>Perspectives on Psychological Science</em> 9 (6): 641–51. <a href="https://doi.org/https://doi.org/10.1177/1745691614551642">https://doi.org/https://doi.org/10.1177/1745691614551642</a>.</p>
</div>
<div id="ref-kruschke2014doing">
<p>Kruschke, John K. 2014. <em>Doing Bayesian Data Analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press.</p>
</div>
<div id="ref-kruschke2018bayesian">
<p>Kruschke, John K., and Torrin M. Liddell. 2018. “The Bayesian New Statistics: Hypothesis Testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective.” <em>Psychonomic Bulletin &amp; Review</em> 25 (1): 178–206. <a href="https://doi.org/https://doi.org/10.3758/s13423-016-1221-4">https://doi.org/https://doi.org/10.3758/s13423-016-1221-4</a>.</p>
</div>
<div id="ref-newall2023evaluation">
<p>Newall, Philip W. S., Taylor R. Hayes, Henrik Singmann, Leonardo Weiss-Cohen, Elliot A. Ludvig, and Lukasz Walasek. 2023. “Evaluation of the ’Take Time to Think’ Safer Gambling Message: A Randomised, Online Experimental Study.” <em>Behavioural Public Policy</em>, 1–18. <a href="https://doi.org/10.1017/bpp.2023.2">https://doi.org/10.1017/bpp.2023.2</a>.</p>
</div>
<div id="ref-NicenboimVasishth2016">
<p>Nicenboim, Bruno, and Shravan Vasishth. 2016. “Statistical methods for linguistic research: Foundational Ideas - Part II.” <em>Language and Linguistics Compass</em> 10 (11): 591–613. <a href="https://doi.org/10.1111/lnc3.12207">https://doi.org/10.1111/lnc3.12207</a>.</p>
</div>
<div id="ref-rouder2018bayesian">
<p>Rouder, Jeffrey N, Julia M. Haaf, and Joachim Vandekerckhove. 2018. “Bayesian Inference for Psychology, Part IV: Parameter Estimation and Bayes Factors.” <em>Psychonomic Bulletin &amp; Review</em> 25 (1): 102–13. <a href="https://doi.org/https://doi.org/10.3758/s13423-017-1420-7">https://doi.org/https://doi.org/10.3758/s13423-017-1420-7</a>.</p>
</div>
<div id="ref-spiegelhalter1994bayesian">
<p>Spiegelhalter, David J., Laurence S. Freedman, and Mahesh K. B. Parmar. 1994. “Bayesian Approaches to Randomized Trials.” <em>Journal of the Royal Statistical Society. Series A (Statistics in Society)</em> 157 (3): 357–416.</p>
</div>
<div id="ref-VasishthMertzenJaegerGelman2018">
<p>Vasishth, Shravan, Daniela Mertzen, Lena A. Jäger, and Andrew Gelman. 2018. “The Statistical Significance Filter Leads to Overoptimistic Expectations of Replicability.” <em>Journal of Memory and Language</em> 103: 151–75. <a href="https://doi.org/https://doi.org/10.1016/j.jml.2018.07.004">https://doi.org/https://doi.org/10.1016/j.jml.2018.07.004</a>.</p>
</div>
<div id="ref-SampleSizeCBB2021">
<p>Vasishth, Shravan, Himanshu Yadav, Daniel J. Schad, and Bruno Nicenboim. 2022. “Sample Size Determination for Bayesian Hierarchical Models Commonly Used in Psycholinguistics.” <em>Computational Brain and Behavior</em>. <a href="https://doi.org/https://doi.org/10.1007/s42113-021-00125-y">https://doi.org/https://doi.org/10.1007/s42113-021-00125-y</a>.</p>
</div>
<div id="ref-vehtariPracticalBayesianModel2017">
<p>Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.” <em>Statistics and Computing</em> 27 (5): 1413–32. <a href="https://doi.org/10.1007/s11222-016-9696-4">https://doi.org/10.1007/s11222-016-9696-4</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="73">
<li id="fn73"><p>This is also strictly true only in a highest density interval (HDI), this is a credible interval where all the points within the interval have a higher probability density than points outside the interval. However, when posterior distributions are symmetrical, these intervals are virtually identical to the equal-tail intervals we use in this book.<a href="model-comparison---extended.html#fnref73" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="evidence-synthesis-and-measurements-with-error---extended.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-priors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
